{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61843d8f-ed29-45e3-8fbc-b0341b739cd0",
      "metadata": {
        "id": "61843d8f-ed29-45e3-8fbc-b0341b739cd0",
        "outputId": "c05ef03a-37eb-4506-fae2-59231c7954e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbase_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\\nhb_thresholds = [    \"9_0\"] #and other HB thresholds\\ntarget_images_total = 3000\\ntarget_per_eye = 495  # ~490â€“498 range\\n\\nused_beneficiaries = set()\\n\\nfor hb in hb_thresholds:\\n    print(f\"\\nğŸš€ Processing Hb threshold: {hb.replace(\\'_\\', \\'.\\')} g/dL\")\\n\\n    output_dir = os.path.join(base_path, f\"hb_{hb}\")\\n    ensure_directory(output_dir)\\n\\n    output_base = os.path.join(output_dir, \"conjunctiva_extracted\")\\n    ensure_directory(output_base)\\n\\n    # Output folders for this Hb threshold\\n    output_paths = [\\n        os.path.join(output_base, \\'anemic_train_roi\\'),\\n        os.path.join(output_base, \\'anemic_not_train_roi\\'),\\n        os.path.join(output_base, \\'anemic_val_roi\\'),\\n        os.path.join(output_base, \\'anemic_not_val_roi\\'),\\n        os.path.join(output_base, \\'anemic_test_roi\\'),\\n        os.path.join(output_base, \\'anemic_not_test_roi\\')\\n    ]\\n    for path in output_paths:\\n        ensure_directory(path)\\n\\n    def make_full_path(subdirs):\\n        return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\\n\\n    # Define mappings dynamically for each Hb threshold\\n    def dirs_for(split_type, anemic=True):\\n        prefix = \"anemic\" if anemic else \"anemic_not\"\\n        return make_full_path({\\n            \\'left1\\': f\"tri_left_eye/left_eye_1_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\\n            \\'left2\\': f\"tri_left_eye/left_eye_2_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\\n            \\'left3\\': f\"tri_left_eye/left_eye_3_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\\n            \\'right1\\': f\"tri_right_eye/right_eye_1_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\\n            \\'right2\\': f\"tri_right_eye/right_eye_2_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\\n            \\'right3\\': f\"tri_right_eye/right_eye_3_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\"\\n        })\\n\\n    # Run balanced selection for all 6 splits per Hb threshold\\n    select_balanced_images(dirs_for(\"train\"), os.path.join(output_base, \\'anemic_train_roi\\'), used_beneficiaries, target_per_eye)\\n    select_balanced_images(dirs_for(\"train\", anemic=False), os.path.join(output_base, \\'anemic_not_train_roi\\'), used_beneficiaries, target_per_eye)\\n    select_balanced_images(dirs_for(\"val\"), os.path.join(output_base, \\'anemic_val_roi\\'), used_beneficiaries, target_per_eye)\\n    select_balanced_images(dirs_for(\"val\", anemic=False), os.path.join(output_base, \\'anemic_not_val_roi\\'), used_beneficiaries, target_per_eye)\\n    select_balanced_images(dirs_for(\"test\"), os.path.join(output_base, \\'anemic_test_roi\\'), used_beneficiaries, target_per_eye)\\n    select_balanced_images(dirs_for(\"test\", anemic=False), os.path.join(output_base, \\'anemic_not_test_roi\\'), used_beneficiaries, target_per_eye)\\n\\n    # Trim dataset to exactly 2990 images for this Hb threshold\\n    trim_to_target_images(output_paths, target_total=target_images_total)\\n\\n    # Verify distribution per Hb threshold\\n    verify_image_distribution(output_base, [\\n        \"anemic_train_roi\", \"anemic_not_train_roi\",\\n        \"anemic_val_roi\", \"anemic_not_val_roi\",\\n        \"anemic_test_roi\", \"anemic_not_test_roi\"\\n    ])\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' single eye random image selection approx 500 each eye'''\n",
        "##### import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. BALANCED IMAGE SELECTION (UNIQUE PER BENEFICIARY)\n",
        "# ---------------------------------------------------------\n",
        "def select_balanced_images(source_dirs, output_dir, used_beneficiaries, target_per_eye, seed=72):\n",
        "    \"\"\"\n",
        "    Selects balanced images across 6 eye views while ensuring:\n",
        "    âœ… Each beneficiary is used only once globally (across all Hb thresholds)\n",
        "    âœ… Each eye view has ~target_per_eye images\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    suffix_map = {\n",
        "        'left1': '_left_eye_1.png',\n",
        "        'left2': '_left_eye_2.png',\n",
        "        'left3': '_left_eye_3.png',\n",
        "        'right1': '_right_eye_1.png',\n",
        "        'right2': '_right_eye_2.png',\n",
        "        'right3': '_right_eye_3.png',\n",
        "    }\n",
        "\n",
        "    # Collect images per beneficiary\n",
        "    beneficiary_images = defaultdict(dict)\n",
        "    for key, src_dir in source_dirs.items():\n",
        "        suffix = suffix_map[key]\n",
        "        if not os.path.exists(src_dir):\n",
        "            continue\n",
        "        for fname in os.listdir(src_dir):\n",
        "            if fname.endswith(suffix):\n",
        "                b_id = fname.replace(suffix, \"\")\n",
        "                if b_id in used_beneficiaries:\n",
        "                    continue\n",
        "                beneficiary_images[b_id][key] = os.path.join(src_dir, fname)\n",
        "\n",
        "    beneficiaries = list(beneficiary_images.keys())\n",
        "    random.shuffle(beneficiaries)\n",
        "\n",
        "    counts = {k: 0 for k in suffix_map.keys()}\n",
        "\n",
        "    # Pick balanced images\n",
        "    for b_id in beneficiaries:\n",
        "        for eye_key in sorted(counts, key=counts.get):  # always choose least-filled eye first\n",
        "            if eye_key in beneficiary_images[b_id] and counts[eye_key] < target_per_eye:\n",
        "                src = beneficiary_images[b_id][eye_key]\n",
        "                shutil.copy(src, os.path.join(output_dir, os.path.basename(src)))\n",
        "                counts[eye_key] += 1\n",
        "                used_beneficiaries.add(b_id)\n",
        "                break\n",
        "\n",
        "        # Stop early if all targets are filled\n",
        "        if all(c >= target_per_eye for c in counts.values()):\n",
        "            break\n",
        "\n",
        "    print(f\"âœ… Copied {sum(counts.values())} images â†’ {output_dir}\")\n",
        "    print(f\"ğŸ“Š Per-eye distribution: {counts}\")\n",
        "    return counts\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. ENSURE DIRECTORY EXISTS\n",
        "# ---------------------------------------------------------\n",
        "def ensure_directory(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. TRIM DATASET TO EXACTLY 2990 IMAGES\n",
        "# ---------------------------------------------------------\n",
        "def trim_to_target_images(folders, target_total=2990, seed=42):\n",
        "    random.seed(seed)\n",
        "    folder_images = {\n",
        "        f: [os.path.join(f, x) for x in os.listdir(f) if x.endswith(\".png\")]\n",
        "        for f in folders\n",
        "    }\n",
        "    total_images = sum(len(imgs) for imgs in folder_images.values())\n",
        "\n",
        "    print(f\"ğŸ“‚ Current total images: {total_images}\")\n",
        "    if total_images <= target_total:\n",
        "        print(f\"âœ… No trimming needed, already â‰¤ {target_total}.\")\n",
        "        return\n",
        "\n",
        "    excess = total_images - target_total\n",
        "    print(f\"âš ï¸ Need to delete {excess} images to maintain {target_total} total.\")\n",
        "\n",
        "    per_folder_delete = excess // len(folders)\n",
        "    remaining = excess % len(folders)\n",
        "    deleted_count = 0\n",
        "\n",
        "    for i, (folder, imgs) in enumerate(folder_images.items()):\n",
        "        random.shuffle(imgs)\n",
        "        num_to_delete = per_folder_delete + (1 if i < remaining else 0)\n",
        "        for img in imgs[:num_to_delete]:\n",
        "            os.remove(img)\n",
        "            deleted_count += 1\n",
        "        print(f\"ğŸ—‘ï¸ Deleted {num_to_delete} images from: {folder}\")\n",
        "\n",
        "    print(f\"âœ… Done! Deleted {deleted_count} images total.\")\n",
        "    print(f\"ğŸ¯ Final dataset size: {target_total}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. VERIFY FINAL DATASET DISTRIBUTION\n",
        "# ---------------------------------------------------------\n",
        "def verify_image_distribution(base_path, folders):\n",
        "    patterns = [\n",
        "        \"_left_eye_1.png\", \"_left_eye_2.png\", \"_left_eye_3.png\",\n",
        "        \"_right_eye_1.png\", \"_right_eye_2.png\", \"_right_eye_3.png\"\n",
        "    ]\n",
        "    image_counts = Counter()\n",
        "    beneficiary_ids = set()\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        for fname in os.listdir(folder_path):\n",
        "            for pattern in patterns:\n",
        "                if fname.endswith(pattern):\n",
        "                    image_counts[pattern] += 1\n",
        "            b_id = fname.split(\"_left_eye_\")[0] if \"_left_eye_\" in fname else fname.split(\"_right_eye_\")[0]\n",
        "            beneficiary_ids.add(b_id)\n",
        "\n",
        "    print(\"\\nğŸ“Š Final Image Counts by Eye Type:\")\n",
        "    for pattern in patterns:\n",
        "        print(f\"{pattern}: {image_counts[pattern]}\")\n",
        "\n",
        "    left_total = sum(image_counts[p] for p in patterns if \"left_eye\" in p)\n",
        "    right_total = sum(image_counts[p] for p in patterns if \"right_eye\" in p)\n",
        "    grand_total = left_total + right_total\n",
        "\n",
        "    print(\"\\nğŸ”¹ Final Totals:\")\n",
        "    print(f\"  Total LEFT eye images : {left_total}\")\n",
        "    print(f\"  Total RIGHT eye images: {right_total}\")\n",
        "    print(f\"  Grand Total           : {grand_total}\")\n",
        "    print(f\"  Unique Beneficiaries  : {len(beneficiary_ids)}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. MAIN EXECUTION (AUTOMATED FOR MULTIPLE Hb THRESHOLDS)\n",
        "# ---------------------------------------------------------\n",
        "'''\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "hb_thresholds = [    \"9_0\"] #and other HB thresholds\n",
        "target_images_total = 3000\n",
        "target_per_eye = 495  # ~490â€“498 range\n",
        "\n",
        "used_beneficiaries = set()\n",
        "\n",
        "for hb in hb_thresholds:\n",
        "    print(f\"\\nğŸš€ Processing Hb threshold: {hb.replace('_', '.')} g/dL\")\n",
        "\n",
        "    output_dir = os.path.join(base_path, f\"hb_{hb}\")\n",
        "    ensure_directory(output_dir)\n",
        "\n",
        "    output_base = os.path.join(output_dir, \"conjunctiva_extracted\")\n",
        "    ensure_directory(output_base)\n",
        "\n",
        "    # Output folders for this Hb threshold\n",
        "    output_paths = [\n",
        "        os.path.join(output_base, 'anemic_train_roi'),\n",
        "        os.path.join(output_base, 'anemic_not_train_roi'),\n",
        "        os.path.join(output_base, 'anemic_val_roi'),\n",
        "        os.path.join(output_base, 'anemic_not_val_roi'),\n",
        "        os.path.join(output_base, 'anemic_test_roi'),\n",
        "        os.path.join(output_base, 'anemic_not_test_roi')\n",
        "    ]\n",
        "    for path in output_paths:\n",
        "        ensure_directory(path)\n",
        "\n",
        "    def make_full_path(subdirs):\n",
        "        return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "    # Define mappings dynamically for each Hb threshold\n",
        "    def dirs_for(split_type, anemic=True):\n",
        "        prefix = \"anemic\" if anemic else \"anemic_not\"\n",
        "        return make_full_path({\n",
        "            'left1': f\"tri_left_eye/left_eye_1_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\n",
        "            'left2': f\"tri_left_eye/left_eye_2_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\n",
        "            'left3': f\"tri_left_eye/left_eye_3_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\n",
        "            'right1': f\"tri_right_eye/right_eye_1_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\n",
        "            'right2': f\"tri_right_eye/right_eye_2_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\",\n",
        "            'right3': f\"tri_right_eye/right_eye_3_hb_less_than_{hb}/conjunctiva_extracted/{prefix}_{split_type}_roi/\"\n",
        "        })\n",
        "\n",
        "    # Run balanced selection for all 6 splits per Hb threshold\n",
        "    select_balanced_images(dirs_for(\"train\"), os.path.join(output_base, 'anemic_train_roi'), used_beneficiaries, target_per_eye)\n",
        "    select_balanced_images(dirs_for(\"train\", anemic=False), os.path.join(output_base, 'anemic_not_train_roi'), used_beneficiaries, target_per_eye)\n",
        "    select_balanced_images(dirs_for(\"val\"), os.path.join(output_base, 'anemic_val_roi'), used_beneficiaries, target_per_eye)\n",
        "    select_balanced_images(dirs_for(\"val\", anemic=False), os.path.join(output_base, 'anemic_not_val_roi'), used_beneficiaries, target_per_eye)\n",
        "    select_balanced_images(dirs_for(\"test\"), os.path.join(output_base, 'anemic_test_roi'), used_beneficiaries, target_per_eye)\n",
        "    select_balanced_images(dirs_for(\"test\", anemic=False), os.path.join(output_base, 'anemic_not_test_roi'), used_beneficiaries, target_per_eye)\n",
        "\n",
        "    # Trim dataset to exactly 2990 images for this Hb threshold\n",
        "    trim_to_target_images(output_paths, target_total=target_images_total)\n",
        "\n",
        "    # Verify distribution per Hb threshold\n",
        "    verify_image_distribution(output_base, [\n",
        "        \"anemic_train_roi\", \"anemic_not_train_roi\",\n",
        "        \"anemic_val_roi\", \"anemic_not_val_roi\",\n",
        "        \"anemic_test_roi\", \"anemic_not_test_roi\"\n",
        "    ])\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188ec9f6-9130-45e5-957f-42ed8122b8fc",
      "metadata": {
        "id": "188ec9f6-9130-45e5-957f-42ed8122b8fc",
        "outputId": "0532bbe5-3aa4-406e-e912-9bb19e5b4fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Image counts by type:\n",
            "\n",
            "_left_eye_1.png: 502\n",
            "_left_eye_2.png: 501\n",
            "_left_eye_3.png: 500\n",
            "_right_eye_1.png: 500\n",
            "_right_eye_2.png: 499\n",
            "_right_eye_3.png: 498\n",
            "\n",
            "ğŸ”¹ Totals:\n",
            "  Total LEFT eye images : 1503\n",
            "  Total RIGHT eye images: 1497\n",
            "  Grand Total          : 3000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Base path for images\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hb_9_0/conjunctiva_extracted\"\n",
        "\n",
        "# List of all 6 folders to scan\n",
        "folders = [\n",
        "    \"anemic_train_roi\",\n",
        "    \"anemic_not_train_roi\",\n",
        "    \"anemic_val_roi\",\n",
        "    \"anemic_not_val_roi\",\n",
        "    \"anemic_test_roi\",\n",
        "    \"anemic_not_test_roi\"\n",
        "]\n",
        "\n",
        "# Patterns to track\n",
        "patterns = [\n",
        "    \"_left_eye_1.png\",\n",
        "    \"_left_eye_2.png\",\n",
        "    \"_left_eye_3.png\",\n",
        "    \"_right_eye_1.png\",\n",
        "    \"_right_eye_2.png\",\n",
        "    \"_right_eye_3.png\"\n",
        "]\n",
        "\n",
        "# Counter for image types\n",
        "image_counts = Counter()\n",
        "\n",
        "# Loop through folders and count images by pattern\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        for pattern in patterns:\n",
        "            if fname.endswith(pattern):\n",
        "                image_counts[pattern] += 1\n",
        "\n",
        "# Display results\n",
        "print(\"ğŸ“Š Image counts by type:\\n\")\n",
        "for pattern in patterns:\n",
        "    print(f\"{pattern}: {image_counts[pattern]}\")\n",
        "\n",
        "print(\"\\nğŸ”¹ Totals:\")\n",
        "left_total = sum(image_counts[p] for p in patterns if \"left_eye\" in p)\n",
        "right_total = sum(image_counts[p] for p in patterns if \"right_eye\" in p)\n",
        "grand_total = left_total + right_total\n",
        "\n",
        "print(f\"  Total LEFT eye images : {left_total}\")\n",
        "print(f\"  Total RIGHT eye images: {right_total}\")\n",
        "print(f\"  Grand Total          : {grand_total}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8eb2d3-bc17-42f2-9d7e-7847ab488491",
      "metadata": {
        "id": "da8eb2d3-bc17-42f2-9d7e-7847ab488491",
        "outputId": "2d4b5a7f-d0d5-414d-aa62-da1dc208765f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ Total images          : 3000\n",
            "ğŸ”¹ Unique beneficiary IDs: 3000\n",
            "âœ… All images are unique!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Base path for images\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hb_9_0/conjunctiva_extracted\"\n",
        "\n",
        "# Folders to check\n",
        "folders = [\n",
        "    \"anemic_train_roi\",\n",
        "    \"anemic_not_train_roi\",\n",
        "    \"anemic_val_roi\",\n",
        "    \"anemic_not_val_roi\",\n",
        "    \"anemic_test_roi\",\n",
        "    \"anemic_not_test_roi\"\n",
        "]\n",
        "\n",
        "# Collect all base IDs (filenames without eye suffixes)\n",
        "base_ids = []\n",
        "\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        if fname.endswith(\".png\"):\n",
        "            # Remove suffix: everything after first \"_left_eye\" or \"_right_eye\"\n",
        "            if \"_left_eye\" in fname:\n",
        "                base_id = fname.split(\"_left_eye\")[0]\n",
        "            elif \"_right_eye\" in fname:\n",
        "                base_id = fname.split(\"_right_eye\")[0]\n",
        "            else:\n",
        "                base_id = os.path.splitext(fname)[0]  # fallback\n",
        "\n",
        "            base_ids.append(base_id)\n",
        "\n",
        "# Count total vs unique\n",
        "total_files = len(base_ids)\n",
        "unique_ids = len(set(base_ids))\n",
        "\n",
        "print(f\"ğŸ“‚ Total images          : {total_files}\")\n",
        "print(f\"ğŸ”¹ Unique beneficiary IDs: {unique_ids}\")\n",
        "\n",
        "if total_files == unique_ids:\n",
        "    print(\"âœ… All images are unique!\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Found {total_files - unique_ids} duplicate images.\")\n",
        "\n",
        "    # Find duplicates explicitly\n",
        "    duplicates = [item for item, count in Counter(base_ids).items() if count > 1]\n",
        "    print(f\"ğŸ” Duplicate IDs ({len(duplicates)}):\")\n",
        "    for dup in duplicates:\n",
        "        print(f\"  - {dup}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d5153c-3808-41f1-b6b0-60e78eb21246",
      "metadata": {
        "id": "e7d5153c-3808-41f1-b6b0-60e78eb21246",
        "outputId": "662d65fa-0a57-413f-9811-03898e570e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ğŸ” TRAIN - discovered bases: anemic=235, non-anemic=1824\n",
            "âœ… TRAIN: hexa-matched samples -> anemic=235, non-anemic=1824, total=2059\n",
            "\n",
            "ğŸ” VAL - discovered bases: anemic=37, non-anemic=291\n",
            "âœ… VAL: hexa-matched samples -> anemic=37, non-anemic=291, total=328\n",
            "\n",
            "ğŸ” TEST - discovered bases: anemic=28, non-anemic=237\n",
            "âœ… TEST: hexa-matched samples -> anemic=28, non-anemic=237, total=265\n",
            "\n",
            "===== Processing resolution: 224 =====\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch [1/75] ğŸ” Loss: 34.002423\n",
            "Epoch [2/75] ğŸ” Loss: 33.531065\n",
            "Epoch [3/75] ğŸ” Loss: 32.803141\n",
            "Epoch [4/75] ğŸ” Loss: 33.063180\n",
            "Epoch [5/75] ğŸ” Loss: 31.811949\n",
            "Epoch [6/75] ğŸ” Loss: 31.779203\n",
            "Epoch [7/75] ğŸ” Loss: 30.522110\n",
            "Epoch [8/75] ğŸ” Loss: 30.739449\n",
            "Epoch [9/75] ğŸ” Loss: 30.665748\n",
            "Epoch [10/75] ğŸ” Loss: 29.967029\n",
            "Epoch [11/75] ğŸ” Loss: 29.971080\n",
            "Epoch [12/75] ğŸ” Loss: 29.074833\n",
            "Epoch [13/75] ğŸ” Loss: 28.495415\n",
            "Epoch [14/75] ğŸ” Loss: 28.998241\n",
            "Epoch [15/75] ğŸ” Loss: 27.142231\n",
            "Epoch [16/75] ğŸ” Loss: 26.677579\n",
            "Epoch [17/75] ğŸ” Loss: 23.380114\n",
            "Epoch [18/75] ğŸ” Loss: 21.268672\n",
            "Epoch [19/75] ğŸ” Loss: 18.876258\n",
            "Epoch [20/75] ğŸ” Loss: 18.149581\n",
            "Epoch [21/75] ğŸ” Loss: 14.546693\n",
            "Epoch [22/75] ğŸ” Loss: 15.065361\n",
            "Epoch [23/75] ğŸ” Loss: 12.468141\n",
            "Epoch [24/75] ğŸ” Loss: 11.917580\n",
            "Epoch [25/75] ğŸ” Loss: 12.257301\n",
            "Epoch [26/75] ğŸ” Loss: 11.045667\n",
            "Epoch [27/75] ğŸ” Loss: 8.731709\n",
            "Epoch [28/75] ğŸ” Loss: 7.185863\n",
            "Epoch [29/75] ğŸ” Loss: 8.749261\n",
            "Epoch [30/75] ğŸ” Loss: 7.273069\n",
            "Epoch [31/75] ğŸ” Loss: 6.323935\n",
            "Epoch [32/75] ğŸ” Loss: 4.704644\n",
            "Epoch [33/75] ğŸ” Loss: 7.144439\n",
            "Epoch [34/75] ğŸ” Loss: 6.011143\n",
            "Epoch [35/75] ğŸ” Loss: 5.143299\n",
            "Epoch [36/75] ğŸ” Loss: 3.500549\n",
            "Epoch [37/75] ğŸ” Loss: 7.820159\n",
            "Epoch [38/75] ğŸ” Loss: 5.488956\n",
            "Epoch [39/75] ğŸ” Loss: 3.902685\n",
            "Epoch [40/75] ğŸ” Loss: 2.663337\n",
            "Epoch [41/75] ğŸ” Loss: 2.754367\n",
            "Epoch [42/75] ğŸ” Loss: 2.689331\n",
            "Epoch [43/75] ğŸ” Loss: 2.816598\n",
            "Epoch [44/75] ğŸ” Loss: 1.596489\n",
            "Epoch [45/75] ğŸ” Loss: 3.006375\n",
            "Epoch [46/75] ğŸ” Loss: 1.109033\n",
            "Epoch [47/75] ğŸ” Loss: 2.620671\n",
            "Epoch [48/75] ğŸ” Loss: 2.545682\n",
            "Epoch [49/75] ğŸ” Loss: 3.694583\n",
            "Epoch [50/75] ğŸ” Loss: 3.327743\n",
            "Epoch [51/75] ğŸ” Loss: 1.620365\n",
            "Epoch [52/75] ğŸ” Loss: 1.440416\n",
            "Epoch [53/75] ğŸ” Loss: 1.994521\n",
            "Epoch [54/75] ğŸ” Loss: 2.069459\n",
            "Epoch [55/75] ğŸ” Loss: 2.305050\n",
            "Epoch [56/75] ğŸ” Loss: 1.606552\n",
            "Epoch [57/75] ğŸ” Loss: 1.457756\n",
            "Epoch [58/75] ğŸ” Loss: 0.788478\n",
            "Epoch [59/75] ğŸ” Loss: 1.735798\n",
            "Epoch [60/75] ğŸ” Loss: 1.266944\n",
            "Epoch [61/75] ğŸ” Loss: 1.965080\n",
            "Epoch [62/75] ğŸ” Loss: 1.053301\n",
            "Epoch [63/75] ğŸ” Loss: 0.817828\n",
            "Epoch [64/75] ğŸ” Loss: 2.351810\n",
            "Epoch [65/75] ğŸ” Loss: 1.298264\n",
            "Epoch [66/75] ğŸ” Loss: 1.949350\n",
            "Epoch [67/75] ğŸ” Loss: 0.426855\n",
            "Epoch [68/75] ğŸ” Loss: 2.089625\n",
            "Epoch [69/75] ğŸ” Loss: 1.570104\n",
            "Epoch [70/75] ğŸ” Loss: 0.649411\n",
            "Epoch [71/75] ğŸ” Loss: 2.047058\n",
            "Epoch [72/75] ğŸ” Loss: 0.695626\n",
            "Epoch [73/75] ğŸ” Loss: 1.221787\n",
            "Epoch [74/75] ğŸ” Loss: 0.423687\n",
            "Epoch [75/75] ğŸ” Loss: 0.179878\n",
            "{'Resolution': 224, 'Fold': 1, 'Epochs': 75, 'BatchSize': 18, 'LearningRate': 0.00018, 'Val_Precision': 1.0, 'Val_Recall': 0.851063829787234, 'Val_F1': 0.9195402298850576, 'Val_Accuracy': 0.9830097087378641, 'Val_AUC': 0.9995919556980473, 'Val_TP': 40, 'Val_TN': 365, 'Val_FP': 0, 'Val_FN': 7}\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch [1/75] ğŸ” Loss: 36.793818\n",
            "Epoch [2/75] ğŸ” Loss: 33.008283\n",
            "Epoch [3/75] ğŸ” Loss: 32.402090\n",
            "Epoch [4/75] ğŸ” Loss: 31.956541\n",
            "Epoch [5/75] ğŸ” Loss: 31.089668\n",
            "Epoch [6/75] ğŸ” Loss: 30.953655\n",
            "Epoch [7/75] ğŸ” Loss: 30.516094\n",
            "Epoch [8/75] ğŸ” Loss: 29.555899\n",
            "Epoch [9/75] ğŸ” Loss: 29.255535\n",
            "Epoch [10/75] ğŸ” Loss: 28.448618\n",
            "Epoch [11/75] ğŸ” Loss: 28.333521\n",
            "Epoch [12/75] ğŸ” Loss: 27.509408\n",
            "Epoch [13/75] ğŸ” Loss: 26.758634\n",
            "Epoch [14/75] ğŸ” Loss: 26.529474\n",
            "Epoch [15/75] ğŸ” Loss: 26.102674\n",
            "Epoch [16/75] ğŸ” Loss: 25.640781\n",
            "Epoch [17/75] ğŸ” Loss: 23.543473\n",
            "Epoch [18/75] ğŸ” Loss: 22.660613\n",
            "Epoch [19/75] ğŸ” Loss: 21.324311\n",
            "Epoch [20/75] ğŸ” Loss: 21.139563\n",
            "Epoch [21/75] ğŸ” Loss: 20.477723\n",
            "Epoch [22/75] ğŸ” Loss: 16.920008\n",
            "Epoch [23/75] ğŸ” Loss: 17.308395\n",
            "Epoch [24/75] ğŸ” Loss: 14.136865\n",
            "Epoch [25/75] ğŸ” Loss: 14.143404\n",
            "Epoch [26/75] ğŸ” Loss: 13.467997\n",
            "Epoch [27/75] ğŸ” Loss: 11.012449\n",
            "Epoch [28/75] ğŸ” Loss: 11.100599\n",
            "Epoch [29/75] ğŸ” Loss: 10.600036\n",
            "Epoch [30/75] ğŸ” Loss: 8.765494\n",
            "Epoch [31/75] ğŸ” Loss: 8.285983\n",
            "Epoch [32/75] ğŸ” Loss: 7.072231\n",
            "Epoch [33/75] ğŸ” Loss: 7.421602\n",
            "Epoch [34/75] ğŸ” Loss: 7.467625\n",
            "Epoch [35/75] ğŸ” Loss: 6.120961\n",
            "Epoch [36/75] ğŸ” Loss: 6.514286\n",
            "Epoch [37/75] ğŸ” Loss: 6.228810\n",
            "Epoch [38/75] ğŸ” Loss: 4.054984\n",
            "Epoch [39/75] ğŸ” Loss: 5.115678\n",
            "Epoch [40/75] ğŸ” Loss: 4.688993\n",
            "Epoch [41/75] ğŸ” Loss: 5.530243\n",
            "Epoch [42/75] ğŸ” Loss: 4.524827\n",
            "Epoch [43/75] ğŸ” Loss: 3.818443\n",
            "Epoch [44/75] ğŸ” Loss: 3.156762\n",
            "Epoch [45/75] ğŸ” Loss: 3.045267\n",
            "Epoch [46/75] ğŸ” Loss: 4.368007\n",
            "Epoch [47/75] ğŸ” Loss: 2.632058\n",
            "Epoch [48/75] ğŸ” Loss: 2.475223\n",
            "Epoch [49/75] ğŸ” Loss: 2.387101\n",
            "Epoch [50/75] ğŸ” Loss: 2.321829\n",
            "Epoch [51/75] ğŸ” Loss: 1.063021\n",
            "Epoch [52/75] ğŸ” Loss: 2.766386\n",
            "Epoch [53/75] ğŸ” Loss: 2.549477\n",
            "Epoch [54/75] ğŸ” Loss: 1.875895\n",
            "Epoch [55/75] ğŸ” Loss: 2.546794\n",
            "Epoch [56/75] ğŸ” Loss: 1.091087\n",
            "Epoch [57/75] ğŸ” Loss: 2.152539\n",
            "Epoch [58/75] ğŸ” Loss: 1.991784\n",
            "Epoch [59/75] ğŸ” Loss: 1.685096\n",
            "Epoch [60/75] ğŸ” Loss: 1.785742\n",
            "Epoch [61/75] ğŸ” Loss: 1.758840\n",
            "Epoch [62/75] ğŸ” Loss: 0.842626\n",
            "Epoch [63/75] ğŸ” Loss: 1.480618\n",
            "Epoch [64/75] ğŸ” Loss: 1.318443\n",
            "Epoch [65/75] ğŸ” Loss: 1.530108\n",
            "Epoch [66/75] ğŸ” Loss: 0.741921\n",
            "Epoch [67/75] ğŸ” Loss: 4.075260\n",
            "Epoch [68/75] ğŸ” Loss: 2.293901\n",
            "Epoch [69/75] ğŸ” Loss: 1.555903\n",
            "Epoch [70/75] ğŸ” Loss: 1.526559\n",
            "Epoch [71/75] ğŸ” Loss: 0.881175\n",
            "Epoch [72/75] ğŸ” Loss: 0.675515\n",
            "Epoch [73/75] ğŸ” Loss: 5.945306\n",
            "Epoch [74/75] ğŸ” Loss: 1.345016\n",
            "Epoch [75/75] ğŸ” Loss: 0.401634\n",
            "{'Resolution': 224, 'Fold': 2, 'Epochs': 75, 'BatchSize': 18, 'LearningRate': 0.00018, 'Val_Precision': 0.8846153846153846, 'Val_Recall': 0.9787234042553191, 'Val_F1': 0.9292929292929293, 'Val_Accuracy': 0.9830097087378641, 'Val_AUC': 0.9983095307490528, 'Val_TP': 46, 'Val_TN': 359, 'Val_FP': 6, 'Val_FN': 1}\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch [1/75] ğŸ” Loss: 40.670844\n",
            "Epoch [2/75] ğŸ” Loss: 33.190468\n",
            "Epoch [3/75] ğŸ” Loss: 32.932491\n",
            "Epoch [4/75] ğŸ” Loss: 33.189747\n",
            "Epoch [5/75] ğŸ” Loss: 31.842219\n",
            "Epoch [6/75] ğŸ” Loss: 30.894152\n",
            "Epoch [7/75] ğŸ” Loss: 30.891065\n",
            "Epoch [8/75] ğŸ” Loss: 29.859803\n",
            "Epoch [9/75] ğŸ” Loss: 29.810660\n",
            "Epoch [10/75] ğŸ” Loss: 29.903899\n",
            "Epoch [11/75] ğŸ” Loss: 29.374709\n",
            "Epoch [12/75] ğŸ” Loss: 29.626005\n",
            "Epoch [13/75] ğŸ” Loss: 28.260883\n",
            "Epoch [14/75] ğŸ” Loss: 28.783890\n",
            "Epoch [15/75] ğŸ” Loss: 27.321326\n",
            "Epoch [16/75] ğŸ” Loss: 27.170499\n",
            "Epoch [17/75] ğŸ” Loss: 26.770013\n",
            "Epoch [18/75] ğŸ” Loss: 26.162452\n",
            "Epoch [19/75] ğŸ” Loss: 25.699553\n",
            "Epoch [20/75] ğŸ” Loss: 25.032969\n",
            "Epoch [21/75] ğŸ” Loss: 23.793107\n",
            "Epoch [22/75] ğŸ” Loss: 23.002353\n",
            "Epoch [23/75] ğŸ” Loss: 22.366750\n",
            "Epoch [24/75] ğŸ” Loss: 19.177727\n",
            "Epoch [25/75] ğŸ” Loss: 18.365339\n",
            "Epoch [26/75] ğŸ” Loss: 17.068577\n",
            "Epoch [27/75] ğŸ” Loss: 13.662049\n",
            "Epoch [28/75] ğŸ” Loss: 14.581637\n",
            "Epoch [29/75] ğŸ” Loss: 12.303396\n",
            "Epoch [30/75] ğŸ” Loss: 11.162640\n",
            "Epoch [31/75] ğŸ” Loss: 11.510431\n",
            "Epoch [32/75] ğŸ” Loss: 11.859444\n",
            "Epoch [33/75] ğŸ” Loss: 8.746589\n",
            "Epoch [34/75] ğŸ” Loss: 10.273079\n",
            "Epoch [35/75] ğŸ” Loss: 8.592863\n",
            "Epoch [36/75] ğŸ” Loss: 7.145166\n",
            "Epoch [37/75] ğŸ” Loss: 5.689800\n",
            "Epoch [38/75] ğŸ” Loss: 5.275738\n",
            "Epoch [39/75] ğŸ” Loss: 6.355533\n",
            "Epoch [40/75] ğŸ” Loss: 5.780874\n",
            "Epoch [41/75] ğŸ” Loss: 5.419073\n",
            "Epoch [42/75] ğŸ” Loss: 5.244733\n",
            "Epoch [43/75] ğŸ” Loss: 4.306686\n",
            "Epoch [44/75] ğŸ” Loss: 3.903376\n",
            "Epoch [45/75] ğŸ” Loss: 3.373824\n",
            "Epoch [46/75] ğŸ” Loss: 2.599751\n",
            "Epoch [47/75] ğŸ” Loss: 2.942251\n",
            "Epoch [48/75] ğŸ” Loss: 6.052905\n",
            "Epoch [49/75] ğŸ” Loss: 3.469941\n",
            "Epoch [50/75] ğŸ” Loss: 2.986390\n",
            "Epoch [51/75] ğŸ” Loss: 1.443009\n",
            "Epoch [52/75] ğŸ” Loss: 2.613096\n",
            "Epoch [53/75] ğŸ” Loss: 3.404854\n",
            "Epoch [54/75] ğŸ” Loss: 0.764033\n",
            "Epoch [55/75] ğŸ” Loss: 3.251899\n",
            "Epoch [56/75] ğŸ” Loss: 2.771221\n",
            "Epoch [57/75] ğŸ” Loss: 2.180918\n",
            "Epoch [58/75] ğŸ” Loss: 1.357247\n",
            "Epoch [59/75] ğŸ” Loss: 2.121683\n",
            "Epoch [60/75] ğŸ” Loss: 2.259083\n",
            "Epoch [61/75] ğŸ” Loss: 1.826108\n",
            "Epoch [62/75] ğŸ” Loss: 1.582072\n",
            "Epoch [63/75] ğŸ” Loss: 2.243244\n",
            "Epoch [64/75] ğŸ” Loss: 1.128247\n",
            "Epoch [65/75] ğŸ” Loss: 1.138278\n",
            "Epoch [66/75] ğŸ” Loss: 1.983909\n",
            "Epoch [67/75] ğŸ” Loss: 1.105627\n",
            "Epoch [68/75] ğŸ” Loss: 1.799454\n",
            "Epoch [69/75] ğŸ” Loss: 1.635495\n",
            "Epoch [70/75] ğŸ” Loss: 2.002148\n",
            "Epoch [71/75] ğŸ” Loss: 1.580778\n",
            "Epoch [72/75] ğŸ” Loss: 1.197917\n",
            "Epoch [73/75] ğŸ” Loss: 1.160458\n",
            "Epoch [74/75] ğŸ” Loss: 0.313887\n",
            "Epoch [75/75] ğŸ” Loss: 1.050671\n",
            "{'Resolution': 224, 'Fold': 3, 'Epochs': 75, 'BatchSize': 18, 'LearningRate': 0.00018, 'Val_Precision': 0.9347826086956522, 'Val_Recall': 0.9148936170212766, 'Val_F1': 0.924731182795699, 'Val_Accuracy': 0.9830097087378641, 'Val_AUC': 0.9935878752550277, 'Val_TP': 43, 'Val_TN': 362, 'Val_FP': 3, 'Val_FN': 4}\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch [1/75] ğŸ” Loss: 34.419107\n",
            "Epoch [2/75] ğŸ” Loss: 32.963697\n",
            "Epoch [3/75] ğŸ” Loss: 32.745180\n",
            "Epoch [4/75] ğŸ” Loss: 32.231372\n",
            "Epoch [5/75] ğŸ” Loss: 30.685724\n",
            "Epoch [6/75] ğŸ” Loss: 31.158266\n",
            "Epoch [7/75] ğŸ” Loss: 29.865511\n",
            "Epoch [8/75] ğŸ” Loss: 29.905062\n",
            "Epoch [9/75] ğŸ” Loss: 29.674252\n",
            "Epoch [10/75] ğŸ” Loss: 29.107292\n",
            "Epoch [11/75] ğŸ” Loss: 28.807397\n",
            "Epoch [12/75] ğŸ” Loss: 28.616460\n",
            "Epoch [13/75] ğŸ” Loss: 27.947939\n",
            "Epoch [14/75] ğŸ” Loss: 27.706075\n",
            "Epoch [15/75] ğŸ” Loss: 27.137991\n",
            "Epoch [16/75] ğŸ” Loss: 26.186942\n",
            "Epoch [17/75] ğŸ” Loss: 25.965314\n",
            "Epoch [18/75] ğŸ” Loss: 24.473153\n",
            "Epoch [19/75] ğŸ” Loss: 24.586319\n",
            "Epoch [20/75] ğŸ” Loss: 23.424315\n",
            "Epoch [21/75] ğŸ” Loss: 23.785887\n",
            "Epoch [22/75] ğŸ” Loss: 24.120809\n",
            "Epoch [23/75] ğŸ” Loss: 22.412015\n",
            "Epoch [24/75] ğŸ” Loss: 20.871452\n",
            "Epoch [25/75] ğŸ” Loss: 21.906962\n",
            "Epoch [26/75] ğŸ” Loss: 20.600759\n",
            "Epoch [27/75] ğŸ” Loss: 19.752319\n",
            "Epoch [28/75] ğŸ” Loss: 18.224578\n",
            "Epoch [29/75] ğŸ” Loss: 16.363610\n",
            "Epoch [30/75] ğŸ” Loss: 16.930001\n",
            "Epoch [31/75] ğŸ” Loss: 17.107001\n",
            "Epoch [32/75] ğŸ” Loss: 15.277873\n",
            "Epoch [33/75] ğŸ” Loss: 16.324776\n",
            "Epoch [34/75] ğŸ” Loss: 13.310498\n",
            "Epoch [35/75] ğŸ” Loss: 15.255506\n",
            "Epoch [36/75] ğŸ” Loss: 14.174281\n",
            "Epoch [37/75] ğŸ” Loss: 13.681344\n",
            "Epoch [38/75] ğŸ” Loss: 12.781688\n",
            "Epoch [39/75] ğŸ” Loss: 10.864486\n",
            "Epoch [40/75] ğŸ” Loss: 8.951949\n",
            "Epoch [41/75] ğŸ” Loss: 12.667072\n",
            "Epoch [42/75] ğŸ” Loss: 11.506942\n",
            "Epoch [43/75] ğŸ” Loss: 9.554076\n",
            "Epoch [44/75] ğŸ” Loss: 11.904285\n",
            "Epoch [45/75] ğŸ” Loss: 9.487801\n",
            "Epoch [46/75] ğŸ” Loss: 9.454072\n",
            "Epoch [47/75] ğŸ” Loss: 8.164663\n",
            "Epoch [48/75] ğŸ” Loss: 7.173897\n",
            "Epoch [49/75] ğŸ” Loss: 8.004029\n",
            "Epoch [50/75] ğŸ” Loss: 6.175437\n",
            "Epoch [51/75] ğŸ” Loss: 3.828405\n",
            "Epoch [52/75] ğŸ” Loss: 6.033503\n",
            "Epoch [53/75] ğŸ” Loss: 5.446044\n",
            "Epoch [54/75] ğŸ” Loss: 4.426342\n",
            "Epoch [55/75] ğŸ” Loss: 5.557719\n",
            "Epoch [56/75] ğŸ” Loss: 4.651525\n",
            "Epoch [57/75] ğŸ” Loss: 3.869000\n",
            "Epoch [58/75] ğŸ” Loss: 3.745027\n",
            "Epoch [59/75] ğŸ” Loss: 3.681298\n",
            "Epoch [60/75] ğŸ” Loss: 3.445612\n",
            "Epoch [61/75] ğŸ” Loss: 3.978808\n",
            "Epoch [62/75] ğŸ” Loss: 4.818139\n",
            "Epoch [63/75] ğŸ” Loss: 3.094015\n",
            "Epoch [64/75] ğŸ” Loss: 2.778648\n",
            "Epoch [65/75] ğŸ” Loss: 4.173763\n",
            "Epoch [66/75] ğŸ” Loss: 2.457709\n",
            "Epoch [67/75] ğŸ” Loss: 1.850466\n",
            "Epoch [68/75] ğŸ” Loss: 3.768610\n",
            "Epoch [69/75] ğŸ” Loss: 2.744768\n",
            "Epoch [70/75] ğŸ” Loss: 2.273408\n",
            "Epoch [71/75] ğŸ” Loss: 1.645869\n",
            "Epoch [72/75] ğŸ” Loss: 2.599839\n",
            "Epoch [73/75] ğŸ” Loss: 2.432465\n",
            "Epoch [74/75] ğŸ” Loss: 2.327833\n",
            "Epoch [75/75] ğŸ” Loss: 1.299691\n",
            "{'Resolution': 224, 'Fold': 4, 'Epochs': 75, 'BatchSize': 18, 'LearningRate': 0.00018, 'Val_Precision': 0.7857142857142857, 'Val_Recall': 0.9361702127659575, 'Val_F1': 0.854368932038835, 'Val_Accuracy': 0.9635922330097088, 'Val_AUC': 0.9852521130865637, 'Val_TP': 44, 'Val_TN': 353, 'Val_FP': 12, 'Val_FN': 3}\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch [1/75] ğŸ” Loss: 38.919849\n",
            "Epoch [2/75] ğŸ” Loss: 33.337003\n",
            "Epoch [3/75] ğŸ” Loss: 32.939730\n",
            "Epoch [4/75] ğŸ” Loss: 31.489082\n",
            "Epoch [5/75] ğŸ” Loss: 31.106206\n",
            "Epoch [6/75] ğŸ” Loss: 31.150314\n",
            "Epoch [7/75] ğŸ” Loss: 29.729656\n",
            "Epoch [8/75] ğŸ” Loss: 28.831875\n",
            "Epoch [9/75] ğŸ” Loss: 29.050230\n",
            "Epoch [10/75] ğŸ” Loss: 27.804999\n",
            "Epoch [11/75] ğŸ” Loss: 27.914753\n",
            "Epoch [12/75] ğŸ” Loss: 27.113366\n",
            "Epoch [13/75] ğŸ” Loss: 26.376193\n",
            "Epoch [14/75] ğŸ” Loss: 25.928470\n",
            "Epoch [15/75] ğŸ” Loss: 26.757684\n",
            "Epoch [16/75] ğŸ” Loss: 24.299993\n",
            "Epoch [17/75] ğŸ” Loss: 22.939627\n",
            "Epoch [18/75] ğŸ” Loss: 24.507714\n",
            "Epoch [19/75] ğŸ” Loss: 22.708681\n",
            "Epoch [20/75] ğŸ” Loss: 22.188990\n",
            "Epoch [21/75] ğŸ” Loss: 22.347314\n",
            "Epoch [22/75] ğŸ” Loss: 20.215540\n",
            "Epoch [23/75] ğŸ” Loss: 19.198563\n",
            "Epoch [24/75] ğŸ” Loss: 18.416975\n",
            "Epoch [25/75] ğŸ” Loss: 17.753935\n",
            "Epoch [26/75] ğŸ” Loss: 16.771791\n",
            "Epoch [27/75] ğŸ” Loss: 15.644971\n",
            "Epoch [28/75] ğŸ” Loss: 12.192822\n",
            "Epoch [29/75] ğŸ” Loss: 12.349838\n",
            "Epoch [30/75] ğŸ” Loss: 10.755868\n",
            "Epoch [31/75] ğŸ” Loss: 11.316624\n",
            "Epoch [32/75] ğŸ” Loss: 7.194491\n",
            "Epoch [33/75] ğŸ” Loss: 7.752782\n",
            "Epoch [34/75] ğŸ” Loss: 7.604118\n",
            "Epoch [35/75] ğŸ” Loss: 7.165596\n",
            "Epoch [36/75] ğŸ” Loss: 8.452595\n",
            "Epoch [37/75] ğŸ” Loss: 7.136363\n",
            "Epoch [38/75] ğŸ” Loss: 5.916042\n",
            "Epoch [39/75] ğŸ” Loss: 5.201418\n",
            "Epoch [40/75] ğŸ” Loss: 7.447441\n",
            "Epoch [41/75] ğŸ” Loss: 5.121824\n",
            "Epoch [42/75] ğŸ” Loss: 3.463003\n",
            "Epoch [43/75] ğŸ” Loss: 4.502457\n",
            "Epoch [44/75] ğŸ” Loss: 2.680681\n",
            "Epoch [45/75] ğŸ” Loss: 3.718273\n",
            "Epoch [46/75] ğŸ” Loss: 4.132140\n",
            "Epoch [47/75] ğŸ” Loss: 4.379732\n",
            "Epoch [48/75] ğŸ” Loss: 3.083759\n",
            "Epoch [49/75] ğŸ” Loss: 3.797855\n",
            "Epoch [50/75] ğŸ” Loss: 1.745595\n",
            "Epoch [51/75] ğŸ” Loss: 5.225431\n",
            "Epoch [52/75] ğŸ” Loss: 2.197094\n",
            "Epoch [53/75] ğŸ” Loss: 2.271351\n",
            "Epoch [54/75] ğŸ” Loss: 2.697992\n",
            "Epoch [55/75] ğŸ” Loss: 2.813727\n",
            "Epoch [56/75] ğŸ” Loss: 4.118308\n",
            "Epoch [57/75] ğŸ” Loss: 3.080303\n",
            "Epoch [58/75] ğŸ” Loss: 1.824363\n",
            "Epoch [59/75] ğŸ” Loss: 1.337046\n",
            "Epoch [60/75] ğŸ” Loss: 1.276800\n",
            "Epoch [61/75] ğŸ” Loss: 2.538979\n",
            "Epoch [62/75] ğŸ” Loss: 3.188854\n",
            "Epoch [63/75] ğŸ” Loss: 2.575266\n",
            "Epoch [64/75] ğŸ” Loss: 2.644416\n",
            "Epoch [65/75] ğŸ” Loss: 0.997512\n",
            "Epoch [66/75] ğŸ” Loss: 2.523491\n",
            "Epoch [67/75] ğŸ” Loss: 1.680061\n",
            "Epoch [68/75] ğŸ” Loss: 0.978286\n",
            "Epoch [69/75] ğŸ” Loss: 2.553475\n",
            "Epoch [70/75] ğŸ” Loss: 1.447968\n",
            "Epoch [71/75] ğŸ” Loss: 1.737687\n",
            "Epoch [72/75] ğŸ” Loss: 1.266792\n",
            "Epoch [73/75] ğŸ” Loss: 1.675776\n",
            "Epoch [74/75] ğŸ” Loss: 0.282200\n",
            "Epoch [75/75] ğŸ” Loss: 0.454869\n",
            "{'Resolution': 224, 'Fold': 5, 'Epochs': 75, 'BatchSize': 18, 'LearningRate': 0.00018, 'Val_Precision': 0.9714285714285714, 'Val_Recall': 0.723404255319149, 'Val_F1': 0.8292682926829269, 'Val_Accuracy': 0.9659367396593674, 'Val_AUC': 0.9837502922609307, 'Val_TP': 34, 'Val_TN': 363, 'Val_FP': 1, 'Val_FN': 13}\n",
            "âœ… Best fold = 3\n",
            "\n",
            "ğŸ“Š TEST (best-fold model) Results\n",
            "Precision: 0.9333, Recall: 1.0000, F1: 0.9655\n",
            "Accuracy:  0.9925, AUC: 0.9997\n",
            "\n",
            "âœ… Hexa-eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# GLOBAL CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "\n",
        "N_SPLITS = 5\n",
        "RESOLUTIONS = [224]\n",
        "EPOCHS_CV = 75\n",
        "BATCH_CV = 18\n",
        "LR_CV = 0.00018\n",
        "\n",
        "# =========================\n",
        "# DEVICE + DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"hexa-eye_hb_90_repro_bestfold_only_with_age_days\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "# Define directories\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS: base id handling and hexa intersections\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    if not fname.endswith(suffix):\n",
        "        return None\n",
        "    return fname[: -len(suffix)]\n",
        "\n",
        "def common_bases_across_six(dirs_map):\n",
        "    suffixes = {\n",
        "        'left1': '_left_eye_1.png',\n",
        "        'left2': '_left_eye_2.png',\n",
        "        'left3': '_left_eye_3.png',\n",
        "        'right1': '_right_eye_1.png',\n",
        "        'right2': '_right_eye_2.png',\n",
        "        'right3': '_right_eye_3.png',\n",
        "    }\n",
        "    bases_sets = []\n",
        "    for k in ['left1','left2','left3','right1','right2','right3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            print(f\"âš ï¸ Folder missing: {folder}\")\n",
        "            return []\n",
        "        names = sorted([f for f in os.listdir(folder) if f.endswith(suffixes[k])])\n",
        "        bases = set()\n",
        "        for f in names:\n",
        "            b = base_from(f, suffixes[k])\n",
        "            if b:\n",
        "                bases.add(b)\n",
        "        bases_sets.append(bases)\n",
        "    common = set.intersection(*bases_sets) if bases_sets else set()\n",
        "    return sorted(list(common))\n",
        "\n",
        "def load_hexa_images_by_bases(dirs_map, bases):\n",
        "    out = {'l1': [], 'l2': [], 'l3': [], 'r1': [], 'r2': [], 'r3': []}\n",
        "    key_map = {\n",
        "        'l1': ('left1',  '_left_eye_1.png'),\n",
        "        'l2': ('left2',  '_left_eye_2.png'),\n",
        "        'l3': ('left3',  '_left_eye_3.png'),\n",
        "        'r1': ('right1', '_right_eye_1.png'),\n",
        "        'r2': ('right2', '_right_eye_2.png'),\n",
        "        'r3': ('right3', '_right_eye_3.png'),\n",
        "    }\n",
        "    ok = 0\n",
        "    for b in bases:\n",
        "        imgs = {}\n",
        "        failed = False\n",
        "        for short_k, (long_k, suf) in key_map.items():\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[short_k] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if failed:\n",
        "            continue\n",
        "        for k in out.keys():\n",
        "            out[k].append(imgs[k])\n",
        "        ok += 1\n",
        "    return out, ok\n",
        "\n",
        "def prepare_dataset_strict(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_anemic = common_bases_across_six(anemic_dirs)\n",
        "    bases_non = common_bases_across_six(non_dirs)\n",
        "    print(f\"\\nğŸ” {split_name} - discovered bases: anemic={len(bases_anemic)}, non-anemic={len(bases_non)}\")\n",
        "\n",
        "    imgs_a, _ = load_hexa_images_by_bases(anemic_dirs, bases_anemic)\n",
        "    imgs_n, _ = load_hexa_images_by_bases(non_dirs,  bases_non)\n",
        "\n",
        "    data = {\n",
        "        'l1': imgs_a['l1'] + imgs_n['l1'],\n",
        "        'l2': imgs_a['l2'] + imgs_n['l2'],\n",
        "        'l3': imgs_a['l3'] + imgs_n['l3'],\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'label': [1]*len(imgs_a['l1']) + [0]*len(imgs_n['l1']),\n",
        "        'base_ids': bases_anemic + bases_non  # âœ… Store base IDs\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… {split_name}: hexa-matched samples -> anemic={len(imgs_a['l1'])}, non-anemic={len(imgs_n['l1'])}, total={len(data['label'])}\")\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# LOAD DATAFRAME WITH AGE, DAYS, AND LIGHTING\n",
        "# =========================\n",
        "df = pd.read_csv(\"/home/ubuntu/anemia-storage/hb_mobilenet/dataset_imputed.csv\")\n",
        "\n",
        "# âœ… Fix: Extract base_id from filename like 'cr4n1a07ch0lnecm8a3g_right_eye_1.png' â†’ 'cr4n1a07ch0lnecm8a3g'\n",
        "def extract_base_id(filename):\n",
        "    for suffix in ['_right_eye_1.png', '_right_eye_2.png', '_right_eye_3.png',\n",
        "                   '_left_eye_1.png', '_left_eye_2.png', '_left_eye_3.png']:\n",
        "        if filename.endswith(suffix):\n",
        "            return filename[:-len(suffix)]\n",
        "    return filename\n",
        "\n",
        "# âœ… Create feature_map using clean base_id\n",
        "feature_map = {}\n",
        "for _, row in df.iterrows():\n",
        "    raw_id = row['right_eye_1']  # Use any image column\n",
        "    base_id = extract_base_id(raw_id)\n",
        "    age = float(row['age_at_registration_final'])\n",
        "    days = float(row['days_since_lmp_final'])\n",
        "    rl1 = float(row['right_eye_1_light'])\n",
        "    ll1 = float(row['left_eye_1_light'])\n",
        "    rl2 = float(row['right_eye_2_light'])\n",
        "    ll2 = float(row['left_eye_2_light'])\n",
        "    rl3 = float(row['right_eye_3_light'])\n",
        "    ll3 = float(row['left_eye_3_light'])\n",
        "\n",
        "    feature_map[base_id] = [age, days, rl1, ll1, rl2, ll2, rl3, ll3]\n",
        "\n",
        "# =========================\n",
        "# DATASET / DATALOADER\n",
        "# =========================\n",
        "class HexaEyeDatasetWithFeatures(Dataset):\n",
        "    def __init__(self, data, transform, feature_map):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.feature_map = feature_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[k][idx] for k in ['l1','l2','l3','r1','r2','r3']]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        base_id = self.data['base_ids'][idx]\n",
        "        features = self.feature_map.get(base_id, [0.0]*8)\n",
        "        return images, label, torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type == 'cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL (6x ResNet18 + MLP head + Feature Fusion)\n",
        "# =========================\n",
        "class HexaResNetWithFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def res():\n",
        "            m = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "            m.fc = nn.Identity()\n",
        "            return m\n",
        "        self.models = nn.ModuleList([res() for _ in range(6)])\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(6*512, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        self.feature_fc = nn.Sequential(\n",
        "            nn.Linear(8, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        self.final_fc = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, *x, features=None):\n",
        "        feats = [model(xi) for model, xi in zip(self.models, x)]\n",
        "        x_img = torch.cat(feats, dim=1)\n",
        "        x_img = self.fc(x_img)\n",
        "        x_feat = self.feature_fc(features)\n",
        "        x = torch.cat([x_img, x_feat], dim=1)\n",
        "        return self.final_fc(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    for imgs, labels, features in loader:\n",
        "        imgs = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        features = features.to(device).float()\n",
        "        out = model(*imgs, features=features)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        p = r = f1 = auc = float('nan')\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        tn = fp = fn = tp = 0\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "# =========================\n",
        "# PREPARE DATASETS\n",
        "# =========================\n",
        "train_data = prepare_dataset_strict(train_dirs_anemic, train_dirs_non, \"TRAIN\")\n",
        "val_data = prepare_dataset_strict(val_dirs_anemic, val_dirs_non, \"VAL\")\n",
        "test_data = prepare_dataset_strict(test_dirs_anemic, test_dirs_non, \"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No hexa-matched TRAIN samples found. Check paths/filenames.\")\n",
        "if len(val_data['label']) == 0:\n",
        "    print(\"âš ï¸ No hexa-matched VAL samples found.\")\n",
        "if len(test_data['label']) == 0:\n",
        "    print(\"âš ï¸ No hexa-matched TEST samples found.\")\n",
        "\n",
        "# =========================\n",
        "# 5-FOLD CV\n",
        "# =========================\n",
        "results = []\n",
        "\n",
        "for resolution in RESOLUTIONS:\n",
        "    print(f\"\\n===== Processing resolution: {resolution} =====\")\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    if len(train_data['label']) < N_SPLITS:\n",
        "        raise RuntimeError(f\"Too few train samples for {N_SPLITS}-fold CV.\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(train_data['label'])\n",
        "    fold = 1\n",
        "    cv_index_records = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        cv_index_records.append({\n",
        "            \"fold\": fold,\n",
        "            \"train_indices\": train_idx.tolist(),\n",
        "            \"val_indices\": val_idx.tolist()\n",
        "        })\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in train_data.items()}\n",
        "        val_subset = {k: [v[i] for i in val_idx] for k, v in train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(HexaEyeDatasetWithFeatures(train_subset, train_tf, feature_map), batch_size=BATCH_CV, shuffle=True)\n",
        "        val_loader = make_loader(HexaEyeDatasetWithFeatures(val_subset, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "\n",
        "        model = HexaResNetWithFeatures().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels, features in train_loader:\n",
        "                imgs = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                features = features.to(device).float()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(*imgs, features=features)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] ğŸ” Loss: {total_loss:.6f}\")\n",
        "\n",
        "        val_metrics = evaluate(model, val_loader)\n",
        "        row = {\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Epochs': EPOCHS_CV,\n",
        "            'BatchSize': BATCH_CV,\n",
        "            'LearningRate': LR_CV,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8]\n",
        "        }\n",
        "        results.append(row)\n",
        "        print(row)\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({\n",
        "                'model_state': model.state_dict(),\n",
        "                'seed': SEED,\n",
        "                'resolution': resolution\n",
        "            }, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save results\n",
        "    if results:\n",
        "        pd.DataFrame(results).to_csv(os.path.join(output_dir, f\"{resolution}_val_cross_validation_results_hexa.csv\"), index=False)\n",
        "    pd.DataFrame(cv_index_records).to_json(os.path.join(output_dir, f\"{resolution}_cv_indices.json\"), orient='records', indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df['min_PR'] = results_df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = results_df[(results_df['Val_Precision'] >= 0.90) & (results_df['Val_Recall'] >= 0.90)]\n",
        "    best = candidates.sort_values(['Val_F1','Val_AUC','min_PR'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "            results_df.sort_values(['min_PR','Val_F1','Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # âœ… Load best fold model for test evaluation\n",
        "    best_model = HexaResNetWithFeatures().to(device)\n",
        "    best_model_path = os.path.join(output_dir, f\"cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    state = torch.load(best_model_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Evaluate on TEST using best fold\n",
        "    if len(test_data['label']) > 0:\n",
        "        test_loader = make_loader(HexaEyeDatasetWithFeatures(test_data, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "        test_metrics = evaluate(best_model, test_loader)\n",
        "        print(\"\\nğŸ“Š TEST (best-fold model) Results\")\n",
        "        print(f\"Precision: {test_metrics[0]:.4f}, Recall: {test_metrics[1]:.4f}, F1: {test_metrics[2]:.4f}\")\n",
        "        print(f\"Accuracy:  {test_metrics[3]:.4f}, AUC: {test_metrics[4]:.4f}\")\n",
        "\n",
        "        pd.DataFrame([{\n",
        "            'ChosenFold': best_fold,\n",
        "            'Test_Precision': test_metrics[0], 'Test_Recall': test_metrics[1], 'Test_F1': test_metrics[2],\n",
        "            'Test_Accuracy': test_metrics[3], 'Test_AUC': test_metrics[4], 'Test_TP': test_metrics[5],\n",
        "            'Test_TN': test_metrics[6], 'Test_FP': test_metrics[7], 'Test_FN': test_metrics[8]\n",
        "        }]).to_csv(os.path.join(output_dir, f\"{resolution}_bestfold_test_results_hexa.csv\"), index=False)\n",
        "\n",
        "print(\"\\nâœ… Hexa-eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26aca7b5-0ce1-4843-87bb-34ffe3c12cca",
      "metadata": {
        "id": "26aca7b5-0ce1-4843-87bb-34ffe3c12cca",
        "outputId": "efd5e804-55da-449f-cde5-fc9eabb77b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Feature Map Created: True\n",
            "  â¤ Number of base IDs in feature_map: 3025\n",
            "  â¤ Sample features for 'cr4n1a07ch0lnecm8a3g': [28.0, 240.0, 317.99252, 337.02753, 382.99503, 407.97, 382.99503, 330.0075]\n",
            "  â¤ Number of features: 8\n",
            "\n",
            "âœ… Model Structure:\n",
            "  â¤ Input features size: 8\n",
            "  â¤ Output features size: 32\n",
            "Sample base_id: cr4n1a07ch0lnecm8a3g\n",
            "Available in train base_ids? True\n",
            "Features: [28.0, 240.0, 317.99252, 337.02753, 382.99503, 407.97, 382.99503, 330.0075]\n"
          ]
        }
      ],
      "source": [
        "# ğŸ” Check if additional features were loaded and used\n",
        "\n",
        "# Step 1: Verify feature_map is created\n",
        "print(\"âœ… Feature Map Created:\", 'feature_map' in locals())\n",
        "if 'feature_map' in locals():\n",
        "    print(f\"  â¤ Number of base IDs in feature_map: {len(feature_map)}\")\n",
        "    # Sample one entry\n",
        "    sample_base = list(feature_map.keys())[0]\n",
        "    sample_features = feature_map[sample_base]\n",
        "    print(f\"  â¤ Sample features for '{sample_base}': {sample_features}\")\n",
        "    print(f\"  â¤ Number of features: {len(sample_features)}\")\n",
        "\n",
        "# Step 2: Verify model structure accepts 8 features\n",
        "model = HexaResNetWithFeatures()\n",
        "print(\"\\nâœ… Model Structure:\")\n",
        "print(\"  â¤ Input features size:\", model.feature_fc[0].in_features)  # Should be 8\n",
        "print(\"  â¤ Output features size:\", model.feature_fc[-1].out_features)  # Should be 32\n",
        "\n",
        "# After fixing feature_map\n",
        "sample_base = list(feature_map.keys())[0]\n",
        "print(\"Sample base_id:\", sample_base)\n",
        "print(\"Available in train base_ids?\", sample_base in train_data['base_ids'])\n",
        "print(\"Features:\", feature_map[sample_base])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be2a519-514d-4455-836b-9245390b7291",
      "metadata": {
        "id": "0be2a519-514d-4455-836b-9245390b7291",
        "outputId": "64669dd4-66fc-4450-9929-de18847b72ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ğŸ” TRAIN - discovered bases: anemic=248, non-anemic=1907\n",
            "âœ… TRAIN: tri-matched samples -> anemic=248, non-anemic=1907, total=2155\n",
            "\n",
            "ğŸ” VAL - discovered bases: anemic=37, non-anemic=298\n",
            "âœ… VAL: tri-matched samples -> anemic=37, non-anemic=298, total=335\n",
            "\n",
            "ğŸ” TEST - discovered bases: anemic=34, non-anemic=284\n",
            "âœ… TEST: tri-matched samples -> anemic=34, non-anemic=284, total=318\n",
            "\n",
            "===== Processing resolution: 224 =====\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch [1/120] ğŸ” Loss: 30.467892\n",
            "Epoch [2/120] ğŸ” Loss: 26.470141\n",
            "Epoch [3/120] ğŸ” Loss: 26.170041\n",
            "Epoch [4/120] ğŸ” Loss: 25.320405\n",
            "Epoch [5/120] ğŸ” Loss: 25.367928\n",
            "Epoch [6/120] ğŸ” Loss: 25.166305\n",
            "Epoch [7/120] ğŸ” Loss: 25.139764\n",
            "Epoch [8/120] ğŸ” Loss: 25.038733\n",
            "Epoch [9/120] ğŸ” Loss: 24.174090\n",
            "Epoch [10/120] ğŸ” Loss: 25.039787\n",
            "Epoch [11/120] ğŸ” Loss: 24.684445\n",
            "Epoch [12/120] ğŸ” Loss: 24.603830\n",
            "Epoch [13/120] ğŸ” Loss: 23.980597\n",
            "Epoch [14/120] ğŸ” Loss: 24.086990\n",
            "Epoch [15/120] ğŸ” Loss: 23.292998\n",
            "Epoch [16/120] ğŸ” Loss: 23.676232\n",
            "Epoch [17/120] ğŸ” Loss: 22.856503\n",
            "Epoch [18/120] ğŸ” Loss: 23.069232\n",
            "Epoch [19/120] ğŸ” Loss: 22.592322\n",
            "Epoch [20/120] ğŸ” Loss: 22.240876\n",
            "Epoch [21/120] ğŸ” Loss: 21.870902\n",
            "Epoch [22/120] ğŸ” Loss: 21.667036\n",
            "Epoch [23/120] ğŸ” Loss: 21.470469\n",
            "Epoch [24/120] ğŸ” Loss: 21.981337\n",
            "Epoch [25/120] ğŸ” Loss: 19.744502\n",
            "Epoch [26/120] ğŸ” Loss: 20.488942\n",
            "Epoch [27/120] ğŸ” Loss: 19.318941\n",
            "Epoch [28/120] ğŸ” Loss: 18.942559\n",
            "Epoch [29/120] ğŸ” Loss: 17.617197\n",
            "Epoch [30/120] ğŸ” Loss: 18.204886\n",
            "Epoch [31/120] ğŸ” Loss: 16.742885\n",
            "Epoch [32/120] ğŸ” Loss: 16.940072\n",
            "Epoch [33/120] ğŸ” Loss: 15.389698\n",
            "Epoch [34/120] ğŸ” Loss: 14.868252\n",
            "Epoch [35/120] ğŸ” Loss: 13.655317\n",
            "Epoch [36/120] ğŸ” Loss: 13.444221\n",
            "Epoch [37/120] ğŸ” Loss: 12.417711\n",
            "Epoch [38/120] ğŸ” Loss: 11.091848\n",
            "Epoch [39/120] ğŸ” Loss: 11.359104\n",
            "Epoch [40/120] ğŸ” Loss: 10.747563\n",
            "Epoch [41/120] ğŸ” Loss: 8.826570\n",
            "Epoch [42/120] ğŸ” Loss: 9.491115\n",
            "Epoch [43/120] ğŸ” Loss: 9.089085\n",
            "Epoch [44/120] ğŸ” Loss: 7.606877\n",
            "Epoch [45/120] ğŸ” Loss: 7.989624\n",
            "Epoch [46/120] ğŸ” Loss: 7.082181\n",
            "Epoch [47/120] ğŸ” Loss: 7.210470\n",
            "Epoch [48/120] ğŸ” Loss: 5.891651\n",
            "Epoch [49/120] ğŸ” Loss: 5.733749\n",
            "Epoch [50/120] ğŸ” Loss: 5.126610\n",
            "Epoch [51/120] ğŸ” Loss: 4.140166\n",
            "Epoch [52/120] ğŸ” Loss: 4.820559\n",
            "Epoch [53/120] ğŸ” Loss: 5.278590\n",
            "Epoch [54/120] ğŸ” Loss: 3.656020\n",
            "Epoch [55/120] ğŸ” Loss: 3.008542\n",
            "Epoch [56/120] ğŸ” Loss: 2.681805\n",
            "Epoch [57/120] ğŸ” Loss: 2.761911\n",
            "Epoch [58/120] ğŸ” Loss: 2.465631\n",
            "Epoch [59/120] ğŸ” Loss: 3.126606\n",
            "Epoch [60/120] ğŸ” Loss: 3.216768\n",
            "Epoch [61/120] ğŸ” Loss: 2.073404\n",
            "Epoch [62/120] ğŸ” Loss: 2.030723\n",
            "Epoch [63/120] ğŸ” Loss: 2.227364\n",
            "Epoch [64/120] ğŸ” Loss: 1.551955\n",
            "Epoch [65/120] ğŸ” Loss: 2.046891\n",
            "Epoch [66/120] ğŸ” Loss: 1.165214\n",
            "Epoch [67/120] ğŸ” Loss: 1.064464\n",
            "Epoch [68/120] ğŸ” Loss: 2.111931\n",
            "Epoch [69/120] ğŸ” Loss: 2.388997\n",
            "Epoch [70/120] ğŸ” Loss: 1.383911\n",
            "Epoch [71/120] ğŸ” Loss: 1.947851\n",
            "Epoch [72/120] ğŸ” Loss: 1.049704\n",
            "Epoch [73/120] ğŸ” Loss: 1.587405\n",
            "Epoch [74/120] ğŸ” Loss: 1.084127\n",
            "Epoch [75/120] ğŸ” Loss: 2.265353\n",
            "Epoch [76/120] ğŸ” Loss: 1.485285\n",
            "Epoch [77/120] ğŸ” Loss: 1.067622\n",
            "Epoch [78/120] ğŸ” Loss: 1.581402\n",
            "Epoch [79/120] ğŸ” Loss: 1.530178\n",
            "Epoch [80/120] ğŸ” Loss: 1.150602\n",
            "Epoch [81/120] ğŸ” Loss: 0.299648\n",
            "Epoch [82/120] ğŸ” Loss: 0.447129\n",
            "Epoch [83/120] ğŸ” Loss: 0.796929\n",
            "Epoch [84/120] ğŸ” Loss: 0.285297\n",
            "Epoch [85/120] ğŸ” Loss: 0.784258\n",
            "Epoch [86/120] ğŸ” Loss: 1.921160\n",
            "Epoch [87/120] ğŸ” Loss: 1.386542\n",
            "Epoch [88/120] ğŸ” Loss: 0.808507\n",
            "Epoch [89/120] ğŸ” Loss: 0.511732\n",
            "Epoch [90/120] ğŸ” Loss: 1.130791\n",
            "Epoch [91/120] ğŸ” Loss: 1.240484\n",
            "Epoch [92/120] ğŸ” Loss: 0.631279\n",
            "Epoch [93/120] ğŸ” Loss: 0.620667\n",
            "Epoch [94/120] ğŸ” Loss: 1.061779\n",
            "Epoch [95/120] ğŸ” Loss: 1.091510\n",
            "Epoch [96/120] ğŸ” Loss: 0.655110\n",
            "Epoch [97/120] ğŸ” Loss: 0.405721\n",
            "Epoch [98/120] ğŸ” Loss: 1.586737\n",
            "Epoch [99/120] ğŸ” Loss: 1.275026\n",
            "Epoch [100/120] ğŸ” Loss: 0.493718\n",
            "Epoch [101/120] ğŸ” Loss: 1.203313\n",
            "Epoch [102/120] ğŸ” Loss: 1.393335\n",
            "Epoch [103/120] ğŸ” Loss: 0.580626\n",
            "Epoch [104/120] ğŸ” Loss: 0.626323\n",
            "Epoch [105/120] ğŸ” Loss: 0.691787\n",
            "Epoch [106/120] ğŸ” Loss: 0.699700\n",
            "Epoch [107/120] ğŸ” Loss: 0.395982\n",
            "Epoch [108/120] ğŸ” Loss: 0.309218\n",
            "Epoch [109/120] ğŸ” Loss: 0.083552\n",
            "Epoch [110/120] ğŸ” Loss: 0.439694\n",
            "Epoch [111/120] ğŸ” Loss: 2.303999\n",
            "Epoch [112/120] ğŸ” Loss: 1.363679\n",
            "Epoch [113/120] ğŸ” Loss: 0.180062\n",
            "Epoch [114/120] ğŸ” Loss: 0.959829\n",
            "Epoch [115/120] ğŸ” Loss: 1.300541\n",
            "Epoch [116/120] ğŸ” Loss: 0.626738\n",
            "Epoch [117/120] ğŸ” Loss: 0.813046\n",
            "Epoch [118/120] ğŸ” Loss: 0.331864\n",
            "Epoch [119/120] ğŸ” Loss: 0.520554\n",
            "Epoch [120/120] ğŸ” Loss: 0.730294\n",
            "{'Resolution': 224, 'Fold': 1, 'Epochs': 120, 'BatchSize': 24, 'LearningRate': 0.00022, 'Val_Precision': 0.8809523809523809, 'Val_Recall': 0.74, 'Val_F1': 0.8043478260869565, 'Val_Accuracy': 0.9582366589327146, 'Val_AUC': 0.9678215223097113, 'Val_TP': 37, 'Val_TN': 376, 'Val_FP': 5, 'Val_FN': 13}\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch [1/120] ğŸ” Loss: 28.229245\n",
            "Epoch [2/120] ğŸ” Loss: 26.042512\n",
            "Epoch [3/120] ğŸ” Loss: 25.321094\n",
            "Epoch [4/120] ğŸ” Loss: 24.821446\n",
            "Epoch [5/120] ğŸ” Loss: 24.987166\n",
            "Epoch [6/120] ğŸ” Loss: 24.153192\n",
            "Epoch [7/120] ğŸ” Loss: 23.674627\n",
            "Epoch [8/120] ğŸ” Loss: 23.542511\n",
            "Epoch [9/120] ğŸ” Loss: 23.279313\n",
            "Epoch [10/120] ğŸ” Loss: 23.133218\n",
            "Epoch [11/120] ğŸ” Loss: 22.954563\n",
            "Epoch [12/120] ğŸ” Loss: 22.417463\n",
            "Epoch [13/120] ğŸ” Loss: 22.424786\n",
            "Epoch [14/120] ğŸ” Loss: 22.203368\n",
            "Epoch [15/120] ğŸ” Loss: 21.790281\n",
            "Epoch [16/120] ğŸ” Loss: 22.024892\n",
            "Epoch [17/120] ğŸ” Loss: 21.777519\n",
            "Epoch [18/120] ğŸ” Loss: 20.786674\n",
            "Epoch [19/120] ğŸ” Loss: 20.676486\n",
            "Epoch [20/120] ğŸ” Loss: 21.307955\n",
            "Epoch [21/120] ğŸ” Loss: 20.622752\n",
            "Epoch [22/120] ğŸ” Loss: 21.817542\n",
            "Epoch [23/120] ğŸ” Loss: 19.574364\n",
            "Epoch [24/120] ğŸ” Loss: 19.949481\n",
            "Epoch [25/120] ğŸ” Loss: 18.436931\n",
            "Epoch [26/120] ğŸ” Loss: 16.925883\n",
            "Epoch [27/120] ğŸ” Loss: 16.675871\n",
            "Epoch [28/120] ğŸ” Loss: 14.810593\n",
            "Epoch [29/120] ğŸ” Loss: 15.184296\n",
            "Epoch [30/120] ğŸ” Loss: 13.591928\n",
            "Epoch [31/120] ğŸ” Loss: 12.521530\n",
            "Epoch [32/120] ğŸ” Loss: 10.093992\n",
            "Epoch [33/120] ğŸ” Loss: 8.813195\n",
            "Epoch [34/120] ğŸ” Loss: 9.357655\n",
            "Epoch [35/120] ğŸ” Loss: 7.338239\n",
            "Epoch [36/120] ğŸ” Loss: 6.397836\n",
            "Epoch [37/120] ğŸ” Loss: 5.653868\n",
            "Epoch [38/120] ğŸ” Loss: 5.657982\n",
            "Epoch [39/120] ğŸ” Loss: 4.820300\n",
            "Epoch [40/120] ğŸ” Loss: 3.841061\n",
            "Epoch [41/120] ğŸ” Loss: 4.785166\n",
            "Epoch [42/120] ğŸ” Loss: 4.332122\n",
            "Epoch [43/120] ğŸ” Loss: 2.385782\n",
            "Epoch [44/120] ğŸ” Loss: 2.628830\n",
            "Epoch [45/120] ğŸ” Loss: 2.751201\n",
            "Epoch [46/120] ğŸ” Loss: 2.529605\n",
            "Epoch [47/120] ğŸ” Loss: 2.438130\n",
            "Epoch [48/120] ğŸ” Loss: 2.283697\n",
            "Epoch [49/120] ğŸ” Loss: 2.897841\n",
            "Epoch [50/120] ğŸ” Loss: 2.028793\n",
            "Epoch [51/120] ğŸ” Loss: 1.063389\n",
            "Epoch [52/120] ğŸ” Loss: 1.926150\n",
            "Epoch [53/120] ğŸ” Loss: 3.184055\n",
            "Epoch [54/120] ğŸ” Loss: 2.527414\n",
            "Epoch [55/120] ğŸ” Loss: 1.566657\n",
            "Epoch [56/120] ğŸ” Loss: 2.214941\n",
            "Epoch [57/120] ğŸ” Loss: 1.196046\n",
            "Epoch [58/120] ğŸ” Loss: 1.497810\n",
            "Epoch [59/120] ğŸ” Loss: 1.317894\n",
            "Epoch [60/120] ğŸ” Loss: 1.739175\n",
            "Epoch [61/120] ğŸ” Loss: 1.092567\n",
            "Epoch [62/120] ğŸ” Loss: 0.708402\n",
            "Epoch [63/120] ğŸ” Loss: 2.486549\n",
            "Epoch [64/120] ğŸ” Loss: 1.184014\n",
            "Epoch [65/120] ğŸ” Loss: 1.501685\n",
            "Epoch [66/120] ğŸ” Loss: 0.922658\n",
            "Epoch [67/120] ğŸ” Loss: 0.862038\n",
            "Epoch [68/120] ğŸ” Loss: 0.515447\n",
            "Epoch [69/120] ğŸ” Loss: 1.515697\n",
            "Epoch [70/120] ğŸ” Loss: 0.993433\n",
            "Epoch [71/120] ğŸ” Loss: 1.181053\n",
            "Epoch [72/120] ğŸ” Loss: 1.976517\n",
            "Epoch [73/120] ğŸ” Loss: 0.885808\n",
            "Epoch [74/120] ğŸ” Loss: 0.861984\n",
            "Epoch [75/120] ğŸ” Loss: 0.525682\n",
            "Epoch [76/120] ğŸ” Loss: 0.695556\n",
            "Epoch [77/120] ğŸ” Loss: 0.439465\n",
            "Epoch [78/120] ğŸ” Loss: 0.721045\n",
            "Epoch [79/120] ğŸ” Loss: 1.153513\n",
            "Epoch [80/120] ğŸ” Loss: 1.080552\n",
            "Epoch [81/120] ğŸ” Loss: 0.809137\n",
            "Epoch [82/120] ğŸ” Loss: 1.335697\n",
            "Epoch [83/120] ğŸ” Loss: 0.412928\n",
            "Epoch [84/120] ğŸ” Loss: 1.217598\n",
            "Epoch [85/120] ğŸ” Loss: 0.292745\n",
            "Epoch [86/120] ğŸ” Loss: 0.542263\n",
            "Epoch [87/120] ğŸ” Loss: 0.693522\n",
            "Epoch [88/120] ğŸ” Loss: 0.336650\n",
            "Epoch [89/120] ğŸ” Loss: 0.175744\n",
            "Epoch [90/120] ğŸ” Loss: 0.676761\n",
            "Epoch [91/120] ğŸ” Loss: 0.932309\n",
            "Epoch [92/120] ğŸ” Loss: 0.811590\n",
            "Epoch [93/120] ğŸ” Loss: 0.376629\n",
            "Epoch [94/120] ğŸ” Loss: 0.517763\n",
            "Epoch [95/120] ğŸ” Loss: 0.328541\n",
            "Epoch [96/120] ğŸ” Loss: 0.364362\n",
            "Epoch [97/120] ğŸ” Loss: 0.435786\n",
            "Epoch [98/120] ğŸ” Loss: 0.764942\n",
            "Epoch [99/120] ğŸ” Loss: 1.147356\n",
            "Epoch [100/120] ğŸ” Loss: 0.543718\n",
            "Epoch [101/120] ğŸ” Loss: 1.155026\n",
            "Epoch [102/120] ğŸ” Loss: 0.588806\n",
            "Epoch [103/120] ğŸ” Loss: 1.289752\n",
            "Epoch [104/120] ğŸ” Loss: 0.977036\n",
            "Epoch [105/120] ğŸ” Loss: 0.238222\n",
            "Epoch [106/120] ğŸ” Loss: 0.311507\n",
            "Epoch [107/120] ğŸ” Loss: 0.076053\n",
            "Epoch [108/120] ğŸ” Loss: 0.063750\n",
            "Epoch [109/120] ğŸ” Loss: 0.058456\n",
            "Epoch [110/120] ğŸ” Loss: 0.046931\n",
            "Epoch [111/120] ğŸ” Loss: 0.297219\n",
            "Epoch [112/120] ğŸ” Loss: 1.326797\n",
            "Epoch [113/120] ğŸ” Loss: 1.149347\n",
            "Epoch [114/120] ğŸ” Loss: 0.669452\n",
            "Epoch [115/120] ğŸ” Loss: 0.370460\n",
            "Epoch [116/120] ğŸ” Loss: 0.416207\n",
            "Epoch [117/120] ğŸ” Loss: 0.211540\n",
            "Epoch [118/120] ğŸ” Loss: 0.372411\n",
            "Epoch [119/120] ğŸ” Loss: 0.582419\n",
            "Epoch [120/120] ğŸ” Loss: 0.734198\n",
            "{'Resolution': 224, 'Fold': 2, 'Epochs': 120, 'BatchSize': 24, 'LearningRate': 0.00022, 'Val_Precision': 0.8490566037735849, 'Val_Recall': 0.9, 'Val_F1': 0.8737864077669903, 'Val_Accuracy': 0.9698375870069605, 'Val_AUC': 0.993228346456693, 'Val_TP': 45, 'Val_TN': 373, 'Val_FP': 8, 'Val_FN': 5}\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch [1/120] ğŸ” Loss: 30.934542\n",
            "Epoch [2/120] ğŸ” Loss: 26.077380\n",
            "Epoch [3/120] ğŸ” Loss: 26.377665\n",
            "Epoch [4/120] ğŸ” Loss: 25.226786\n",
            "Epoch [5/120] ğŸ” Loss: 24.981192\n",
            "Epoch [6/120] ğŸ” Loss: 25.279321\n",
            "Epoch [7/120] ğŸ” Loss: 24.369232\n",
            "Epoch [8/120] ğŸ” Loss: 23.975272\n",
            "Epoch [9/120] ğŸ” Loss: 24.127276\n",
            "Epoch [10/120] ğŸ” Loss: 24.027474\n",
            "Epoch [11/120] ğŸ” Loss: 23.716389\n",
            "Epoch [12/120] ğŸ” Loss: 23.343433\n",
            "Epoch [13/120] ğŸ” Loss: 23.107424\n",
            "Epoch [14/120] ğŸ” Loss: 22.834179\n",
            "Epoch [15/120] ğŸ” Loss: 22.615190\n",
            "Epoch [16/120] ğŸ” Loss: 21.921927\n",
            "Epoch [17/120] ğŸ” Loss: 22.284803\n",
            "Epoch [18/120] ğŸ” Loss: 21.518758\n",
            "Epoch [19/120] ğŸ” Loss: 20.781218\n",
            "Epoch [20/120] ğŸ” Loss: 21.477874\n",
            "Epoch [21/120] ğŸ” Loss: 20.530033\n",
            "Epoch [22/120] ğŸ” Loss: 19.988872\n",
            "Epoch [23/120] ğŸ” Loss: 20.173358\n",
            "Epoch [24/120] ğŸ” Loss: 19.977903\n",
            "Epoch [25/120] ğŸ” Loss: 18.828377\n",
            "Epoch [26/120] ğŸ” Loss: 17.627481\n",
            "Epoch [27/120] ğŸ” Loss: 16.862333\n",
            "Epoch [28/120] ğŸ” Loss: 17.935814\n",
            "Epoch [29/120] ğŸ” Loss: 16.880403\n",
            "Epoch [30/120] ğŸ” Loss: 16.436257\n",
            "Epoch [31/120] ğŸ” Loss: 15.920193\n",
            "Epoch [32/120] ğŸ” Loss: 12.988005\n",
            "Epoch [33/120] ğŸ” Loss: 14.450571\n",
            "Epoch [34/120] ğŸ” Loss: 12.295111\n",
            "Epoch [35/120] ğŸ” Loss: 9.981390\n",
            "Epoch [36/120] ğŸ” Loss: 10.151816\n",
            "Epoch [37/120] ğŸ” Loss: 8.221704\n",
            "Epoch [38/120] ğŸ” Loss: 8.654243\n",
            "Epoch [39/120] ğŸ” Loss: 7.632426\n",
            "Epoch [40/120] ğŸ” Loss: 7.376749\n",
            "Epoch [41/120] ğŸ” Loss: 5.750814\n",
            "Epoch [42/120] ğŸ” Loss: 6.379474\n",
            "Epoch [43/120] ğŸ” Loss: 4.964894\n",
            "Epoch [44/120] ğŸ” Loss: 5.848001\n",
            "Epoch [45/120] ğŸ” Loss: 4.253946\n",
            "Epoch [46/120] ğŸ” Loss: 2.939380\n",
            "Epoch [47/120] ğŸ” Loss: 4.440734\n",
            "Epoch [48/120] ğŸ” Loss: 3.487140\n",
            "Epoch [49/120] ğŸ” Loss: 3.436331\n",
            "Epoch [50/120] ğŸ” Loss: 2.909870\n",
            "Epoch [51/120] ğŸ” Loss: 2.824424\n",
            "Epoch [52/120] ğŸ” Loss: 3.184501\n",
            "Epoch [53/120] ğŸ” Loss: 3.359744\n",
            "Epoch [54/120] ğŸ” Loss: 2.866479\n",
            "Epoch [55/120] ğŸ” Loss: 1.726798\n",
            "Epoch [56/120] ğŸ” Loss: 1.925017\n",
            "Epoch [57/120] ğŸ” Loss: 1.904924\n",
            "Epoch [58/120] ğŸ” Loss: 1.960307\n",
            "Epoch [59/120] ğŸ” Loss: 1.769031\n",
            "Epoch [60/120] ğŸ” Loss: 1.105072\n",
            "Epoch [61/120] ğŸ” Loss: 3.013456\n",
            "Epoch [62/120] ğŸ” Loss: 1.237684\n",
            "Epoch [63/120] ğŸ” Loss: 1.765725\n",
            "Epoch [64/120] ğŸ” Loss: 1.325420\n",
            "Epoch [65/120] ğŸ” Loss: 1.294048\n",
            "Epoch [66/120] ğŸ” Loss: 2.805036\n",
            "Epoch [67/120] ğŸ” Loss: 0.747629\n",
            "Epoch [68/120] ğŸ” Loss: 1.145659\n",
            "Epoch [69/120] ğŸ” Loss: 0.690712\n",
            "Epoch [70/120] ğŸ” Loss: 1.488959\n",
            "Epoch [71/120] ğŸ” Loss: 1.395213\n",
            "Epoch [72/120] ğŸ” Loss: 1.408461\n",
            "Epoch [73/120] ğŸ” Loss: 0.926852\n",
            "Epoch [74/120] ğŸ” Loss: 1.153991\n",
            "Epoch [75/120] ğŸ” Loss: 1.358452\n",
            "Epoch [76/120] ğŸ” Loss: 1.241003\n",
            "Epoch [77/120] ğŸ” Loss: 0.946665\n",
            "Epoch [78/120] ğŸ” Loss: 0.651870\n",
            "Epoch [79/120] ğŸ” Loss: 0.620023\n",
            "Epoch [80/120] ğŸ” Loss: 0.940073\n",
            "Epoch [81/120] ğŸ” Loss: 1.338265\n",
            "Epoch [82/120] ğŸ” Loss: 0.256265\n",
            "Epoch [83/120] ğŸ” Loss: 0.298782\n",
            "Epoch [84/120] ğŸ” Loss: 0.450036\n",
            "Epoch [85/120] ğŸ” Loss: 0.397241\n",
            "Epoch [86/120] ğŸ” Loss: 0.344907\n",
            "Epoch [87/120] ğŸ” Loss: 0.516163\n",
            "Epoch [88/120] ğŸ” Loss: 1.364284\n",
            "Epoch [89/120] ğŸ” Loss: 1.129625\n",
            "Epoch [90/120] ğŸ” Loss: 1.479278\n",
            "Epoch [91/120] ğŸ” Loss: 1.142278\n",
            "Epoch [92/120] ğŸ” Loss: 1.424898\n",
            "Epoch [93/120] ğŸ” Loss: 0.633930\n",
            "Epoch [94/120] ğŸ” Loss: 0.267055\n",
            "Epoch [95/120] ğŸ” Loss: 0.279974\n",
            "Epoch [96/120] ğŸ” Loss: 0.169070\n",
            "Epoch [97/120] ğŸ” Loss: 0.810053\n",
            "Epoch [98/120] ğŸ” Loss: 1.596488\n",
            "Epoch [99/120] ğŸ” Loss: 1.211172\n",
            "Epoch [100/120] ğŸ” Loss: 0.814957\n",
            "Epoch [101/120] ğŸ” Loss: 0.327240\n",
            "Epoch [102/120] ğŸ” Loss: 0.491074\n",
            "Epoch [103/120] ğŸ” Loss: 1.202045\n",
            "Epoch [104/120] ğŸ” Loss: 1.041527\n",
            "Epoch [105/120] ğŸ” Loss: 1.002560\n",
            "Epoch [106/120] ğŸ” Loss: 1.162516\n",
            "Epoch [107/120] ğŸ” Loss: 1.156496\n",
            "Epoch [108/120] ğŸ” Loss: 0.657657\n",
            "Epoch [109/120] ğŸ” Loss: 0.492089\n",
            "Epoch [110/120] ğŸ” Loss: 0.589121\n",
            "Epoch [111/120] ğŸ” Loss: 0.110471\n",
            "Epoch [112/120] ğŸ” Loss: 0.091633\n",
            "Epoch [113/120] ğŸ” Loss: 0.399466\n",
            "Epoch [114/120] ğŸ” Loss: 0.844317\n",
            "Epoch [115/120] ğŸ” Loss: 1.562421\n",
            "Epoch [116/120] ğŸ” Loss: 0.277819\n",
            "Epoch [117/120] ğŸ” Loss: 1.723509\n",
            "Epoch [118/120] ğŸ” Loss: 1.139453\n",
            "Epoch [119/120] ğŸ” Loss: 0.474972\n",
            "Epoch [120/120] ğŸ” Loss: 0.947519\n",
            "{'Resolution': 224, 'Fold': 3, 'Epochs': 120, 'BatchSize': 24, 'LearningRate': 0.00022, 'Val_Precision': 0.975, 'Val_Recall': 0.78, 'Val_F1': 0.8666666666666667, 'Val_Accuracy': 0.9721577726218097, 'Val_AUC': 0.9971653543307086, 'Val_TP': 39, 'Val_TN': 380, 'Val_FP': 1, 'Val_FN': 11}\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch [1/120] ğŸ” Loss: 28.515939\n",
            "Epoch [2/120] ğŸ” Loss: 26.045829\n",
            "Epoch [3/120] ğŸ” Loss: 25.967053\n",
            "Epoch [4/120] ğŸ” Loss: 25.491978\n",
            "Epoch [5/120] ğŸ” Loss: 25.163317\n",
            "Epoch [6/120] ğŸ” Loss: 24.914458\n",
            "Epoch [7/120] ğŸ” Loss: 23.709070\n",
            "Epoch [8/120] ğŸ” Loss: 24.000781\n",
            "Epoch [9/120] ğŸ” Loss: 23.763091\n",
            "Epoch [10/120] ğŸ” Loss: 23.129403\n",
            "Epoch [11/120] ğŸ” Loss: 23.083485\n",
            "Epoch [12/120] ğŸ” Loss: 22.739736\n",
            "Epoch [13/120] ğŸ” Loss: 22.603353\n",
            "Epoch [14/120] ğŸ” Loss: 22.594108\n",
            "Epoch [15/120] ğŸ” Loss: 21.757474\n",
            "Epoch [16/120] ğŸ” Loss: 22.396222\n",
            "Epoch [17/120] ğŸ” Loss: 21.693862\n",
            "Epoch [18/120] ğŸ” Loss: 21.332909\n",
            "Epoch [19/120] ğŸ” Loss: 21.194857\n",
            "Epoch [20/120] ğŸ” Loss: 21.065697\n",
            "Epoch [21/120] ğŸ” Loss: 20.295337\n",
            "Epoch [22/120] ğŸ” Loss: 20.544292\n",
            "Epoch [23/120] ğŸ” Loss: 19.043189\n",
            "Epoch [24/120] ğŸ” Loss: 20.201967\n",
            "Epoch [25/120] ğŸ” Loss: 19.633927\n",
            "Epoch [26/120] ğŸ” Loss: 19.156659\n",
            "Epoch [27/120] ğŸ” Loss: 18.312699\n",
            "Epoch [28/120] ğŸ” Loss: 18.622531\n",
            "Epoch [29/120] ğŸ” Loss: 17.567713\n",
            "Epoch [30/120] ğŸ” Loss: 18.180516\n",
            "Epoch [31/120] ğŸ” Loss: 16.822623\n",
            "Epoch [32/120] ğŸ” Loss: 16.196909\n",
            "Epoch [33/120] ğŸ” Loss: 15.531135\n",
            "Epoch [34/120] ğŸ” Loss: 15.355606\n",
            "Epoch [35/120] ğŸ” Loss: 14.873937\n",
            "Epoch [36/120] ğŸ” Loss: 13.898151\n",
            "Epoch [37/120] ğŸ” Loss: 13.106831\n",
            "Epoch [38/120] ğŸ” Loss: 13.669334\n",
            "Epoch [39/120] ğŸ” Loss: 12.817101\n",
            "Epoch [40/120] ğŸ” Loss: 12.403268\n",
            "Epoch [41/120] ğŸ” Loss: 12.082403\n",
            "Epoch [42/120] ğŸ” Loss: 10.466704\n",
            "Epoch [43/120] ğŸ” Loss: 9.769220\n",
            "Epoch [44/120] ğŸ” Loss: 10.099905\n",
            "Epoch [45/120] ğŸ” Loss: 9.512053\n",
            "Epoch [46/120] ğŸ” Loss: 9.333162\n",
            "Epoch [47/120] ğŸ” Loss: 8.388285\n",
            "Epoch [48/120] ğŸ” Loss: 8.255725\n",
            "Epoch [49/120] ğŸ” Loss: 9.578438\n",
            "Epoch [50/120] ğŸ” Loss: 8.333741\n",
            "Epoch [51/120] ğŸ” Loss: 7.131649\n",
            "Epoch [52/120] ğŸ” Loss: 7.662877\n",
            "Epoch [53/120] ğŸ” Loss: 6.892938\n",
            "Epoch [54/120] ğŸ” Loss: 5.872982\n",
            "Epoch [55/120] ğŸ” Loss: 7.031943\n",
            "Epoch [56/120] ğŸ” Loss: 6.001482\n",
            "Epoch [57/120] ğŸ” Loss: 4.976835\n",
            "Epoch [58/120] ğŸ” Loss: 5.015214\n",
            "Epoch [59/120] ğŸ” Loss: 6.159894\n",
            "Epoch [60/120] ğŸ” Loss: 4.987252\n",
            "Epoch [61/120] ğŸ” Loss: 6.816030\n",
            "Epoch [62/120] ğŸ” Loss: 4.601191\n",
            "Epoch [63/120] ğŸ” Loss: 5.317976\n",
            "Epoch [64/120] ğŸ” Loss: 5.101116\n",
            "Epoch [65/120] ğŸ” Loss: 4.384254\n",
            "Epoch [66/120] ğŸ” Loss: 4.356329\n",
            "Epoch [67/120] ğŸ” Loss: 4.992409\n",
            "Epoch [68/120] ğŸ” Loss: 4.559147\n",
            "Epoch [69/120] ğŸ” Loss: 5.346378\n",
            "Epoch [70/120] ğŸ” Loss: 3.586148\n",
            "Epoch [71/120] ğŸ” Loss: 3.310686\n",
            "Epoch [72/120] ğŸ” Loss: 2.894133\n",
            "Epoch [73/120] ğŸ” Loss: 2.858777\n",
            "Epoch [74/120] ğŸ” Loss: 3.909391\n",
            "Epoch [75/120] ğŸ” Loss: 3.175615\n",
            "Epoch [76/120] ğŸ” Loss: 5.244125\n",
            "Epoch [77/120] ğŸ” Loss: 3.383762\n",
            "Epoch [78/120] ğŸ” Loss: 2.651925\n",
            "Epoch [79/120] ğŸ” Loss: 3.213830\n",
            "Epoch [80/120] ğŸ” Loss: 2.948800\n",
            "Epoch [81/120] ğŸ” Loss: 2.423987\n",
            "Epoch [82/120] ğŸ” Loss: 1.911991\n",
            "Epoch [83/120] ğŸ” Loss: 2.029553\n",
            "Epoch [84/120] ğŸ” Loss: 2.906075\n",
            "Epoch [85/120] ğŸ” Loss: 3.250299\n",
            "Epoch [86/120] ğŸ” Loss: 2.574366\n",
            "Epoch [87/120] ğŸ” Loss: 1.744840\n",
            "Epoch [88/120] ğŸ” Loss: 2.816268\n",
            "Epoch [89/120] ğŸ” Loss: 2.376730\n",
            "Epoch [90/120] ğŸ” Loss: 2.417544\n",
            "Epoch [91/120] ğŸ” Loss: 2.213822\n",
            "Epoch [92/120] ğŸ” Loss: 2.423336\n",
            "Epoch [93/120] ğŸ” Loss: 3.058521\n",
            "Epoch [94/120] ğŸ” Loss: 2.358261\n",
            "Epoch [95/120] ğŸ” Loss: 2.905864\n",
            "Epoch [96/120] ğŸ” Loss: 2.030794\n",
            "Epoch [97/120] ğŸ” Loss: 2.303027\n",
            "Epoch [98/120] ğŸ” Loss: 2.398451\n",
            "Epoch [99/120] ğŸ” Loss: 2.165171\n",
            "Epoch [100/120] ğŸ” Loss: 1.554755\n",
            "Epoch [101/120] ğŸ” Loss: 1.339479\n",
            "Epoch [102/120] ğŸ” Loss: 2.075966\n",
            "Epoch [103/120] ğŸ” Loss: 2.404908\n",
            "Epoch [104/120] ğŸ” Loss: 3.145890\n",
            "Epoch [105/120] ğŸ” Loss: 1.786435\n",
            "Epoch [106/120] ğŸ” Loss: 2.824170\n",
            "Epoch [107/120] ğŸ” Loss: 3.198358\n",
            "Epoch [108/120] ğŸ” Loss: 1.506494\n",
            "Epoch [109/120] ğŸ” Loss: 2.182736\n",
            "Epoch [110/120] ğŸ” Loss: 2.124611\n",
            "Epoch [111/120] ğŸ” Loss: 1.641121\n",
            "Epoch [112/120] ğŸ” Loss: 1.625852\n",
            "Epoch [113/120] ğŸ” Loss: 1.381289\n",
            "Epoch [114/120] ğŸ” Loss: 1.958044\n",
            "Epoch [115/120] ğŸ” Loss: 1.397287\n",
            "Epoch [116/120] ğŸ” Loss: 1.886727\n",
            "Epoch [117/120] ğŸ” Loss: 0.859462\n",
            "Epoch [118/120] ğŸ” Loss: 1.816852\n",
            "Epoch [119/120] ğŸ” Loss: 2.270730\n",
            "Epoch [120/120] ğŸ” Loss: 1.730893\n",
            "{'Resolution': 224, 'Fold': 4, 'Epochs': 120, 'BatchSize': 24, 'LearningRate': 0.00022, 'Val_Precision': 0.43478260869565216, 'Val_Recall': 0.40816326530612246, 'Val_F1': 0.4210526315789474, 'Val_Accuracy': 0.8723897911832946, 'Val_AUC': 0.7787690992627417, 'Val_TP': 20, 'Val_TN': 356, 'Val_FP': 26, 'Val_FN': 29}\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch [1/120] ğŸ” Loss: 30.584213\n",
            "Epoch [2/120] ğŸ” Loss: 26.219795\n",
            "Epoch [3/120] ğŸ” Loss: 25.755918\n",
            "Epoch [4/120] ğŸ” Loss: 25.931824\n",
            "Epoch [5/120] ğŸ” Loss: 25.425371\n",
            "Epoch [6/120] ğŸ” Loss: 25.531679\n",
            "Epoch [7/120] ğŸ” Loss: 24.467542\n",
            "Epoch [8/120] ğŸ” Loss: 23.919692\n",
            "Epoch [9/120] ğŸ” Loss: 23.978920\n",
            "Epoch [10/120] ğŸ” Loss: 24.052746\n",
            "Epoch [11/120] ğŸ” Loss: 23.688833\n",
            "Epoch [12/120] ğŸ” Loss: 23.978701\n",
            "Epoch [13/120] ğŸ” Loss: 22.766655\n",
            "Epoch [14/120] ğŸ” Loss: 23.247258\n",
            "Epoch [15/120] ğŸ” Loss: 23.152575\n",
            "Epoch [16/120] ğŸ” Loss: 23.089837\n",
            "Epoch [17/120] ğŸ” Loss: 22.494395\n",
            "Epoch [18/120] ğŸ” Loss: 22.523869\n",
            "Epoch [19/120] ğŸ” Loss: 21.482704\n",
            "Epoch [20/120] ğŸ” Loss: 21.240590\n",
            "Epoch [21/120] ğŸ” Loss: 21.593160\n",
            "Epoch [22/120] ğŸ” Loss: 21.211134\n",
            "Epoch [23/120] ğŸ” Loss: 20.647377\n",
            "Epoch [24/120] ğŸ” Loss: 19.811626\n",
            "Epoch [25/120] ğŸ” Loss: 18.334617\n",
            "Epoch [26/120] ğŸ” Loss: 15.044734\n",
            "Epoch [27/120] ğŸ” Loss: 12.719952\n",
            "Epoch [28/120] ğŸ” Loss: 9.645676\n",
            "Epoch [29/120] ğŸ” Loss: 9.906675\n",
            "Epoch [30/120] ğŸ” Loss: 9.069249\n",
            "Epoch [31/120] ğŸ” Loss: 8.337205\n",
            "Epoch [32/120] ğŸ” Loss: 7.544220\n",
            "Epoch [33/120] ğŸ” Loss: 8.353691\n",
            "Epoch [34/120] ğŸ” Loss: 7.042723\n",
            "Epoch [35/120] ğŸ” Loss: 6.254192\n",
            "Epoch [36/120] ğŸ” Loss: 5.069660\n",
            "Epoch [37/120] ğŸ” Loss: 5.047838\n",
            "Epoch [38/120] ğŸ” Loss: 4.200013\n",
            "Epoch [39/120] ğŸ” Loss: 2.832036\n",
            "Epoch [40/120] ğŸ” Loss: 3.096176\n",
            "Epoch [41/120] ğŸ” Loss: 3.212755\n",
            "Epoch [42/120] ğŸ” Loss: 3.087149\n",
            "Epoch [43/120] ğŸ” Loss: 2.581795\n",
            "Epoch [44/120] ğŸ” Loss: 3.566675\n",
            "Epoch [45/120] ğŸ” Loss: 1.961733\n",
            "Epoch [46/120] ğŸ” Loss: 1.861980\n",
            "Epoch [47/120] ğŸ” Loss: 1.760224\n",
            "Epoch [48/120] ğŸ” Loss: 2.163754\n",
            "Epoch [49/120] ğŸ” Loss: 1.942949\n",
            "Epoch [50/120] ğŸ” Loss: 2.861605\n",
            "Epoch [51/120] ğŸ” Loss: 1.502285\n",
            "Epoch [52/120] ğŸ” Loss: 2.315761\n",
            "Epoch [53/120] ğŸ” Loss: 1.694878\n",
            "Epoch [54/120] ğŸ” Loss: 1.274833\n",
            "Epoch [55/120] ğŸ” Loss: 1.653530\n",
            "Epoch [56/120] ğŸ” Loss: 1.610003\n",
            "Epoch [57/120] ğŸ” Loss: 1.372429\n",
            "Epoch [58/120] ğŸ” Loss: 1.260077\n",
            "Epoch [59/120] ğŸ” Loss: 1.253362\n",
            "Epoch [60/120] ğŸ” Loss: 1.350361\n",
            "Epoch [61/120] ğŸ” Loss: 0.973027\n",
            "Epoch [62/120] ğŸ” Loss: 1.527815\n",
            "Epoch [63/120] ğŸ” Loss: 1.024210\n",
            "Epoch [64/120] ğŸ” Loss: 1.448169\n",
            "Epoch [65/120] ğŸ” Loss: 1.587933\n",
            "Epoch [66/120] ğŸ” Loss: 1.235946\n",
            "Epoch [67/120] ğŸ” Loss: 0.758822\n",
            "Epoch [68/120] ğŸ” Loss: 1.281662\n",
            "Epoch [69/120] ğŸ” Loss: 0.554528\n",
            "Epoch [70/120] ğŸ” Loss: 1.423108\n",
            "Epoch [71/120] ğŸ” Loss: 0.590652\n",
            "Epoch [72/120] ğŸ” Loss: 0.442222\n",
            "Epoch [73/120] ğŸ” Loss: 1.207389\n",
            "Epoch [74/120] ğŸ” Loss: 2.088790\n",
            "Epoch [75/120] ğŸ” Loss: 1.119830\n",
            "Epoch [76/120] ğŸ” Loss: 1.099330\n",
            "Epoch [77/120] ğŸ” Loss: 0.859647\n",
            "Epoch [78/120] ğŸ” Loss: 0.296033\n",
            "Epoch [79/120] ğŸ” Loss: 0.723117\n",
            "Epoch [80/120] ğŸ” Loss: 1.211205\n",
            "Epoch [81/120] ğŸ” Loss: 0.211925\n",
            "Epoch [82/120] ğŸ” Loss: 1.118533\n",
            "Epoch [83/120] ğŸ” Loss: 0.516735\n",
            "Epoch [84/120] ğŸ” Loss: 0.610848\n",
            "Epoch [85/120] ğŸ” Loss: 0.400789\n",
            "Epoch [86/120] ğŸ” Loss: 3.638717\n",
            "Epoch [87/120] ğŸ” Loss: 0.953640\n",
            "Epoch [88/120] ğŸ” Loss: 1.349290\n",
            "Epoch [89/120] ğŸ” Loss: 1.040124\n",
            "Epoch [90/120] ğŸ” Loss: 0.615094\n",
            "Epoch [91/120] ğŸ” Loss: 0.879273\n",
            "Epoch [92/120] ğŸ” Loss: 0.721404\n",
            "Epoch [93/120] ğŸ” Loss: 1.245293\n",
            "Epoch [94/120] ğŸ” Loss: 0.751396\n",
            "Epoch [95/120] ğŸ” Loss: 0.945670\n",
            "Epoch [96/120] ğŸ” Loss: 0.341906\n",
            "Epoch [97/120] ğŸ” Loss: 0.207959\n",
            "Epoch [98/120] ğŸ” Loss: 0.705081\n",
            "Epoch [99/120] ğŸ” Loss: 0.392650\n",
            "Epoch [100/120] ğŸ” Loss: 0.249305\n",
            "Epoch [101/120] ğŸ” Loss: 1.097435\n",
            "Epoch [102/120] ğŸ” Loss: 1.467169\n",
            "Epoch [103/120] ğŸ” Loss: 0.719586\n",
            "Epoch [104/120] ğŸ” Loss: 0.822128\n",
            "Epoch [105/120] ğŸ” Loss: 1.422991\n",
            "Epoch [106/120] ğŸ” Loss: 1.113651\n",
            "Epoch [107/120] ğŸ” Loss: 1.000400\n",
            "Epoch [108/120] ğŸ” Loss: 1.010840\n",
            "Epoch [109/120] ğŸ” Loss: 0.901761\n",
            "Epoch [110/120] ğŸ” Loss: 0.623005\n",
            "Epoch [111/120] ğŸ” Loss: 0.828986\n",
            "Epoch [112/120] ğŸ” Loss: 0.429099\n",
            "Epoch [113/120] ğŸ” Loss: 0.845399\n",
            "Epoch [114/120] ğŸ” Loss: 0.127625\n",
            "Epoch [115/120] ğŸ” Loss: 0.813281\n",
            "Epoch [116/120] ğŸ” Loss: 0.484199\n",
            "Epoch [117/120] ğŸ” Loss: 0.999801\n",
            "Epoch [118/120] ğŸ” Loss: 0.469056\n",
            "Epoch [119/120] ğŸ” Loss: 0.234214\n",
            "Epoch [120/120] ğŸ” Loss: 0.780863\n",
            "{'Resolution': 224, 'Fold': 5, 'Epochs': 120, 'BatchSize': 24, 'LearningRate': 0.00022, 'Val_Precision': 0.8163265306122449, 'Val_Recall': 0.8163265306122449, 'Val_F1': 0.8163265306122449, 'Val_Accuracy': 0.9582366589327146, 'Val_AUC': 0.9880863340100438, 'Val_TP': 40, 'Val_TN': 373, 'Val_FP': 9, 'Val_FN': 9}\n",
            "âœ… Best fold = 2\n",
            "\n",
            "ğŸ“Š TEST (best-fold model) Results\n",
            "Precision: 1.0000, Recall: 0.9412, F1: 0.9697\n",
            "Accuracy:  0.9937, AUC: 0.9998\n",
            "\n",
            "âœ… Tri-Right-Eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# GLOBAL CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "\n",
        "N_SPLITS = 5\n",
        "RESOLUTIONS = [224]\n",
        "EPOCHS_CV =120\n",
        "BATCH_CV = 24\n",
        "LR_CV = 0.00022\n",
        "\n",
        "# =========================\n",
        "# DEVICE + DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"tri-right-eye_hb_90_repro_bestfold_only_with_age_days\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "# Define directories (RIGHT EYE ONLY)\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS: base id handling and tri-eye intersections\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    if not fname.endswith(suffix):\n",
        "        return None\n",
        "    return fname[: -len(suffix)]\n",
        "\n",
        "def common_bases_across_three(dirs_map):\n",
        "    suffixes = {\n",
        "        'right1': '_right_eye_1.png',\n",
        "        'right2': '_right_eye_2.png',\n",
        "        'right3': '_right_eye_3.png',\n",
        "    }\n",
        "    bases_sets = []\n",
        "    for k in ['right1','right2','right3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            print(f\"âš ï¸ Folder missing: {folder}\")\n",
        "            return []\n",
        "        names = sorted([f for f in os.listdir(folder) if f.endswith(suffixes[k])])\n",
        "        bases = set()\n",
        "        for f in names:\n",
        "            b = base_from(f, suffixes[k])\n",
        "            if b:\n",
        "                bases.add(b)\n",
        "        bases_sets.append(bases)\n",
        "    common = set.intersection(*bases_sets) if bases_sets else set()\n",
        "    return sorted(list(common))\n",
        "\n",
        "def load_tri_images_by_bases(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': []}\n",
        "    key_map = {\n",
        "        'r1': ('right1', '_right_eye_1.png'),\n",
        "        'r2': ('right2', '_right_eye_2.png'),\n",
        "        'r3': ('right3', '_right_eye_3.png'),\n",
        "    }\n",
        "    ok = 0\n",
        "    for b in bases:\n",
        "        imgs = {}\n",
        "        failed = False\n",
        "        for short_k, (long_k, suf) in key_map.items():\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[short_k] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if failed:\n",
        "            continue\n",
        "        for k in out.keys():\n",
        "            out[k].append(imgs[k])\n",
        "        ok += 1\n",
        "    return out, ok\n",
        "\n",
        "def prepare_dataset_strict(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_anemic = common_bases_across_three(anemic_dirs)\n",
        "    bases_non = common_bases_across_three(non_dirs)\n",
        "    print(f\"\\nğŸ” {split_name} - discovered bases: anemic={len(bases_anemic)}, non-anemic={len(bases_non)}\")\n",
        "\n",
        "    imgs_a, _ = load_tri_images_by_bases(anemic_dirs, bases_anemic)\n",
        "    imgs_n, _ = load_tri_images_by_bases(non_dirs, bases_non)\n",
        "\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1']),\n",
        "        'base_ids': bases_anemic + bases_non  # âœ… Store base IDs\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… {split_name}: tri-matched samples -> anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# LOAD DATAFRAME WITH AGE, DAYS, AND LIGHTING\n",
        "# =========================\n",
        "df = pd.read_csv(\"/home/ubuntu/anemia-storage/hb_mobilenet/dataset_imputed.csv\")\n",
        "\n",
        "# âœ… Extract base_id from filename\n",
        "def extract_base_id(filename):\n",
        "    for suffix in ['_right_eye_1.png', '_right_eye_2.png', '_right_eye_3.png']:\n",
        "        if filename.endswith(suffix):\n",
        "            return filename[:-len(suffix)]\n",
        "    return filename\n",
        "\n",
        "# âœ… Create feature_map using clean base_id\n",
        "feature_map = {}\n",
        "for _, row in df.iterrows():\n",
        "    raw_id = row['right_eye_1']\n",
        "    base_id = extract_base_id(raw_id)\n",
        "    age = float(row['age_at_registration_final'])\n",
        "    days = float(row['days_since_lmp_final'])\n",
        "    rl1 = float(row['right_eye_1_light'])\n",
        "    rl2 = float(row['right_eye_2_light'])\n",
        "    rl3 = float(row['right_eye_3_light'])\n",
        "\n",
        "    feature_map[base_id] = [age, days, rl1, rl2, rl3]  # 5 features total\n",
        "\n",
        "# =========================\n",
        "# DATASET / DATALOADER\n",
        "# =========================\n",
        "class TriRightEyeDatasetWithFeatures(Dataset):\n",
        "    def __init__(self, data, transform, feature_map):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.feature_map = feature_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[k][idx] for k in ['r1','r2','r3']]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        base_id = self.data['base_ids'][idx]\n",
        "        features = self.feature_map.get(base_id, [0.0]*5)\n",
        "        return images, label, torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type == 'cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL (3x ResNet18 + MLP head + Feature Fusion)\n",
        "# =========================\n",
        "class TriRightResNetWithFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def res():\n",
        "            m = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "            m.fc = nn.Identity()\n",
        "            return m\n",
        "        self.models = nn.ModuleList([res() for _ in range(3)])  # Only 3 models\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(3*512, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        # 5 features: age, days, rl1, rl2, rl3\n",
        "        self.feature_fc = nn.Sequential(\n",
        "            nn.Linear(5, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        self.final_fc = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, *x, features=None):\n",
        "        feats = [model(xi) for model, xi in zip(self.models, x)]\n",
        "        x_img = torch.cat(feats, dim=1)\n",
        "        x_img = self.fc(x_img)\n",
        "        x_feat = self.feature_fc(features)\n",
        "        x = torch.cat([x_img, x_feat], dim=1)\n",
        "        return self.final_fc(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    for imgs, labels, features in loader:\n",
        "        imgs = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        features = features.to(device).float()\n",
        "        out = model(*imgs, features=features)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        p = r = f1 = auc = float('nan')\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        tn = fp = fn = tp = 0\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "# =========================\n",
        "# PREPARE DATASETS\n",
        "# =========================\n",
        "train_data = prepare_dataset_strict(train_dirs_anemic, train_dirs_non, \"TRAIN\")\n",
        "val_data = prepare_dataset_strict(val_dirs_anemic, val_dirs_non, \"VAL\")\n",
        "test_data = prepare_dataset_strict(test_dirs_anemic, test_dirs_non, \"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No tri-matched TRAIN samples found. Check paths/filenames.\")\n",
        "if len(val_data['label']) == 0:\n",
        "    print(\"âš ï¸ No tri-matched VAL samples found.\")\n",
        "if len(test_data['label']) == 0:\n",
        "    print(\"âš ï¸ No tri-matched TEST samples found.\")\n",
        "\n",
        "# =========================\n",
        "# 5-FOLD CV\n",
        "# =========================\n",
        "results = []\n",
        "\n",
        "for resolution in RESOLUTIONS:\n",
        "    print(f\"\\n===== Processing resolution: {resolution} =====\")\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    if len(train_data['label']) < N_SPLITS:\n",
        "        raise RuntimeError(f\"Too few train samples for {N_SPLITS}-fold CV.\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(train_data['label'])\n",
        "    fold = 1\n",
        "    cv_index_records = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        cv_index_records.append({\n",
        "            \"fold\": fold,\n",
        "            \"train_indices\": train_idx.tolist(),\n",
        "            \"val_indices\": val_idx.tolist()\n",
        "        })\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in train_data.items()}\n",
        "        val_subset = {k: [v[i] for i in val_idx] for k, v in train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(TriRightEyeDatasetWithFeatures(train_subset, train_tf, feature_map), batch_size=BATCH_CV, shuffle=True)\n",
        "        val_loader = make_loader(TriRightEyeDatasetWithFeatures(val_subset, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "\n",
        "        model = TriRightResNetWithFeatures().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels, features in train_loader:\n",
        "                imgs = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                features = features.to(device).float()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(*imgs, features=features)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] ğŸ” Loss: {total_loss:.6f}\")\n",
        "\n",
        "        val_metrics = evaluate(model, val_loader)\n",
        "        row = {\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Epochs': EPOCHS_CV,\n",
        "            'BatchSize': BATCH_CV,\n",
        "            'LearningRate': LR_CV,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8]\n",
        "        }\n",
        "        results.append(row)\n",
        "        print(row)\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({\n",
        "                'model_state': model.state_dict(),\n",
        "                'seed': SEED,\n",
        "                'resolution': resolution\n",
        "            }, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save results\n",
        "    if results:\n",
        "        pd.DataFrame(results).to_csv(os.path.join(output_dir, f\"{resolution}_val_cross_validation_results_tri_right.csv\"), index=False)\n",
        "    pd.DataFrame(cv_index_records).to_json(os.path.join(output_dir, f\"{resolution}_cv_indices.json\"), orient='records', indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df['min_PR'] = results_df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = results_df[(results_df['Val_Precision'] >= 0.90) & (results_df['Val_Recall'] >= 0.90)]\n",
        "    best = candidates.sort_values(['Val_F1','Val_AUC','min_PR'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "            results_df.sort_values(['min_PR','Val_F1','Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # Load best fold model\n",
        "    best_model = TriRightResNetWithFeatures().to(device)\n",
        "    best_model_path = os.path.join(output_dir, f\"cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    state = torch.load(best_model_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Evaluate on TEST using best fold\n",
        "    if len(test_data['label']) > 0:\n",
        "        test_loader = make_loader(TriRightEyeDatasetWithFeatures(test_data, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "        test_metrics = evaluate(best_model, test_loader)\n",
        "        print(\"\\nğŸ“Š TEST (best-fold model) Results\")\n",
        "        print(f\"Precision: {test_metrics[0]:.4f}, Recall: {test_metrics[1]:.4f}, F1: {test_metrics[2]:.4f}\")\n",
        "        print(f\"Accuracy:  {test_metrics[3]:.4f}, AUC: {test_metrics[4]:.4f}\")\n",
        "\n",
        "        pd.DataFrame([{\n",
        "            'ChosenFold': best_fold,\n",
        "            'Test_Precision': test_metrics[0], 'Test_Recall': test_metrics[1], 'Test_F1': test_metrics[2],\n",
        "            'Test_Accuracy': test_metrics[3], 'Test_AUC': test_metrics[4], 'Test_TP': test_metrics[5],\n",
        "            'Test_TN': test_metrics[6], 'Test_FP': test_metrics[7], 'Test_FN': test_metrics[8]\n",
        "        }]).to_csv(os.path.join(output_dir, f\"{resolution}_bestfold_test_results_tri_right.csv\"), index=False)\n",
        "\n",
        "print(\"\\nâœ… Tri-Right-Eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4532a2-72e0-405a-a945-5e30dbeaf260",
      "metadata": {
        "id": "9d4532a2-72e0-405a-a945-5e30dbeaf260",
        "outputId": "d1c4456e-0b74-4da4-d4c7-143375e44219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ğŸ” TRAIN - discovered bases: anemic=243, non-anemic=1857\n",
            "âœ… TRAIN: tri-matched samples -> anemic=243, non-anemic=1857, total=2100\n",
            "\n",
            "ğŸ” VAL - discovered bases: anemic=39, non-anemic=294\n",
            "âœ… VAL: tri-matched samples -> anemic=39, non-anemic=294, total=333\n",
            "\n",
            "ğŸ” TEST - discovered bases: anemic=35, non-anemic=270\n",
            "âœ… TEST: tri-matched samples -> anemic=35, non-anemic=270, total=305\n",
            "\n",
            "===== Processing resolution: 224 =====\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch [1/60] ğŸ” Loss: 40.116294\n",
            "Epoch [2/60] ğŸ” Loss: 34.522666\n",
            "Epoch [3/60] ğŸ” Loss: 34.022404\n",
            "Epoch [4/60] ğŸ” Loss: 33.561304\n",
            "Epoch [5/60] ğŸ” Loss: 32.779696\n",
            "Epoch [6/60] ğŸ” Loss: 31.862547\n",
            "Epoch [7/60] ğŸ” Loss: 31.765271\n",
            "Epoch [8/60] ğŸ” Loss: 30.737337\n",
            "Epoch [9/60] ğŸ” Loss: 30.733905\n",
            "Epoch [10/60] ğŸ” Loss: 29.635578\n",
            "Epoch [11/60] ğŸ” Loss: 29.762556\n",
            "Epoch [12/60] ğŸ” Loss: 29.926157\n",
            "Epoch [13/60] ğŸ” Loss: 29.133246\n",
            "Epoch [14/60] ğŸ” Loss: 27.053476\n",
            "Epoch [15/60] ğŸ” Loss: 27.675854\n",
            "Epoch [16/60] ğŸ” Loss: 26.900820\n",
            "Epoch [17/60] ğŸ” Loss: 25.113572\n",
            "Epoch [18/60] ğŸ” Loss: 24.805700\n",
            "Epoch [19/60] ğŸ” Loss: 20.960577\n",
            "Epoch [20/60] ğŸ” Loss: 17.826508\n",
            "Epoch [21/60] ğŸ” Loss: 17.525388\n",
            "Epoch [22/60] ğŸ” Loss: 16.112565\n",
            "Epoch [23/60] ğŸ” Loss: 14.950205\n",
            "Epoch [24/60] ğŸ” Loss: 13.797016\n",
            "Epoch [25/60] ğŸ” Loss: 12.473011\n",
            "Epoch [26/60] ğŸ” Loss: 11.141610\n",
            "Epoch [27/60] ğŸ” Loss: 10.642115\n",
            "Epoch [28/60] ğŸ” Loss: 9.136490\n",
            "Epoch [29/60] ğŸ” Loss: 6.952467\n",
            "Epoch [30/60] ğŸ” Loss: 7.652305\n",
            "Epoch [31/60] ğŸ” Loss: 6.744589\n",
            "Epoch [32/60] ğŸ” Loss: 6.276190\n",
            "Epoch [33/60] ğŸ” Loss: 5.304507\n",
            "Epoch [34/60] ğŸ” Loss: 5.168519\n",
            "Epoch [35/60] ğŸ” Loss: 5.592776\n",
            "Epoch [36/60] ğŸ” Loss: 4.922347\n",
            "Epoch [37/60] ğŸ” Loss: 3.830897\n",
            "Epoch [38/60] ğŸ” Loss: 3.352726\n",
            "Epoch [39/60] ğŸ” Loss: 4.988194\n",
            "Epoch [40/60] ğŸ” Loss: 4.907558\n",
            "Epoch [41/60] ğŸ” Loss: 2.787055\n",
            "Epoch [42/60] ğŸ” Loss: 3.359615\n",
            "Epoch [43/60] ğŸ” Loss: 1.322974\n",
            "Epoch [44/60] ğŸ” Loss: 1.453030\n",
            "Epoch [45/60] ğŸ” Loss: 5.245050\n",
            "Epoch [46/60] ğŸ” Loss: 3.437759\n",
            "Epoch [47/60] ğŸ” Loss: 3.807488\n",
            "Epoch [48/60] ğŸ” Loss: 2.573753\n",
            "Epoch [49/60] ğŸ” Loss: 2.296476\n",
            "Epoch [50/60] ğŸ” Loss: 2.457642\n",
            "Epoch [51/60] ğŸ” Loss: 4.046761\n",
            "Epoch [52/60] ğŸ” Loss: 1.196798\n",
            "Epoch [53/60] ğŸ” Loss: 1.411149\n",
            "Epoch [54/60] ğŸ” Loss: 0.368521\n",
            "Epoch [55/60] ğŸ” Loss: 0.832728\n",
            "Epoch [56/60] ğŸ” Loss: 1.828576\n",
            "Epoch [57/60] ğŸ” Loss: 1.654031\n",
            "Epoch [58/60] ğŸ” Loss: 1.964380\n",
            "Epoch [59/60] ğŸ” Loss: 2.356742\n",
            "Epoch [60/60] ğŸ” Loss: 1.059047\n",
            "{'Resolution': 224, 'Fold': 1, 'Epochs': 60, 'BatchSize': 18, 'LearningRate': 0.00017, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.8571428571428571, 'Val_F1': 0.9032258064516128, 'Val_Accuracy': 0.9785714285714285, 'Val_AUC': 0.9966994884207052, 'Val_TP': 42, 'Val_TN': 369, 'Val_FP': 2, 'Val_FN': 7}\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch [1/60] ğŸ” Loss: 39.469946\n",
            "Epoch [2/60] ğŸ” Loss: 33.870981\n",
            "Epoch [3/60] ğŸ” Loss: 34.049426\n",
            "Epoch [4/60] ğŸ” Loss: 33.363268\n",
            "Epoch [5/60] ğŸ” Loss: 32.053965\n",
            "Epoch [6/60] ğŸ” Loss: 31.638458\n",
            "Epoch [7/60] ğŸ” Loss: 30.769300\n",
            "Epoch [8/60] ğŸ” Loss: 31.108512\n",
            "Epoch [9/60] ğŸ” Loss: 29.700746\n",
            "Epoch [10/60] ğŸ” Loss: 29.256181\n",
            "Epoch [11/60] ğŸ” Loss: 28.910995\n",
            "Epoch [12/60] ğŸ” Loss: 26.864006\n",
            "Epoch [13/60] ğŸ” Loss: 22.739309\n",
            "Epoch [14/60] ğŸ” Loss: 21.954586\n",
            "Epoch [15/60] ğŸ” Loss: 18.860958\n",
            "Epoch [16/60] ğŸ” Loss: 18.419201\n",
            "Epoch [17/60] ğŸ” Loss: 15.802576\n",
            "Epoch [18/60] ğŸ” Loss: 14.506096\n",
            "Epoch [19/60] ğŸ” Loss: 14.133656\n",
            "Epoch [20/60] ğŸ” Loss: 13.779093\n",
            "Epoch [21/60] ğŸ” Loss: 10.861408\n",
            "Epoch [22/60] ğŸ” Loss: 10.263342\n",
            "Epoch [23/60] ğŸ” Loss: 10.459849\n",
            "Epoch [24/60] ğŸ” Loss: 9.256752\n",
            "Epoch [25/60] ğŸ” Loss: 8.836280\n",
            "Epoch [26/60] ğŸ” Loss: 9.139643\n",
            "Epoch [27/60] ğŸ” Loss: 7.455509\n",
            "Epoch [28/60] ğŸ” Loss: 7.391701\n",
            "Epoch [29/60] ğŸ” Loss: 5.227368\n",
            "Epoch [30/60] ğŸ” Loss: 7.503150\n",
            "Epoch [31/60] ğŸ” Loss: 6.428747\n",
            "Epoch [32/60] ğŸ” Loss: 3.734352\n",
            "Epoch [33/60] ğŸ” Loss: 4.730280\n",
            "Epoch [34/60] ğŸ” Loss: 3.218202\n",
            "Epoch [35/60] ğŸ” Loss: 2.876317\n",
            "Epoch [36/60] ğŸ” Loss: 3.951132\n",
            "Epoch [37/60] ğŸ” Loss: 5.066561\n",
            "Epoch [38/60] ğŸ” Loss: 3.032239\n",
            "Epoch [39/60] ğŸ” Loss: 2.615630\n",
            "Epoch [40/60] ğŸ” Loss: 3.139102\n",
            "Epoch [41/60] ğŸ” Loss: 3.680097\n",
            "Epoch [42/60] ğŸ” Loss: 2.173494\n",
            "Epoch [43/60] ğŸ” Loss: 2.032455\n",
            "Epoch [44/60] ğŸ” Loss: 2.648459\n",
            "Epoch [45/60] ğŸ” Loss: 2.622705\n",
            "Epoch [46/60] ğŸ” Loss: 2.934027\n",
            "Epoch [47/60] ğŸ” Loss: 1.381349\n",
            "Epoch [48/60] ğŸ” Loss: 7.041419\n",
            "Epoch [49/60] ğŸ” Loss: 1.585050\n",
            "Epoch [50/60] ğŸ” Loss: 2.563311\n",
            "Epoch [51/60] ğŸ” Loss: 1.776381\n",
            "Epoch [52/60] ğŸ” Loss: 1.443167\n",
            "Epoch [53/60] ğŸ” Loss: 1.765226\n",
            "Epoch [54/60] ğŸ” Loss: 1.317968\n",
            "Epoch [55/60] ğŸ” Loss: 1.826201\n",
            "Epoch [56/60] ğŸ” Loss: 0.808345\n",
            "Epoch [57/60] ğŸ” Loss: 1.597553\n",
            "Epoch [58/60] ğŸ” Loss: 3.036547\n",
            "Epoch [59/60] ğŸ” Loss: 1.701596\n",
            "Epoch [60/60] ğŸ” Loss: 0.550838\n",
            "{'Resolution': 224, 'Fold': 2, 'Epochs': 60, 'BatchSize': 18, 'LearningRate': 0.00017, 'Val_Precision': 0.92, 'Val_Recall': 0.9387755102040817, 'Val_F1': 0.9292929292929293, 'Val_Accuracy': 0.9833333333333333, 'Val_AUC': 0.9904835249463667, 'Val_TP': 46, 'Val_TN': 367, 'Val_FP': 4, 'Val_FN': 3}\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch [1/60] ğŸ” Loss: 37.044519\n",
            "Epoch [2/60] ğŸ” Loss: 33.766936\n",
            "Epoch [3/60] ğŸ” Loss: 33.121041\n",
            "Epoch [4/60] ğŸ” Loss: 32.895479\n",
            "Epoch [5/60] ğŸ” Loss: 31.901056\n",
            "Epoch [6/60] ğŸ” Loss: 31.157070\n",
            "Epoch [7/60] ğŸ” Loss: 30.089202\n",
            "Epoch [8/60] ğŸ” Loss: 30.248995\n",
            "Epoch [9/60] ğŸ” Loss: 29.326532\n",
            "Epoch [10/60] ğŸ” Loss: 29.570221\n",
            "Epoch [11/60] ğŸ” Loss: 28.697213\n",
            "Epoch [12/60] ğŸ” Loss: 29.173836\n",
            "Epoch [13/60] ğŸ” Loss: 27.078060\n",
            "Epoch [14/60] ğŸ” Loss: 27.914327\n",
            "Epoch [15/60] ğŸ” Loss: 26.941992\n",
            "Epoch [16/60] ğŸ” Loss: 26.804550\n",
            "Epoch [17/60] ğŸ” Loss: 25.082915\n",
            "Epoch [18/60] ğŸ” Loss: 24.959889\n",
            "Epoch [19/60] ğŸ” Loss: 22.166028\n",
            "Epoch [20/60] ğŸ” Loss: 20.301364\n",
            "Epoch [21/60] ğŸ” Loss: 17.226964\n",
            "Epoch [22/60] ğŸ” Loss: 16.441591\n",
            "Epoch [23/60] ğŸ” Loss: 14.638828\n",
            "Epoch [24/60] ğŸ” Loss: 15.703228\n",
            "Epoch [25/60] ğŸ” Loss: 12.746200\n",
            "Epoch [26/60] ğŸ” Loss: 11.748500\n",
            "Epoch [27/60] ğŸ” Loss: 10.096208\n",
            "Epoch [28/60] ğŸ” Loss: 8.756548\n",
            "Epoch [29/60] ğŸ” Loss: 9.388765\n",
            "Epoch [30/60] ğŸ” Loss: 7.298750\n",
            "Epoch [31/60] ğŸ” Loss: 8.704352\n",
            "Epoch [32/60] ğŸ” Loss: 7.626408\n",
            "Epoch [33/60] ğŸ” Loss: 5.162314\n",
            "Epoch [34/60] ğŸ” Loss: 4.682913\n",
            "Epoch [35/60] ğŸ” Loss: 4.312124\n",
            "Epoch [36/60] ğŸ” Loss: 5.786773\n",
            "Epoch [37/60] ğŸ” Loss: 5.203634\n",
            "Epoch [38/60] ğŸ” Loss: 3.602359\n",
            "Epoch [39/60] ğŸ” Loss: 5.001121\n",
            "Epoch [40/60] ğŸ” Loss: 3.891477\n",
            "Epoch [41/60] ğŸ” Loss: 3.562917\n",
            "Epoch [42/60] ğŸ” Loss: 2.572550\n",
            "Epoch [43/60] ğŸ” Loss: 3.181371\n",
            "Epoch [44/60] ğŸ” Loss: 2.107010\n",
            "Epoch [45/60] ğŸ” Loss: 2.952745\n",
            "Epoch [46/60] ğŸ” Loss: 2.204356\n",
            "Epoch [47/60] ğŸ” Loss: 4.377495\n",
            "Epoch [48/60] ğŸ” Loss: 2.057080\n",
            "Epoch [49/60] ğŸ” Loss: 1.395051\n",
            "Epoch [50/60] ğŸ” Loss: 2.853517\n",
            "Epoch [51/60] ğŸ” Loss: 2.865682\n",
            "Epoch [52/60] ğŸ” Loss: 1.514397\n",
            "Epoch [53/60] ğŸ” Loss: 0.429799\n",
            "Epoch [54/60] ğŸ” Loss: 1.396376\n",
            "Epoch [55/60] ğŸ” Loss: 1.198376\n",
            "Epoch [56/60] ğŸ” Loss: 3.765985\n",
            "Epoch [57/60] ğŸ” Loss: 3.036746\n",
            "Epoch [58/60] ğŸ” Loss: 1.681055\n",
            "Epoch [59/60] ğŸ” Loss: 2.192534\n",
            "Epoch [60/60] ğŸ” Loss: 1.143559\n",
            "{'Resolution': 224, 'Fold': 3, 'Epochs': 60, 'BatchSize': 18, 'LearningRate': 0.00017, 'Val_Precision': 0.9183673469387755, 'Val_Recall': 0.9183673469387755, 'Val_F1': 0.9183673469387755, 'Val_Accuracy': 0.9809523809523809, 'Val_AUC': 0.9936740194730183, 'Val_TP': 45, 'Val_TN': 367, 'Val_FP': 4, 'Val_FN': 4}\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch [1/60] ğŸ” Loss: 37.140372\n",
            "Epoch [2/60] ğŸ” Loss: 33.868697\n",
            "Epoch [3/60] ğŸ” Loss: 34.128864\n",
            "Epoch [4/60] ğŸ” Loss: 33.182903\n",
            "Epoch [5/60] ğŸ” Loss: 31.744444\n",
            "Epoch [6/60] ğŸ” Loss: 31.740714\n",
            "Epoch [7/60] ğŸ” Loss: 31.455187\n",
            "Epoch [8/60] ğŸ” Loss: 30.882181\n",
            "Epoch [9/60] ğŸ” Loss: 30.835561\n",
            "Epoch [10/60] ğŸ” Loss: 30.268175\n",
            "Epoch [11/60] ğŸ” Loss: 29.521469\n",
            "Epoch [12/60] ğŸ” Loss: 29.543468\n",
            "Epoch [13/60] ğŸ” Loss: 28.860069\n",
            "Epoch [14/60] ğŸ” Loss: 27.806189\n",
            "Epoch [15/60] ğŸ” Loss: 26.751793\n",
            "Epoch [16/60] ğŸ” Loss: 28.368242\n",
            "Epoch [17/60] ğŸ” Loss: 25.955558\n",
            "Epoch [18/60] ğŸ” Loss: 25.196464\n",
            "Epoch [19/60] ğŸ” Loss: 22.722192\n",
            "Epoch [20/60] ğŸ” Loss: 20.376500\n",
            "Epoch [21/60] ğŸ” Loss: 18.707846\n",
            "Epoch [22/60] ğŸ” Loss: 16.404768\n",
            "Epoch [23/60] ğŸ” Loss: 16.444821\n",
            "Epoch [24/60] ğŸ” Loss: 16.265114\n",
            "Epoch [25/60] ğŸ” Loss: 14.846963\n",
            "Epoch [26/60] ğŸ” Loss: 12.264424\n",
            "Epoch [27/60] ğŸ” Loss: 12.063384\n",
            "Epoch [28/60] ğŸ” Loss: 9.569009\n",
            "Epoch [29/60] ğŸ” Loss: 9.112904\n",
            "Epoch [30/60] ğŸ” Loss: 8.251111\n",
            "Epoch [31/60] ğŸ” Loss: 9.620556\n",
            "Epoch [32/60] ğŸ” Loss: 6.395161\n",
            "Epoch [33/60] ğŸ” Loss: 6.420629\n",
            "Epoch [34/60] ğŸ” Loss: 4.430684\n",
            "Epoch [35/60] ğŸ” Loss: 5.840631\n",
            "Epoch [36/60] ğŸ” Loss: 4.978664\n",
            "Epoch [37/60] ğŸ” Loss: 6.182036\n",
            "Epoch [38/60] ğŸ” Loss: 5.522658\n",
            "Epoch [39/60] ğŸ” Loss: 3.727347\n",
            "Epoch [40/60] ğŸ” Loss: 4.158076\n",
            "Epoch [41/60] ğŸ” Loss: 4.163420\n",
            "Epoch [42/60] ğŸ” Loss: 3.478213\n",
            "Epoch [43/60] ğŸ” Loss: 2.192369\n",
            "Epoch [44/60] ğŸ” Loss: 2.614420\n",
            "Epoch [45/60] ğŸ” Loss: 3.652890\n",
            "Epoch [46/60] ğŸ” Loss: 2.537832\n",
            "Epoch [47/60] ğŸ” Loss: 3.429505\n",
            "Epoch [48/60] ğŸ” Loss: 2.118417\n",
            "Epoch [49/60] ğŸ” Loss: 1.946134\n",
            "Epoch [50/60] ğŸ” Loss: 3.192992\n",
            "Epoch [51/60] ğŸ” Loss: 2.739662\n",
            "Epoch [52/60] ğŸ” Loss: 2.171218\n",
            "Epoch [53/60] ğŸ” Loss: 0.724725\n",
            "Epoch [54/60] ğŸ” Loss: 3.961711\n",
            "Epoch [55/60] ğŸ” Loss: 2.196246\n",
            "Epoch [56/60] ğŸ” Loss: 2.190279\n",
            "Epoch [57/60] ğŸ” Loss: 3.305192\n",
            "Epoch [58/60] ğŸ” Loss: 1.818705\n",
            "Epoch [59/60] ğŸ” Loss: 1.196524\n",
            "Epoch [60/60] ğŸ” Loss: 1.363990\n",
            "{'Resolution': 224, 'Fold': 4, 'Epochs': 60, 'BatchSize': 18, 'LearningRate': 0.00017, 'Val_Precision': 0.9148936170212766, 'Val_Recall': 0.8958333333333334, 'Val_F1': 0.9052631578947369, 'Val_Accuracy': 0.9785714285714285, 'Val_AUC': 0.9965277777777778, 'Val_TP': 43, 'Val_TN': 368, 'Val_FP': 4, 'Val_FN': 5}\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch [1/60] ğŸ” Loss: 36.824396\n",
            "Epoch [2/60] ğŸ” Loss: 34.104583\n",
            "Epoch [3/60] ğŸ” Loss: 33.249857\n",
            "Epoch [4/60] ğŸ” Loss: 31.729285\n",
            "Epoch [5/60] ğŸ” Loss: 31.461136\n",
            "Epoch [6/60] ğŸ” Loss: 31.556120\n",
            "Epoch [7/60] ğŸ” Loss: 30.485502\n",
            "Epoch [8/60] ğŸ” Loss: 30.298092\n",
            "Epoch [9/60] ğŸ” Loss: 30.302073\n",
            "Epoch [10/60] ğŸ” Loss: 29.734748\n",
            "Epoch [11/60] ğŸ” Loss: 28.903781\n",
            "Epoch [12/60] ğŸ” Loss: 29.691493\n",
            "Epoch [13/60] ğŸ” Loss: 28.480090\n",
            "Epoch [14/60] ğŸ” Loss: 27.585953\n",
            "Epoch [15/60] ğŸ” Loss: 27.670537\n",
            "Epoch [16/60] ğŸ” Loss: 27.421820\n",
            "Epoch [17/60] ğŸ” Loss: 25.937401\n",
            "Epoch [18/60] ğŸ” Loss: 23.211938\n",
            "Epoch [19/60] ğŸ” Loss: 20.384110\n",
            "Epoch [20/60] ğŸ” Loss: 18.897020\n",
            "Epoch [21/60] ğŸ” Loss: 16.977700\n",
            "Epoch [22/60] ğŸ” Loss: 15.907260\n",
            "Epoch [23/60] ğŸ” Loss: 13.728952\n",
            "Epoch [24/60] ğŸ” Loss: 11.801730\n",
            "Epoch [25/60] ğŸ” Loss: 11.255539\n",
            "Epoch [26/60] ğŸ” Loss: 10.755208\n",
            "Epoch [27/60] ğŸ” Loss: 9.588656\n",
            "Epoch [28/60] ğŸ” Loss: 7.834632\n",
            "Epoch [29/60] ğŸ” Loss: 7.395089\n",
            "Epoch [30/60] ğŸ” Loss: 7.973957\n",
            "Epoch [31/60] ğŸ” Loss: 7.056979\n",
            "Epoch [32/60] ğŸ” Loss: 4.985205\n",
            "Epoch [33/60] ğŸ” Loss: 6.166102\n",
            "Epoch [34/60] ğŸ” Loss: 5.082087\n",
            "Epoch [35/60] ğŸ” Loss: 4.009389\n",
            "Epoch [36/60] ğŸ” Loss: 4.553657\n",
            "Epoch [37/60] ğŸ” Loss: 3.974262\n",
            "Epoch [38/60] ğŸ” Loss: 3.779891\n",
            "Epoch [39/60] ğŸ” Loss: 3.041003\n",
            "Epoch [40/60] ğŸ” Loss: 3.301128\n",
            "Epoch [41/60] ğŸ” Loss: 2.075941\n",
            "Epoch [42/60] ğŸ” Loss: 3.038456\n",
            "Epoch [43/60] ğŸ” Loss: 2.341205\n",
            "Epoch [44/60] ğŸ” Loss: 2.934286\n",
            "Epoch [45/60] ğŸ” Loss: 1.855400\n",
            "Epoch [46/60] ğŸ” Loss: 1.547708\n",
            "Epoch [47/60] ğŸ” Loss: 3.572902\n",
            "Epoch [48/60] ğŸ” Loss: 2.422827\n",
            "Epoch [49/60] ğŸ” Loss: 2.165309\n",
            "Epoch [50/60] ğŸ” Loss: 2.358969\n",
            "Epoch [51/60] ğŸ” Loss: 1.720828\n",
            "Epoch [52/60] ğŸ” Loss: 2.532696\n",
            "Epoch [53/60] ğŸ” Loss: 1.921331\n",
            "Epoch [54/60] ğŸ” Loss: 1.337412\n",
            "Epoch [55/60] ğŸ” Loss: 2.476949\n",
            "Epoch [56/60] ğŸ” Loss: 1.170784\n",
            "Epoch [57/60] ğŸ” Loss: 1.785253\n",
            "Epoch [58/60] ğŸ” Loss: 1.658003\n",
            "Epoch [59/60] ğŸ” Loss: 1.092644\n",
            "Epoch [60/60] ğŸ” Loss: 1.536045\n",
            "{'Resolution': 224, 'Fold': 5, 'Epochs': 60, 'BatchSize': 18, 'LearningRate': 0.00017, 'Val_Precision': 0.9534883720930233, 'Val_Recall': 0.8541666666666666, 'Val_F1': 0.9010989010989011, 'Val_Accuracy': 0.9785714285714285, 'Val_AUC': 0.9942316308243728, 'Val_TP': 41, 'Val_TN': 370, 'Val_FP': 2, 'Val_FN': 7}\n",
            "âœ… Best fold = 2\n",
            "\n",
            "ğŸ“Š TEST (best-fold model) Results\n",
            "Precision: 1.0000, Recall: 0.9714, F1: 0.9855\n",
            "Accuracy:  0.9967, AUC: 1.0000\n",
            "\n",
            "âœ… Tri-left-Eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# GLOBAL CONFIG\n",
        "# =========================\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0          # keep 0 for strict reproducibility\n",
        "PIN_MEMORY = False       # can be True on CUDA; doesn't affect determinism\n",
        "USE_AMP = True           # AMP is deterministic under fixed seeds + deterministic algos\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTIONS = [224]\n",
        "EPOCHS_CV = 60\n",
        "BATCH_CV = 18\n",
        "LR_CV = 0.00017\n",
        "\n",
        "# =========================\n",
        "# DEVICE + DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"tri-left-eye_hb_90_repro_bestfold_only_with_age_days\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "# Define directories (left EYE ONLY)\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS: base id handling and tri-eye intersections\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    if not fname.endswith(suffix):\n",
        "        return None\n",
        "    return fname[: -len(suffix)]\n",
        "\n",
        "def common_bases_across_three(dirs_map):\n",
        "    suffixes = {\n",
        "        'left1': '_left_eye_1.png',\n",
        "        'left2': '_left_eye_2.png',\n",
        "        'left3': '_left_eye_3.png',\n",
        "    }\n",
        "    bases_sets = []\n",
        "    for k in ['left1','left2','left3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            print(f\"âš ï¸ Folder missing: {folder}\")\n",
        "            return []\n",
        "        names = sorted([f for f in os.listdir(folder) if f.endswith(suffixes[k])])\n",
        "        bases = set()\n",
        "        for f in names:\n",
        "            b = base_from(f, suffixes[k])\n",
        "            if b:\n",
        "                bases.add(b)\n",
        "        bases_sets.append(bases)\n",
        "    common = set.intersection(*bases_sets) if bases_sets else set()\n",
        "    return sorted(list(common))\n",
        "\n",
        "def load_tri_images_by_bases(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': []}\n",
        "    key_map = {\n",
        "        'r1': ('left1', '_left_eye_1.png'),\n",
        "        'r2': ('left2', '_left_eye_2.png'),\n",
        "        'r3': ('left3', '_left_eye_3.png'),\n",
        "    }\n",
        "    ok = 0\n",
        "    for b in bases:\n",
        "        imgs = {}\n",
        "        failed = False\n",
        "        for short_k, (long_k, suf) in key_map.items():\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[short_k] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if failed:\n",
        "            continue\n",
        "        for k in out.keys():\n",
        "            out[k].append(imgs[k])\n",
        "        ok += 1\n",
        "    return out, ok\n",
        "\n",
        "def prepare_dataset_strict(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_anemic = common_bases_across_three(anemic_dirs)\n",
        "    bases_non = common_bases_across_three(non_dirs)\n",
        "    print(f\"\\nğŸ” {split_name} - discovered bases: anemic={len(bases_anemic)}, non-anemic={len(bases_non)}\")\n",
        "\n",
        "    imgs_a, _ = load_tri_images_by_bases(anemic_dirs, bases_anemic)\n",
        "    imgs_n, _ = load_tri_images_by_bases(non_dirs, bases_non)\n",
        "\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1']),\n",
        "        'base_ids': bases_anemic + bases_non  # âœ… Store base IDs\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… {split_name}: tri-matched samples -> anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# LOAD DATAFRAME WITH AGE, DAYS, AND LIGHTING\n",
        "# =========================\n",
        "df = pd.read_csv(\"/home/ubuntu/anemia-storage/hb_mobilenet/dataset_imputed.csv\")\n",
        "\n",
        "# âœ… Extract base_id from filename\n",
        "def extract_base_id(filename):\n",
        "    for suffix in ['_left_eye_1.png', '_left_eye_2.png', '_left_eye_3.png']:\n",
        "        if filename.endswith(suffix):\n",
        "            return filename[:-len(suffix)]\n",
        "    return filename\n",
        "\n",
        "# âœ… Create feature_map using clean base_id\n",
        "feature_map = {}\n",
        "for _, row in df.iterrows():\n",
        "    raw_id = row['left_eye_1']\n",
        "    base_id = extract_base_id(raw_id)\n",
        "    age = float(row['age_at_registration_final'])\n",
        "    days = float(row['days_since_lmp_final'])\n",
        "    rl1 = float(row['left_eye_1_light'])\n",
        "    rl2 = float(row['left_eye_2_light'])\n",
        "    rl3 = float(row['left_eye_3_light'])\n",
        "\n",
        "    feature_map[base_id] = [age, days, rl1, rl2, rl3]  # 5 features total\n",
        "\n",
        "# =========================\n",
        "# DATASET / DATALOADER\n",
        "# =========================\n",
        "class TrileftEyeDatasetWithFeatures(Dataset):\n",
        "    def __init__(self, data, transform, feature_map):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.feature_map = feature_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[k][idx] for k in ['r1','r2','r3']]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        base_id = self.data['base_ids'][idx]\n",
        "        features = self.feature_map.get(base_id, [0.0]*5)\n",
        "        return images, label, torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type == 'cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL (3x ResNet18 + MLP head + Feature Fusion)\n",
        "# =========================\n",
        "class TrileftResNetWithFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def res():\n",
        "            m = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "            m.fc = nn.Identity()\n",
        "            return m\n",
        "        self.models = nn.ModuleList([res() for _ in range(3)])  # Only 3 models\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(3*512, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        # 5 features: age, days, rl1, rl2, rl3\n",
        "        self.feature_fc = nn.Sequential(\n",
        "            nn.Linear(5, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        self.final_fc = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, *x, features=None):\n",
        "        feats = [model(xi) for model, xi in zip(self.models, x)]\n",
        "        x_img = torch.cat(feats, dim=1)\n",
        "        x_img = self.fc(x_img)\n",
        "        x_feat = self.feature_fc(features)\n",
        "        x = torch.cat([x_img, x_feat], dim=1)\n",
        "        return self.final_fc(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    for imgs, labels, features in loader:\n",
        "        imgs = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        features = features.to(device).float()\n",
        "        out = model(*imgs, features=features)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        p = r = f1 = auc = float('nan')\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        tn = fp = fn = tp = 0\n",
        "        try:\n",
        "            tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn\n",
        "\n",
        "# =========================\n",
        "# PREPARE DATASETS\n",
        "# =========================\n",
        "train_data = prepare_dataset_strict(train_dirs_anemic, train_dirs_non, \"TRAIN\")\n",
        "val_data = prepare_dataset_strict(val_dirs_anemic, val_dirs_non, \"VAL\")\n",
        "test_data = prepare_dataset_strict(test_dirs_anemic, test_dirs_non, \"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No tri-matched TRAIN samples found. Check paths/filenames.\")\n",
        "if len(val_data['label']) == 0:\n",
        "    print(\"âš ï¸ No tri-matched VAL samples found.\")\n",
        "if len(test_data['label']) == 0:\n",
        "    print(\"âš ï¸ No tri-matched TEST samples found.\")\n",
        "\n",
        "# =========================\n",
        "# 5-FOLD CV\n",
        "# =========================\n",
        "results = []\n",
        "\n",
        "for resolution in RESOLUTIONS:\n",
        "    print(f\"\\n===== Processing resolution: {resolution} =====\")\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    if len(train_data['label']) < N_SPLITS:\n",
        "        raise RuntimeError(f\"Too few train samples for {N_SPLITS}-fold CV.\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(train_data['label'])\n",
        "    fold = 1\n",
        "    cv_index_records = []\n",
        "\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        cv_index_records.append({\n",
        "            \"fold\": fold,\n",
        "            \"train_indices\": train_idx.tolist(),\n",
        "            \"val_indices\": val_idx.tolist()\n",
        "        })\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in train_data.items()}\n",
        "        val_subset = {k: [v[i] for i in val_idx] for k, v in train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(TrileftEyeDatasetWithFeatures(train_subset, train_tf, feature_map), batch_size=BATCH_CV, shuffle=True)\n",
        "        val_loader = make_loader(TrileftEyeDatasetWithFeatures(val_subset, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "\n",
        "        model = TrileftResNetWithFeatures().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels, features in train_loader:\n",
        "                imgs = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                features = features.to(device).float()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(*imgs, features=features)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] ğŸ” Loss: {total_loss:.6f}\")\n",
        "\n",
        "        val_metrics = evaluate(model, val_loader)\n",
        "        row = {\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Epochs': EPOCHS_CV,\n",
        "            'BatchSize': BATCH_CV,\n",
        "            'LearningRate': LR_CV,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8]\n",
        "        }\n",
        "        results.append(row)\n",
        "        print(row)\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({\n",
        "                'model_state': model.state_dict(),\n",
        "                'seed': SEED,\n",
        "                'resolution': resolution\n",
        "            }, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save results\n",
        "    if results:\n",
        "        pd.DataFrame(results).to_csv(os.path.join(output_dir, f\"{resolution}_val_cross_validation_results_tri_left.csv\"), index=False)\n",
        "    pd.DataFrame(cv_index_records).to_json(os.path.join(output_dir, f\"{resolution}_cv_indices.json\"), orient='records', indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df['min_PR'] = results_df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = results_df[(results_df['Val_Precision'] >= 0.90) & (results_df['Val_Recall'] >= 0.90)]\n",
        "    best = candidates.sort_values(['Val_F1','Val_AUC','min_PR'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "            results_df.sort_values(['min_PR','Val_F1','Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # Load best fold model\n",
        "    best_model = TrileftResNetWithFeatures().to(device)\n",
        "    best_model_path = os.path.join(output_dir, f\"cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    state = torch.load(best_model_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Evaluate on TEST using best fold\n",
        "    if len(test_data['label']) > 0:\n",
        "        test_loader = make_loader(TrileftEyeDatasetWithFeatures(test_data, eval_tf, feature_map), batch_size=BATCH_CV, shuffle=False)\n",
        "        test_metrics = evaluate(best_model, test_loader)\n",
        "        print(\"\\nğŸ“Š TEST (best-fold model) Results\")\n",
        "        print(f\"Precision: {test_metrics[0]:.4f}, Recall: {test_metrics[1]:.4f}, F1: {test_metrics[2]:.4f}\")\n",
        "        print(f\"Accuracy:  {test_metrics[3]:.4f}, AUC: {test_metrics[4]:.4f}\")\n",
        "\n",
        "        pd.DataFrame([{\n",
        "            'ChosenFold': best_fold,\n",
        "            'Test_Precision': test_metrics[0], 'Test_Recall': test_metrics[1], 'Test_F1': test_metrics[2],\n",
        "            'Test_Accuracy': test_metrics[3], 'Test_AUC': test_metrics[4], 'Test_TP': test_metrics[5],\n",
        "            'Test_TN': test_metrics[6], 'Test_FP': test_metrics[7], 'Test_FN': test_metrics[8]\n",
        "        }]).to_csv(os.path.join(output_dir, f\"{resolution}_bestfold_test_results_tri_left.csv\"), index=False)\n",
        "\n",
        "print(\"\\nâœ… Tri-left-Eye: Done. 5-fold CV, best-fold selection, and TEST evaluation are fully reproducible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa1de09-df1f-4f1b-ab89-745846567ffc",
      "metadata": {
        "id": "4fa1de09-df1f-4f1b-ab89-745846567ffc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}