{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b859cf28-732a-4c37-b877-c17fc3dfbe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/lib/python3/dist-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/lib/python3/dist-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45241e3e-7b5f-481e-b31e-1bbc8f6e6cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 44 anemic / 358 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/200 Loss: 6.6544\n",
      "Epoch 40/200 Loss: 1.5821\n",
      "Epoch 60/200 Loss: 1.5592\n",
      "Epoch 80/200 Loss: 1.5198\n",
      "Epoch 100/200 Loss: 1.3433\n",
      "Epoch 120/200 Loss: 0.7224\n",
      "Epoch 140/200 Loss: 0.6282\n",
      "Epoch 160/200 Loss: 0.1034\n",
      "Epoch 180/200 Loss: 0.2253\n",
      "Epoch 200/200 Loss: 0.2291\n",
      "Fold 1 â†’ P=0.286, R=0.196\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 20/200 Loss: 3.9086\n",
      "Epoch 40/200 Loss: 1.9648\n",
      "Epoch 60/200 Loss: 1.5771\n",
      "Epoch 80/200 Loss: 1.0537\n",
      "Epoch 100/200 Loss: 0.0289\n",
      "Epoch 120/200 Loss: 2.3484\n",
      "Epoch 140/200 Loss: 0.7058\n",
      "Epoch 160/200 Loss: 1.3418\n",
      "Epoch 180/200 Loss: 0.3754\n",
      "Epoch 200/200 Loss: 0.6522\n",
      "Fold 2 â†’ P=0.353, R=0.118\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 20/200 Loss: 4.9757\n",
      "Epoch 40/200 Loss: 1.4419\n",
      "Epoch 60/200 Loss: 0.5515\n",
      "Epoch 80/200 Loss: 0.8145\n",
      "Epoch 100/200 Loss: 1.5890\n",
      "Epoch 120/200 Loss: 0.2898\n",
      "Epoch 140/200 Loss: 0.5472\n",
      "Epoch 160/200 Loss: 0.8428\n",
      "Epoch 180/200 Loss: 0.8369\n",
      "Epoch 200/200 Loss: 0.0199\n",
      "Fold 3 â†’ P=0.429, R=0.176\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 20/200 Loss: 5.7252\n",
      "Epoch 40/200 Loss: 2.4406\n",
      "Epoch 60/200 Loss: 0.8090\n",
      "Epoch 80/200 Loss: 1.2368\n",
      "Epoch 100/200 Loss: 0.3560\n",
      "Epoch 120/200 Loss: 1.2064\n",
      "Epoch 140/200 Loss: 1.1328\n",
      "Epoch 160/200 Loss: 0.1482\n",
      "Epoch 180/200 Loss: 0.2684\n",
      "Epoch 200/200 Loss: 0.2739\n",
      "Fold 4 â†’ P=0.333, R=0.100\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/200 Loss: 5.8853\n",
      "Epoch 40/200 Loss: 1.9692\n",
      "Epoch 60/200 Loss: 1.1037\n",
      "Epoch 80/200 Loss: 0.6325\n",
      "Epoch 100/200 Loss: 0.1398\n",
      "Epoch 120/200 Loss: 1.0183\n",
      "Epoch 140/200 Loss: 0.8544\n",
      "Epoch 160/200 Loss: 0.6851\n",
      "Epoch 180/200 Loss: 0.0147\n",
      "Epoch 200/200 Loss: 0.0019\n",
      "Fold 5 â†’ P=0.259, R=0.140\n",
      "âœ… Best fold = 1 | P=0.286, R=0.196\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 0.3235\n",
      "Recall:    0.2500\n",
      "F1 score:  0.2821\n",
      "Accuracy:  0.8436\n",
      "AUC:       0.6836\n",
      "TP, TN, FP, FN: 11, 291, 23, 33\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 20:51:10.588199: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-20 20:51:10.589827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-20 20:51:10.624402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-20 20:51:11.230959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 20:51:13.351661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-12-20 20:51:13.353518: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 20:51:18.675917: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-20 20:51:18.675954: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-20 20:51:18.678199: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-20 20:51:18.711722: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-20 20:51:18.711746: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-20 20:51:18.747687: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-12-20 20:51:18.748636: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-20 20:51:18.820024: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-20 20:51:18.846538: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 168343 microseconds.\n",
      "2025-12-20 20:51:18.941334: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-20 20:51:19.201451: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 0.3235\n",
      "Recall:    0.2500\n",
      "F1 score:  0.2821\n",
      "Accuracy:  0.8436\n",
      "AUC:       0.6836\n",
      "TP, TN, FP, FN: 11, 291, 23, 33\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 0.3235, R: 0.2500, AUC: 0.6836\n",
      "TFLite  â†’ P: 0.3235, R: 0.2500, AUC: 0.6836\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "LEFT_EYE_1 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 200\n",
    "BATCH_CV = 24\n",
    "LR_CV = 0.00012\n",
    "EARLY_STOP_PR = 0.90\n",
    "\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_1_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28b3638-4ec5-49ac-9f91-e7160a4c0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 40 anemic / 369 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/120 Loss: 5.0493\n",
      "Epoch 40/120 Loss: 1.8257\n",
      "Epoch 60/120 Loss: 0.9100\n",
      "Epoch 80/120 Loss: 0.9780\n",
      "Epoch 100/120 Loss: 0.3668\n",
      "Epoch 120/120 Loss: 0.3514\n",
      "Fold 1 â†’ P=0.417, R=0.192\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 20/120 Loss: 8.3801\n",
      "Epoch 40/120 Loss: 1.5416\n",
      "Epoch 60/120 Loss: 2.4622\n",
      "Epoch 80/120 Loss: 1.6257\n",
      "Epoch 100/120 Loss: 0.8236\n",
      "Epoch 120/120 Loss: 1.2022\n",
      "Fold 2 â†’ P=0.333, R=0.327\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 20/120 Loss: 7.8954\n",
      "Epoch 40/120 Loss: 2.6256\n",
      "Epoch 60/120 Loss: 1.9422\n",
      "Epoch 80/120 Loss: 2.7991\n",
      "Epoch 100/120 Loss: 1.0196\n",
      "Epoch 120/120 Loss: 1.9349\n",
      "Fold 3 â†’ P=0.533, R=0.157\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 20/120 Loss: 6.7645\n",
      "Epoch 40/120 Loss: 1.1256\n",
      "Epoch 60/120 Loss: 1.9642\n",
      "Epoch 80/120 Loss: 1.8901\n",
      "Epoch 100/120 Loss: 0.9835\n",
      "Epoch 120/120 Loss: 1.0020\n",
      "Fold 4 â†’ P=0.286, R=0.118\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/120 Loss: 4.6125\n",
      "Epoch 40/120 Loss: 3.1232\n",
      "Epoch 60/120 Loss: 0.7864\n",
      "Epoch 80/120 Loss: 0.4808\n",
      "Epoch 100/120 Loss: 0.9190\n",
      "Epoch 120/120 Loss: 0.2803\n",
      "Fold 5 â†’ P=0.500, R=0.275\n",
      "âœ… Best fold = 2 | P=0.333, R=0.327\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 0.2105\n",
      "Recall:    0.1000\n",
      "F1 score:  0.1356\n",
      "Accuracy:  0.8618\n",
      "AUC:       0.5947\n",
      "TP, TN, FP, FN: 4, 314, 15, 36\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 21:56:25.292748: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-20 21:56:25.292782: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-20 21:56:25.294626: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 21:56:25.326159: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-20 21:56:25.326182: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 21:56:25.357803: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-20 21:56:25.420064: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 21:56:25.440444: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 145823 microseconds.\n",
      "2025-12-20 21:56:25.782320: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n",
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 0.2105\n",
      "Recall:    0.1000\n",
      "F1 score:  0.1356\n",
      "Accuracy:  0.8618\n",
      "AUC:       0.5947\n",
      "TP, TN, FP, FN: 4, 314, 15, 36\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 0.2105, R: 0.1000, AUC: 0.5947\n",
      "TFLite  â†’ P: 0.2105, R: 0.1000, AUC: 0.5947\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_2_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "RIGHT_EYE_2 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0           # safest for reproducibility\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 120\n",
    "BATCH_CV = 16\n",
    "LR_CV = 0.00003\n",
    "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"RIGHT_EYE_2_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11605ca5-acf4-4c01-827c-23870d93b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 42 anemic / 361 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/25 Loss: 6.2749\n",
      "âœ… Early stop at epoch 20: P=0.907, R=0.961\n",
      "Fold 1 â†’ P=0.907, R=0.961\n",
      "\n",
      "--- Fold 2 ---\n",
      "âœ… Early stop at epoch 18: P=0.920, R=0.902\n",
      "Fold 2 â†’ P=0.920, R=0.902\n",
      "\n",
      "--- Fold 3 ---\n",
      "âœ… Early stop at epoch 16: P=0.909, R=0.980\n",
      "Fold 3 â†’ P=0.909, R=0.980\n",
      "\n",
      "--- Fold 4 ---\n",
      "âœ… Early stop at epoch 19: P=0.962, R=0.980\n",
      "Fold 4 â†’ P=0.962, R=0.980\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/25 Loss: 12.0477\n",
      "âœ… Early stop at epoch 21: P=0.980, R=0.960\n",
      "Fold 5 â†’ P=0.980, R=0.960\n",
      "âœ… Best fold = 4 | P=0.962, R=0.980\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 1.0000\n",
      "Recall:    1.0000\n",
      "F1 score:  1.0000\n",
      "Accuracy:  1.0000\n",
      "AUC:       1.0000\n",
      "TP, TN, FP, FN: 42, 319, 0, 0\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:09:09.349332: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-20 22:09:09.349368: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-20 22:09:09.350910: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 22:09:09.384919: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-20 22:09:09.384939: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 22:09:09.397323: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-20 22:09:09.464090: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/tf_model\n",
      "2025-12-20 22:09:09.489313: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 138407 microseconds.\n",
      "2025-12-20 22:09:09.810790: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n",
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 1.0000\n",
      "Recall:    1.0000\n",
      "F1 score:  1.0000\n",
      "Accuracy:  1.0000\n",
      "AUC:       1.0000\n",
      "TP, TN, FP, FN: 42, 319, 0, 0\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 1.0000, R: 1.0000, AUC: 1.0000\n",
      "TFLite  â†’ P: 1.0000, R: 1.0000, AUC: 1.0000\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "LEFT_EYE_2 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0           # safest for reproducibility\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 25\n",
    "BATCH_CV = 8\n",
    "LR_CV = 0.00028\n",
    "\n",
    "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
    "\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_2_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20d34e9-f2a8-4161-bdae-51f120ff852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 40 anemic / 368 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/120 Loss: 16.0380\n",
      "Epoch 40/120 Loss: 10.2095\n",
      "Epoch 60/120 Loss: 4.5857\n",
      "Epoch 80/120 Loss: 1.9499\n",
      "Epoch 100/120 Loss: 0.8839\n",
      "Epoch 120/120 Loss: 0.5279\n",
      "Fold 1 â†’ P=0.174, R=0.078\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 20/120 Loss: 16.5953\n",
      "Epoch 40/120 Loss: 10.9553\n",
      "Epoch 60/120 Loss: 4.5363\n",
      "Epoch 80/120 Loss: 1.9418\n",
      "Epoch 100/120 Loss: 0.9903\n",
      "Epoch 120/120 Loss: 0.5642\n",
      "Fold 2 â†’ P=0.188, R=0.059\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 20/120 Loss: 15.4202\n",
      "Epoch 40/120 Loss: 9.0802\n",
      "Epoch 60/120 Loss: 4.1905\n",
      "Epoch 80/120 Loss: 1.5633\n",
      "Epoch 100/120 Loss: 0.7899\n",
      "Epoch 120/120 Loss: 0.4116\n",
      "Fold 3 â†’ P=0.250, R=0.098\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 20/120 Loss: 16.3249\n",
      "Epoch 40/120 Loss: 10.3220\n",
      "Epoch 60/120 Loss: 4.6457\n",
      "Epoch 80/120 Loss: 1.8070\n",
      "Epoch 100/120 Loss: 0.8796\n",
      "Epoch 120/120 Loss: 0.4798\n",
      "Fold 4 â†’ P=0.214, R=0.118\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/120 Loss: 15.7944\n",
      "Epoch 40/120 Loss: 9.7277\n",
      "Epoch 60/120 Loss: 4.1110\n",
      "Epoch 80/120 Loss: 1.7532\n",
      "Epoch 100/120 Loss: 0.8679\n",
      "Epoch 120/120 Loss: 0.4930\n",
      "Fold 5 â†’ P=0.240, R=0.118\n",
      "âœ… Best fold = 5 | P=0.240, R=0.118\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 0.2667\n",
      "Recall:    0.1000\n",
      "F1 score:  0.1455\n",
      "Accuracy:  0.8723\n",
      "AUC:       0.5828\n",
      "TP, TN, FP, FN: 4, 317, 11, 36\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 23:09:52.931404: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-20 23:09:52.931441: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-20 23:09:52.932877: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:09:52.971210: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-20 23:09:52.971232: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:09:52.984143: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-20 23:09:53.012353: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:09:53.037905: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 105032 microseconds.\n",
      "2025-12-20 23:09:53.366440: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n",
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 0.2667\n",
      "Recall:    0.1000\n",
      "F1 score:  0.1455\n",
      "Accuracy:  0.8723\n",
      "AUC:       0.5828\n",
      "TP, TN, FP, FN: 4, 317, 11, 36\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 0.2667, R: 0.1000, AUC: 0.5828\n",
      "TFLite  â†’ P: 0.2667, R: 0.1000, AUC: 0.5828\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_3_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "RIGHT_EYE_3 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0           # safest for reproducibility\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 120\n",
    "BATCH_CV = 32\n",
    "LR_CV = 0.000003\n",
    "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
    "\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"RIGHT_EYE_3_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77655a89-0d21-449a-8d7d-8d6af0325a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 43 anemic / 361 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/20 Loss: 15.7675\n",
      "Fold 1 â†’ P=0.352, R=0.380\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 20/20 Loss: 17.3592\n",
      "Fold 2 â†’ P=0.192, R=0.100\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 20/20 Loss: 17.9651\n",
      "Fold 3 â†’ P=0.269, R=0.280\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 20/20 Loss: 17.7913\n",
      "Fold 4 â†’ P=0.182, R=0.040\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/20 Loss: 16.6174\n",
      "Fold 5 â†’ P=0.355, R=0.220\n",
      "âœ… Best fold = 1 | P=0.352, R=0.380\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 0.3600\n",
      "Recall:    0.2093\n",
      "F1 score:  0.2647\n",
      "Accuracy:  0.8615\n",
      "AUC:       0.6670\n",
      "TP, TN, FP, FN: 9, 302, 16, 34\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 23:21:09.230886: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-20 23:21:09.230921: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-20 23:21:09.232800: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:21:09.265574: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-20 23:21:09.265595: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:21:09.276651: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-20 23:21:09.298643: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/tf_model\n",
      "2025-12-20 23:21:09.318780: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 85985 microseconds.\n",
      "2025-12-20 23:21:09.652550: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n",
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 0.3600\n",
      "Recall:    0.2093\n",
      "F1 score:  0.2647\n",
      "Accuracy:  0.8615\n",
      "AUC:       0.6670\n",
      "TP, TN, FP, FN: 9, 302, 16, 34\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 0.3600, R: 0.2093, AUC: 0.6670\n",
      "TFLite  â†’ P: 0.3600, R: 0.2093, AUC: 0.6670\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "LEFT_EYE_3 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0           # safest for reproducibility\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 20\n",
    "BATCH_CV = 16\n",
    "LR_CV = 0.00028\n",
    "\n",
    "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_3_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6214a4-36c2-4f9b-a900-c7725d12c929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb206de-a7ec-47c1-9dcf-a735e61121e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "TEST: 43 anemic / 365 total\n",
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 20/220 Loss: 7.0661\n",
      "Epoch 40/220 Loss: 2.1240\n",
      "Epoch 60/220 Loss: 0.8061\n",
      "Epoch 80/220 Loss: 1.0488\n",
      "Epoch 100/220 Loss: 1.9039\n",
      "Epoch 120/220 Loss: 3.3508\n",
      "Epoch 140/220 Loss: 0.9679\n",
      "Epoch 160/220 Loss: 0.3840\n",
      "Epoch 180/220 Loss: 0.0638\n",
      "Epoch 200/220 Loss: 0.3001\n",
      "Epoch 220/220 Loss: 0.1953\n",
      "Fold 1 â†’ P=0.419, R=0.255\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 20/220 Loss: 7.2471\n",
      "Epoch 40/220 Loss: 2.1460\n",
      "Epoch 60/220 Loss: 1.8991\n",
      "Epoch 80/220 Loss: 1.2631\n",
      "Epoch 100/220 Loss: 2.3499\n",
      "Epoch 120/220 Loss: 1.4601\n",
      "Epoch 140/220 Loss: 1.3751\n",
      "Epoch 160/220 Loss: 1.0555\n",
      "Epoch 180/220 Loss: 0.2162\n",
      "Epoch 200/220 Loss: 1.1324\n",
      "Epoch 220/220 Loss: 0.1581\n",
      "Fold 2 â†’ P=0.389, R=0.137\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 20/220 Loss: 8.3035\n",
      "Epoch 40/220 Loss: 1.7379\n",
      "Epoch 60/220 Loss: 1.8511\n",
      "Epoch 80/220 Loss: 0.9578\n",
      "Epoch 100/220 Loss: 1.0803\n",
      "Epoch 120/220 Loss: 0.3961\n",
      "Epoch 140/220 Loss: 0.8459\n",
      "Epoch 160/220 Loss: 0.2028\n",
      "Epoch 180/220 Loss: 0.1201\n",
      "Epoch 200/220 Loss: 0.1149\n",
      "Epoch 220/220 Loss: 1.1544\n",
      "Fold 3 â†’ P=0.438, R=0.275\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 20/220 Loss: 6.9710\n",
      "Epoch 40/220 Loss: 1.8532\n",
      "Epoch 60/220 Loss: 1.9469\n",
      "Epoch 80/220 Loss: 0.9356\n",
      "Epoch 100/220 Loss: 1.4437\n",
      "Epoch 120/220 Loss: 6.2516\n",
      "Epoch 140/220 Loss: 0.0820\n",
      "Epoch 160/220 Loss: 0.5467\n",
      "Epoch 180/220 Loss: 0.5085\n",
      "Epoch 200/220 Loss: 0.5156\n",
      "Epoch 220/220 Loss: 0.2147\n",
      "Fold 4 â†’ P=0.136, R=0.059\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 20/220 Loss: 6.0472\n",
      "Epoch 40/220 Loss: 3.9327\n",
      "Epoch 60/220 Loss: 1.5447\n",
      "Epoch 80/220 Loss: 3.4364\n",
      "Epoch 100/220 Loss: 1.5492\n",
      "Epoch 120/220 Loss: 2.5082\n",
      "Epoch 140/220 Loss: 1.3017\n",
      "Epoch 160/220 Loss: 0.5105\n",
      "Epoch 180/220 Loss: 0.2990\n",
      "Epoch 200/220 Loss: 2.0415\n",
      "Epoch 220/220 Loss: 0.3909\n",
      "Fold 5 â†’ P=0.310, R=0.180\n",
      "âœ… Best fold = 3 | P=0.438, R=0.275\n",
      "\n",
      "ðŸ“Š FINAL TEST RESULTS (Original Test Set):\n",
      "Precision: 0.4000\n",
      "Recall:    0.0465\n",
      "F1 score:  0.0833\n",
      "Accuracy:  0.8795\n",
      "AUC:       0.6595\n",
      "TP, TN, FP, FN: 2, 319, 3, 41\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/detailed_predictions_pytorch.csv\n",
      "\n",
      "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
      "\n",
      "--- Starting TFLite Conversion Pipeline ---\n",
      "1. Converting PyTorch model to ONNX...\n",
      "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/model.onnx\n",
      "2. Converting ONNX model to TensorFlow SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model/assets\n",
      "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model/fingerprint.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model\n",
      "3. Converting TensorFlow SavedModel to TFLite...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 01:25:31.784602: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-12-21 01:25:31.784644: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-21 01:25:31.786184: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-21 01:25:31.818363: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-12-21 01:25:31.818395: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-21 01:25:31.829649: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-12-21 01:25:31.885989: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/tf_model\n",
      "2025-12-21 01:25:31.910057: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 123874 microseconds.\n",
      "2025-12-21 01:25:32.258733: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 3.632 G  ops, equivalently 1.816 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/single_eye_resnet18.tflite\n",
      "   TFLite Model Size: 42.64 MB\n",
      "âœ… TFLite conversion pipeline complete.\n",
      "\n",
      "ðŸ” Loading TFLite model and re-evaluating on original test set...\n",
      "ðŸ” TFLite model input shape: [  1   3 224 224]\n",
      "   âž¤ Detected layout: NCHW\n",
      "\n",
      "ðŸ“Š TFLITE TEST RESULTS (Same test set):\n",
      "Precision: 0.4000\n",
      "Recall:    0.0465\n",
      "F1 score:  0.0833\n",
      "Accuracy:  0.8795\n",
      "AUC:       0.6595\n",
      "TP, TN, FP, FN: 2, 319, 3, 41\n",
      "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224/detailed_predictions_tflite.csv\n",
      "\n",
      "ðŸ” Comparing with original PyTorch test results:\n",
      "PyTorch â†’ P: 0.4000, R: 0.0465, AUC: 0.6595\n",
      "TFLite  â†’ P: 0.4000, R: 0.0465, AUC: 0.6595\n",
      "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
      "\n",
      "âœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\n",
      "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/RIGHT_EYE_1_eye_original_repro_224\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
    "-------------------------------------------------------------------------------\n",
    "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
    "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
    "- Single image per patient\n",
    "- Early stop if P & R >= 0.90 on validation\n",
    "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
    "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
    "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
    "\n",
    "RIGHT_EYE_1 (Chronological Split)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "SEED = 42\n",
    "NUM_WORKERS = 0           # safest for reproducibility\n",
    "PIN_MEMORY = False\n",
    "USE_AMP = True\n",
    "SAVE_EVERY_FOLD_MODEL = True\n",
    "N_SPLITS = 5\n",
    "RESOLUTION = 224\n",
    "EPOCHS_CV = 220\n",
    "BATCH_CV = 14\n",
    "LR_CV = 0.00003\n",
    "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
    "\n",
    "\n",
    "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
    "DATA_DIR = \"tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
    "OUTPUT_DIR = os.path.join(BASE_PATH, \"RIGHT_EYE_1_eye_original_repro_224\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# =========================\n",
    "# DETERMINISM\n",
    "# =========================\n",
    "def set_global_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_global_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# =========================\n",
    "# PATHS\n",
    "# =========================\n",
    "dirs = {\n",
    "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
    "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
    "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
    "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
    "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
    "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# DATA LOADING WITH FILENAMES\n",
    "# =========================\n",
    "def load_images_with_filenames(folder, label):\n",
    "    imgs, lbls, filenames = [], [], []\n",
    "    if os.path.exists(folder):\n",
    "        for f in sorted(os.listdir(folder)):\n",
    "            if f.endswith(\".png\"):\n",
    "                im = cv2.imread(os.path.join(folder, f))\n",
    "                if im is not None:\n",
    "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "                    lbls.append(label)\n",
    "                    filenames.append(f)\n",
    "    return imgs, lbls, filenames\n",
    "\n",
    "train_imgs, train_lbls, train_filenames = [], [], []\n",
    "val_imgs, val_lbls, val_filenames = [], [], []\n",
    "test_imgs, test_lbls, test_filenames = [], [], []\n",
    "\n",
    "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
    "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
    "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
    "    i,l,f = load_images_with_filenames(folder,label)\n",
    "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
    "\n",
    "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
    "\n",
    "# =========================\n",
    "# DATASET\n",
    "# =========================\n",
    "class SingleEyeDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "# =========================\n",
    "# MODEL\n",
    "# =========================\n",
    "class SingleResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.backbone.fc = nn.Linear(512,1)\n",
    "    def forward(self,x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# =========================\n",
    "# METRICS WITH PREDICTIONS\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def evaluate_with_predictions(model, loader, filenames):\n",
    "    model.eval()\n",
    "    preds, probs, labels_all = [], [], []\n",
    "    all_filenames = []\n",
    "    \n",
    "    # Get all filenames in loader order\n",
    "    batch_size = loader.batch_size\n",
    "    for i in range(0, len(filenames), batch_size):\n",
    "        batch_end = min(i + batch_size, len(filenames))\n",
    "        all_filenames.extend(filenames[i:batch_end])\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "        out = model(imgs)\n",
    "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
    "        pred = (p > 0.5).astype(int)\n",
    "        preds.extend(pred.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
    "    if len(set(labels_all))<2:\n",
    "        return float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),float(\"nan\"),0,0,0,0, labels_all, probs, all_filenames, preds\n",
    "    P,R,F1,_ = precision_recall_fscore_support(labels_all,preds,average='binary')\n",
    "    acc = accuracy_score(labels_all,preds)\n",
    "    auc = roc_auc_score(labels_all,probs)\n",
    "    tn,fp,fn,tp = confusion_matrix(labels_all,preds,labels=[0,1]).ravel()\n",
    "    return P,R,F1,acc,auc,tp,tn,fp,fn, labels_all, probs, all_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# PLOTTING FUNCTIONS\n",
    "# =========================\n",
    "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Anemic', 'Anemic'],\n",
    "                yticklabels=['Non-Anemic', 'Anemic'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
    "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'], \n",
    "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'], \n",
    "                    pytorch_metrics['Test_AUC']]\n",
    "    tflite_vals = [tflite_metrics[0], tflite_metrics[1], \n",
    "                   tflite_metrics[2], tflite_metrics[3], \n",
    "                   tflite_metrics[4]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
    "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# SAVE PREDICTIONS TO CSV\n",
    "# =========================\n",
    "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
    "    # Convert labels to readable format\n",
    "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
    "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
    "    \n",
    "    # Calculate confusion matrix indicators\n",
    "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'file_id': filenames,\n",
    "        'actual_value': true_labels_str,\n",
    "        'predicted_value': pred_labels_str,\n",
    "        'predicted_probability': pred_probs,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "def train_and_eval_single():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    X = train_imgs\n",
    "    y = train_lbls\n",
    "    filenames = train_filenames\n",
    "    \n",
    "    if len(y) < N_SPLITS:\n",
    "        raise RuntimeError(\"Not enough training samples for CV\")\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    results = []\n",
    "    \n",
    "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "        \n",
    "        train_subset_imgs = [X[i] for i in tr_idx]\n",
    "        train_subset_lbls = [y[i] for i in tr_idx]\n",
    "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
    "        val_subset_imgs = [X[i] for i in vl_idx]\n",
    "        val_subset_lbls = [y[i] for i in vl_idx]\n",
    "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
    "        \n",
    "        tr_loader = DataLoader(\n",
    "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
    "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
    "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
    "            generator=torch.Generator().manual_seed(SEED)\n",
    "        )\n",
    "        vl_loader = DataLoader(\n",
    "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
    "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        model = SingleResNet18().to(device)\n",
    "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
    "\n",
    "        for ep in range(EPOCHS_CV):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for imgs, labels in tr_loader:\n",
    "                imgs = imgs.to(device).float()\n",
    "                labels = labels.to(device).float().unsqueeze(1)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
    "                    out = model(imgs)\n",
    "                    loss = loss_fn(out, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
    "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
    "            \n",
    "            if EARLY_STOP_PR:\n",
    "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR:\n",
    "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
    "                    break\n",
    "\n",
    "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
    "        results.append({\n",
    "             'Fold': fold,\n",
    "             'Val_Precision': val_metrics[0],\n",
    "             'Val_Recall': val_metrics[1],\n",
    "             'Val_F1': val_metrics[2],\n",
    "             'Val_Accuracy': val_metrics[3],\n",
    "             'Val_AUC': val_metrics[4],\n",
    "             'Val_TP': val_metrics[5],\n",
    "             'Val_TN': val_metrics[6],\n",
    "             'Val_FP': val_metrics[7],\n",
    "             'Val_FN': val_metrics[8],\n",
    "         })\n",
    "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
    "        \n",
    "        if SAVE_EVERY_FOLD_MODEL:\n",
    "             torch.save({\n",
    "                 'model_state': model.state_dict(),\n",
    "                 'fold': fold,\n",
    "                 'val_metrics': {\n",
    "                     'precision': val_metrics[0],\n",
    "                     'recall': val_metrics[1],\n",
    "                     'f1': val_metrics[2],\n",
    "                     'accuracy': val_metrics[3],\n",
    "                     'auc': val_metrics[4],\n",
    "                     'tp': val_metrics[5],\n",
    "                     'tn': val_metrics[6],\n",
    "                     'fp': val_metrics[7],\n",
    "                     'fn': val_metrics[8],\n",
    "                 }\n",
    "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
    "\n",
    "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
    "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
    "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
    "    else:\n",
    "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
    "    \n",
    "    best_fold = int(best['Fold'])\n",
    "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loader = DataLoader(\n",
    "        SingleEyeDataset(test_imgs, test_lbls, eval_tf),\n",
    "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
    "        map_location=device,\n",
    "        weights_only=False\n",
    "    )\n",
    "    model = SingleResNet18().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "    test_metrics = evaluate_with_predictions(model, test_loader, test_filenames)\n",
    "\n",
    "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Original Test Set):\")\n",
    "    print(f\"Precision: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 score:  {test_metrics[2]:.4f}\")\n",
    "    print(f\"Accuracy:  {test_metrics[3]:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics[4]:.4f}\")\n",
    "    print(f\"TP, TN, FP, FN: {int(test_metrics[5])}, {int(test_metrics[6])}, {int(test_metrics[7])}, {int(test_metrics[8])}\")\n",
    "  \n",
    "    _test_row = [{\n",
    "         'Test_Precision': test_metrics[0],\n",
    "         'Test_Recall': test_metrics[1],\n",
    "         'Test_F1': test_metrics[2],\n",
    "         'Test_Accuracy': test_metrics[3],\n",
    "         'Test_AUC': test_metrics[4],\n",
    "         'Test_TP': test_metrics[5],\n",
    "         'Test_TN': test_metrics[6],\n",
    "         'Test_FP': test_metrics[7],\n",
    "         'Test_FN': test_metrics[8],\n",
    "         'Best_Fold': best_fold\n",
    "    }]\n",
    "    _test_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
    "    pd.DataFrame(_test_row)[_test_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    # Save detailed predictions to CSV\n",
    "    save_predictions_to_csv(\n",
    "        test_metrics[11],  # filenames\n",
    "        test_metrics[9],   # true labels\n",
    "        test_metrics[12],  # pred labels\n",
    "        test_metrics[10],  # pred probs\n",
    "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
    "    )\n",
    "    \n",
    "    # Plot ROC curve and confusion matrix for PyTorch model\n",
    "    plot_roc_curve(test_metrics[9], test_metrics[10], \n",
    "                   \"ROC Curve - PyTorch Model (Original Chronological Test Set)\", \n",
    "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
    "    plot_confusion_matrix(test_metrics[9], \n",
    "                          test_metrics[12], \n",
    "                          \"Confusion Matrix - PyTorch Model\", \n",
    "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# TFLITE CONVERSION\n",
    "# =========================\n",
    "def convert_to_tflite(model, output_dir, resolution):\n",
    "    import torch.onnx\n",
    "    import onnx\n",
    "    from onnx_tf.backend import prepare\n",
    "    import tensorflow as tf\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
    "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
    "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
    "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
    "    \n",
    "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
    "    \n",
    "    # PyTorch â†’ ONNX\n",
    "    print(\"1. Converting PyTorch model to ONNX...\")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=13,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['output'],\n",
    "            # No dynamic_axes â†’ fixes input size\n",
    "        )\n",
    "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # ONNX â†’ TensorFlow\n",
    "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
    "    try:\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        tf_rep = prepare(onnx_model)\n",
    "        tf_rep.export_graph(tf_path)\n",
    "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # TensorFlow â†’ TFLite\n",
    "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
    "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
    "        return\n",
    "\n",
    "# =========================\n",
    "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE) WITH PREDICTIONS\n",
    "# =========================\n",
    "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
    "    import tensorflow as tf\n",
    "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import to_tensor, normalize\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
    "\n",
    "    if len(expected_shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
    "    \n",
    "    batch = expected_shape[0]\n",
    "    assert batch == 1, \"Batch size must be 1\"\n",
    "\n",
    "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
    "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
    "        layout = 'NCHW'\n",
    "        _, _, h, w = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NCHW\")\n",
    "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
    "        layout = 'NHWC'\n",
    "        _, h, w, _ = expected_shape\n",
    "        resize_h, resize_w = int(h), int(w)\n",
    "        print(f\"   âž¤ Detected layout: NHWC\")\n",
    "    else:\n",
    "        # Fallback: assume NHWC if last dim is 3\n",
    "        if expected_shape[-1] == 3:\n",
    "            layout = 'NHWC'\n",
    "            _, h, w, _ = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        elif expected_shape[1] == 3:\n",
    "            layout = 'NCHW'\n",
    "            _, _, h, w = expected_shape\n",
    "            resize_h, resize_w = int(h), int(w)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
    "\n",
    "    preds, probs, labels_all = [], [], []\n",
    "\n",
    "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
    "    def preprocess_pil_style(img_rgb, target_size):\n",
    "        \"\"\"\n",
    "        Reproduce: \n",
    "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
    "        \"\"\"\n",
    "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        # Resize with PIL BILINEAR (same as torchvision)\n",
    "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
    "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
    "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
    "        # Normalize with ImageNet stats\n",
    "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return normalized.numpy()  # (C, H, W), float32\n",
    "\n",
    "    for img, label in zip(test_imgs, test_lbls):\n",
    "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
    "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
    "\n",
    "        if layout == 'NCHW':\n",
    "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
    "        else:  # NHWC\n",
    "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
    "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
    "\n",
    "        input_data = input_data.astype(input_details[0]['dtype'])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
    "        logit = output[0][0]\n",
    "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
    "        pred = int(prob > 0.5)\n",
    "\n",
    "        preds.append(pred)\n",
    "        probs.append(prob)\n",
    "        labels_all.append(label)\n",
    "\n",
    "    if len(set(labels_all)) < 2:\n",
    "        print(\"âš ï¸ Only one class in test set!\")\n",
    "        return None\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
    "    acc = accuracy_score(labels_all, preds)\n",
    "    auc = roc_auc_score(labels_all, probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
    "\n",
    "# =========================\n",
    "# MAIN EXECUTION\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate\n",
    "    zz = train_and_eval_single()\n",
    "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(zz, OUTPUT_DIR, RESOLUTION)\n",
    "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
    "\n",
    "    # Re-evaluate TFLite on same test set\n",
    "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on original test set...\")\n",
    "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
    "    if not os.path.exists(tflite_file):\n",
    "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
    "\n",
    "    tflite_metrics = evaluate_tflite_on_test_with_predictions(tflite_file, test_imgs, test_lbls, test_filenames)\n",
    "\n",
    "    if tflite_metrics:\n",
    "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
    "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Same test set):\")\n",
    "        print(f\"Precision: {P:.4f}\")\n",
    "        print(f\"Recall:    {R:.4f}\")\n",
    "        print(f\"F1 score:  {F1:.4f}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"AUC:       {auc:.4f}\")\n",
    "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
    "\n",
    "        # Save detailed TFLite predictions to CSV\n",
    "        save_predictions_to_csv(\n",
    "            tflite_filenames,\n",
    "            tflite_labels,\n",
    "            tflite_preds,\n",
    "            tflite_probs,\n",
    "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curve and confusion matrix for TFLite model\n",
    "        plot_roc_curve(tflite_labels, tflite_probs, \n",
    "                       \"ROC Curve - TFLite Model (Original Chronological Test Set)\", \n",
    "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
    "        plot_confusion_matrix(tflite_labels, \n",
    "                              tflite_preds, \n",
    "                              \"Confusion Matrix - TFLite Model\", \n",
    "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
    "\n",
    "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "        if os.path.exists(test_results_path):\n",
    "            orig = pd.read_csv(test_results_path).iloc[0]\n",
    "            print(\"\\nðŸ” Comparing with original PyTorch test results:\")\n",
    "            print(f\"PyTorch â†’ P: {orig['Test_Precision']:.4f}, R: {orig['Test_Recall']:.4f}, AUC: {orig['Test_AUC']:.4f}\")\n",
    "            print(f\"TFLite  â†’ P: {P:.4f}, R: {R:.4f}, AUC: {auc:.4f}\")\n",
    "            \n",
    "            # Create metrics comparison plot\n",
    "            plot_metrics_comparison(orig.to_dict(), tflite_metrics, \n",
    "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
    "            \n",
    "            tol = 1e-3\n",
    "            p_ok = abs(P - orig['Test_Precision']) < tol\n",
    "            r_ok = abs(R - orig['Test_Recall']) < tol\n",
    "            auc_ok = abs(auc - orig['Test_AUC']) < tol\n",
    "            \n",
    "            if p_ok and r_ok and auc_ok:\n",
    "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
    "            else:\n",
    "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
    "    else:\n",
    "        print(\"âŒ TFLite evaluation failed.\")\n",
    "\n",
    "    print(\"\\nâœ… Analysis complete: Original chronological test set evaluated with detailed CSV predictions and comprehensive plots!\")\n",
    "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0453e18-b308-4704-a93b-b0f674647f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f44b9c-2bea-4a92-a393-5af76fa7a888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff611319-7a43-4d79-a34f-6ccfc35b7c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09424dd1-6573-40a3-b5b4-53072856c4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
