{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook contains the executed random-stratified experiments for all nine**. **models, including evaluation metrics, ROC curves, confusion matrices and saved predictions**."
      ],
      "metadata": {
        "id": "CHFswMCeSKh6"
      },
      "id": "CHFswMCeSKh6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4ede66-3e2d-4a37-8f78-66a2852e2506",
      "metadata": {
        "id": "ca4ede66-3e2d-4a37-8f78-66a2852e2506",
        "outputId": "ee5a791e-fee5-4341-bee5-a5d47fb8b278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: seaborn in /home/ubuntu/.local/lib/python3.10/site-packages (0.13.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/lib/python3/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/ubuntu/.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/lib/python3/dist-packages (from seaborn) (3.5.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45241e3e-7b5f-481e-b31e-1bbc8f6e6cee",
      "metadata": {
        "id": "45241e3e-7b5f-481e-b31e-1bbc8f6e6cee",
        "outputId": "4aa5cc22-9442-49df-dde4-d5298dff6be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 44 anemic / 358 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 255 anemic / 2152 total\n",
            "Random stratified val set: 42 anemic / 359 total\n",
            "Random stratified test set: 42 anemic / 359 total\n",
            "Original test set: 44 anemic / 358 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 20/200 Loss: 8.3448\n",
            "Epoch 40/200 Loss: 1.4184\n",
            "Epoch 60/200 Loss: 0.5800\n",
            "Epoch 80/200 Loss: 0.4744\n",
            "Epoch 100/200 Loss: 0.0108\n",
            "âœ… Early stop at epoch 112: P=0.979, R=0.902\n",
            "Fold 1 â†’ P=0.979, R=0.902\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/200 Loss: 0.7714\n",
            "Epoch 40/200 Loss: 0.0629\n",
            "âœ… Early stop at epoch 50: P=0.980, R=0.961\n",
            "Fold 2 â†’ P=0.980, R=0.961\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/200 Loss: 1.1884\n",
            "âœ… Early stop at epoch 20: P=0.980, R=0.980\n",
            "Fold 3 â†’ P=0.980, R=0.980\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 20/200 Loss: 0.4454\n",
            "Epoch 40/200 Loss: 0.0626\n",
            "âœ… Early stop at epoch 49: P=0.979, R=0.902\n",
            "Fold 4 â†’ P=0.979, R=0.902\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/200 Loss: 4.6756\n",
            "âœ… Early stop at epoch 27: P=0.980, R=0.980\n",
            "Fold 5 â†’ P=0.980, R=0.980\n",
            "âœ… Best fold = 5 | P=0.980, R=0.980\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.9750\n",
            "Recall:    0.9286\n",
            "F1 score:  0.9512\n",
            "Accuracy:  0.9889\n",
            "AUC:       0.9994\n",
            "TP, TN, FP, FN: 39, 316, 1, 3\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 23:24:59.004455: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-16 23:24:59.006045: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-11-16 23:24:59.035577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-16 23:24:59.608677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 23:25:01.342085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-16 23:25:01.343716: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-16 23:25:06.458868: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-16 23:25:06.458902: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-16 23:25:06.461261: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-11-16 23:25:06.495943: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-16 23:25:06.495963: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-11-16 23:25:06.527376: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-11-16 23:25:06.528079: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-16 23:25:06.592239: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-11-16 23:25:06.613569: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 152311 microseconds.\n",
            "2025-11-16 23:25:06.703665: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-11-16 23:25:06.984878: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.9750\n",
            "Recall:    0.9286\n",
            "F1 score:  0.9512\n",
            "Accuracy:  0.9889\n",
            "AUC:       0.9994\n",
            "TP, TN, FP, FN: 39, 316, 1, 3\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 0.9750, R: 0.9286, AUC: 0.9994\n",
            "TFLite  â†’ P: 0.9750, R: 0.9286, AUC: 0.9994\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_1_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as npA\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 200\n",
        "BATCH_CV = 24\n",
        "LR_CV = 0.00012\n",
        "EARLY_STOP_PR = 0.90\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_1_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f28b3638-4ec5-49ac-9f91-e7160a4c0a22",
      "metadata": {
        "id": "f28b3638-4ec5-49ac-9f91-e7160a4c0a22",
        "outputId": "36df1599-6ec6-414f-b107-a7bfcf4a2832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 40 anemic / 369 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 255 anemic / 2218 total\n",
            "Random stratified val set: 42 anemic / 370 total\n",
            "Random stratified test set: 43 anemic / 370 total\n",
            "Original test set: 40 anemic / 369 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "âœ… Early stop at epoch 15: P=0.920, R=0.902\n",
            "Fold 1 â†’ P=0.920, R=0.902\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/200 Loss: 1.1620\n",
            "Epoch 40/200 Loss: 0.1085\n",
            "Epoch 60/200 Loss: 0.0590\n",
            "Epoch 80/200 Loss: 0.0180\n",
            "Epoch 100/200 Loss: 0.4234\n",
            "Epoch 120/200 Loss: 0.0252\n",
            "Epoch 140/200 Loss: 0.0093\n",
            "Epoch 160/200 Loss: 0.0053\n",
            "Epoch 180/200 Loss: 0.1676\n",
            "Epoch 200/200 Loss: 0.0139\n",
            "Fold 2 â†’ P=1.000, R=1.000\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/200 Loss: 2.1314\n",
            "âœ… Early stop at epoch 30: P=0.980, R=0.941\n",
            "Fold 3 â†’ P=0.980, R=0.941\n",
            "\n",
            "--- Fold 4 ---\n",
            "âœ… Early stop at epoch 15: P=0.980, R=0.941\n",
            "Fold 4 â†’ P=0.980, R=0.941\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/200 Loss: 2.5919\n",
            "âœ… Early stop at epoch 24: P=0.906, R=0.941\n",
            "Fold 5 â†’ P=0.906, R=0.941\n",
            "âœ… Best fold = 2 | P=1.000, R=1.000\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 1.0000\n",
            "Recall:    1.0000\n",
            "F1 score:  1.0000\n",
            "Accuracy:  1.0000\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 43, 327, 0, 0\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 01:27:14.554526: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-17 01:27:14.554561: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-17 01:27:14.555917: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 01:27:14.588360: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-17 01:27:14.588381: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 01:27:14.598847: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-17 01:27:14.621746: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 01:27:14.645388: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 89475 microseconds.\n",
            "2025-11-17 01:27:14.956911: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 1.0000\n",
            "Recall:    1.0000\n",
            "F1 score:  1.0000\n",
            "Accuracy:  1.0000\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 43, 327, 0, 0\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 1.0000, R: 1.0000, AUC: 1.0000\n",
            "TFLite  â†’ P: 1.0000, R: 1.0000, AUC: 1.0000\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_2_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 200\n",
        "BATCH_CV = 16\n",
        "LR_CV = 0.00003\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"Right_EYE_2_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feae062d-6e75-4a02-b3c4-8b0f20f060d9",
      "metadata": {
        "id": "feae062d-6e75-4a02-b3c4-8b0f20f060d9",
        "outputId": "19673e3c-dc01-4dcf-d8ab-0c2333c7ff24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 42 anemic / 361 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 254 anemic / 2169 total\n",
            "Random stratified val set: 42 anemic / 362 total\n",
            "Random stratified test set: 42 anemic / 362 total\n",
            "Original test set: 42 anemic / 361 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "âœ… Early stop at epoch 11: P=0.980, R=0.980\n",
            "Fold 1 â†’ P=0.980, R=0.980\n",
            "\n",
            "--- Fold 2 ---\n",
            "âœ… Early stop at epoch 4: P=0.980, R=0.980\n",
            "Fold 2 â†’ P=0.980, R=0.980\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/200 Loss: 3.5058\n",
            "Epoch 40/200 Loss: 3.4240\n",
            "Epoch 60/200 Loss: 0.7244\n",
            "âœ… Early stop at epoch 66: P=0.980, R=0.961\n",
            "Fold 3 â†’ P=0.980, R=0.961\n",
            "\n",
            "--- Fold 4 ---\n",
            "âœ… Early stop at epoch 3: P=0.980, R=0.941\n",
            "Fold 4 â†’ P=0.980, R=0.941\n",
            "\n",
            "--- Fold 5 ---\n",
            "âœ… Early stop at epoch 3: P=0.961, R=0.980\n",
            "Fold 5 â†’ P=0.961, R=0.980\n",
            "âœ… Best fold = 2 | P=0.980, R=0.980\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.9500\n",
            "Recall:    0.9048\n",
            "F1 score:  0.9268\n",
            "Accuracy:  0.9834\n",
            "AUC:       0.9984\n",
            "TP, TN, FP, FN: 38, 318, 2, 4\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 02:06:00.416153: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-17 02:06:00.416189: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-17 02:06:00.417951: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 02:06:00.450036: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-17 02:06:00.450058: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 02:06:00.461402: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-17 02:06:00.483765: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/tf_model\n",
            "2025-11-17 02:06:00.503598: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 85653 microseconds.\n",
            "2025-11-17 02:06:00.765307: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.9500\n",
            "Recall:    0.9048\n",
            "F1 score:  0.9268\n",
            "Accuracy:  0.9834\n",
            "AUC:       0.9984\n",
            "TP, TN, FP, FN: 38, 318, 2, 4\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 0.9500, R: 0.9048, AUC: 0.9984\n",
            "TFLite  â†’ P: 0.9500, R: 0.9048, AUC: 0.9984\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_2_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 200\n",
        "BATCH_CV = 8\n",
        "LR_CV = 0.00025\n",
        "\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_2_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "280b4c41-e282-47a5-9430-1427b9feef6a",
      "metadata": {
        "id": "280b4c41-e282-47a5-9430-1427b9feef6a",
        "outputId": "2c520757-d48e-4691-ce83-ef87ef5ca534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 40 anemic / 368 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 254 anemic / 2211 total\n",
            "Random stratified val set: 42 anemic / 369 total\n",
            "Random stratified test set: 42 anemic / 369 total\n",
            "Original test set: 40 anemic / 368 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 20/200 Loss: 17.9642\n",
            "Epoch 40/200 Loss: 4.0380\n",
            "Epoch 60/200 Loss: 1.5548\n",
            "Epoch 80/200 Loss: 0.9898\n",
            "Epoch 100/200 Loss: 0.4621\n",
            "Epoch 120/200 Loss: 0.4131\n",
            "Epoch 140/200 Loss: 0.2729\n",
            "Epoch 160/200 Loss: 0.1374\n",
            "Epoch 180/200 Loss: 0.1000\n",
            "Epoch 200/200 Loss: 0.0980\n",
            "Fold 1 â†’ P=1.000, R=0.961\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/200 Loss: 18.4466\n",
            "Epoch 40/200 Loss: 13.5051\n",
            "âœ… Early stop at epoch 50: P=0.978, R=0.900\n",
            "Fold 2 â†’ P=0.978, R=0.900\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/200 Loss: 18.6543\n",
            "Epoch 40/200 Loss: 10.8715\n",
            "Epoch 60/200 Loss: 4.5510\n",
            "Epoch 80/200 Loss: 2.1403\n",
            "Epoch 100/200 Loss: 1.1887\n",
            "Epoch 120/200 Loss: 0.7236\n",
            "Epoch 140/200 Loss: 0.3532\n",
            "Epoch 160/200 Loss: 0.2453\n",
            "Epoch 180/200 Loss: 0.1561\n",
            "Epoch 200/200 Loss: 0.0993\n",
            "Fold 3 â†’ P=1.000, R=0.961\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 20/200 Loss: 16.8439\n",
            "Epoch 40/200 Loss: 6.0223\n",
            "âœ… Early stop at epoch 43: P=0.960, R=0.941\n",
            "Fold 4 â†’ P=0.960, R=0.941\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/200 Loss: 17.2684\n",
            "Epoch 40/200 Loss: 8.9349\n",
            "Epoch 60/200 Loss: 3.3799\n",
            "Epoch 80/200 Loss: 1.6552\n",
            "Epoch 100/200 Loss: 0.8743\n",
            "Epoch 120/200 Loss: 0.4671\n",
            "Epoch 140/200 Loss: 0.2345\n",
            "Epoch 160/200 Loss: 0.1457\n",
            "Epoch 180/200 Loss: 0.1056\n",
            "Epoch 200/200 Loss: 0.0567\n",
            "Fold 5 â†’ P=1.000, R=0.980\n",
            "âœ… Best fold = 5 | P=1.000, R=0.980\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 1.0000\n",
            "Recall:    0.8810\n",
            "F1 score:  0.9367\n",
            "Accuracy:  0.9864\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 37, 327, 0, 5\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 06:41:17.858158: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-17 06:41:17.858192: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-17 06:41:17.859796: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 06:41:17.890992: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-17 06:41:17.891010: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 06:41:17.901555: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-17 06:41:17.923240: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 06:41:17.943641: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 83850 microseconds.\n",
            "2025-11-17 06:41:18.249908: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 1.0000\n",
            "Recall:    0.8810\n",
            "F1 score:  0.9367\n",
            "Accuracy:  0.9864\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 37, 327, 0, 5\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 1.0000, R: 0.8810, AUC: 1.0000\n",
            "TFLite  â†’ P: 1.0000, R: 0.8810, AUC: 1.0000\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_3_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 200\n",
        "BATCH_CV = 32\n",
        "LR_CV = 0.000003\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"Right_EYE_3_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d8182a-3314-4588-9473-da537b6105e5",
      "metadata": {
        "id": "47d8182a-3314-4588-9473-da537b6105e5",
        "outputId": "6247f8fb-4505-4d77-df71-4e8cb36bd189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 43 anemic / 361 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 252 anemic / 2172 total\n",
            "Random stratified val set: 42 anemic / 363 total\n",
            "Random stratified test set: 42 anemic / 363 total\n",
            "Original test set: 43 anemic / 361 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 20/200 Loss: 0.0863\n",
            "âœ… Early stop at epoch 29: P=0.902, R=0.902\n",
            "Fold 1 â†’ P=0.902, R=0.902\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/200 Loss: 0.0267\n",
            "Epoch 40/200 Loss: 0.0227\n",
            "âœ… Early stop at epoch 50: P=0.962, R=0.980\n",
            "Fold 2 â†’ P=0.962, R=0.980\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/200 Loss: 0.1168\n",
            "Epoch 40/200 Loss: 0.0169\n",
            "âœ… Early stop at epoch 56: P=0.980, R=0.980\n",
            "Fold 3 â†’ P=0.980, R=0.980\n",
            "\n",
            "--- Fold 4 ---\n",
            "âœ… Early stop at epoch 7: P=0.980, R=0.960\n",
            "Fold 4 â†’ P=0.980, R=0.960\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/200 Loss: 3.5117\n",
            "Epoch 40/200 Loss: 0.9427\n",
            "Epoch 60/200 Loss: 1.1052\n",
            "Epoch 80/200 Loss: 0.0062\n",
            "âœ… Early stop at epoch 91: P=0.979, R=0.940\n",
            "Fold 5 â†’ P=0.979, R=0.940\n",
            "âœ… Best fold = 3 | P=0.980, R=0.980\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.8864\n",
            "Recall:    0.9286\n",
            "F1 score:  0.9070\n",
            "Accuracy:  0.9780\n",
            "AUC:       0.9981\n",
            "TP, TN, FP, FN: 39, 316, 5, 3\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 08:16:47.987005: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-17 08:16:47.987038: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-17 08:16:47.988750: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 08:16:48.020428: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-17 08:16:48.020451: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 08:16:48.031073: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-17 08:16:48.053048: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/tf_model\n",
            "2025-11-17 08:16:48.073509: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 84763 microseconds.\n",
            "2025-11-17 08:16:48.347215: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.8864\n",
            "Recall:    0.9286\n",
            "F1 score:  0.9070\n",
            "Accuracy:  0.9780\n",
            "AUC:       0.9981\n",
            "TP, TN, FP, FN: 39, 316, 5, 3\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 0.8864, R: 0.9286, AUC: 0.9981\n",
            "TFLite  â†’ P: 0.8864, R: 0.9286, AUC: 0.9981\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/LEFT_EYE_3_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 200\n",
        "BATCH_CV = 16\n",
        "LR_CV = 0.0003\n",
        "\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"LEFT_EYE_3_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48ce61d-5d9d-4459-a735-3895dde3294a",
      "metadata": {
        "id": "e48ce61d-5d9d-4459-a735-3895dde3294a",
        "outputId": "afa348b1-9ee2-4e46-fe21-8532981c8d6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 43 anemic / 365 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 254 anemic / 2190 total\n",
            "Random stratified val set: 42 anemic / 365 total\n",
            "Random stratified test set: 42 anemic / 365 total\n",
            "Original test set: 43 anemic / 365 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 20/300 Loss: 8.4474\n",
            "Epoch 40/300 Loss: 4.2687\n",
            "Epoch 60/300 Loss: 1.7011\n",
            "Epoch 80/300 Loss: 2.0485\n",
            "Epoch 100/300 Loss: 0.4169\n",
            "Epoch 120/300 Loss: 0.9647\n",
            "Epoch 140/300 Loss: 0.2443\n",
            "Epoch 160/300 Loss: 0.1371\n",
            "Epoch 180/300 Loss: 6.9355\n",
            "Epoch 200/300 Loss: 0.2364\n",
            "Epoch 220/300 Loss: 0.3945\n",
            "Epoch 240/300 Loss: 1.4637\n",
            "Epoch 260/300 Loss: 0.2370\n",
            "Epoch 280/300 Loss: 1.8021\n",
            "Epoch 300/300 Loss: 0.0343\n",
            "Fold 1 â†’ P=0.571, R=0.640\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/300 Loss: 6.5682\n",
            "Epoch 40/300 Loss: 2.3780\n",
            "Epoch 60/300 Loss: 1.2212\n",
            "Epoch 80/300 Loss: 0.3834\n",
            "Epoch 100/300 Loss: 2.8597\n",
            "Epoch 120/300 Loss: 0.0816\n",
            "Epoch 140/300 Loss: 0.1088\n",
            "Epoch 160/300 Loss: 0.6964\n",
            "Epoch 180/300 Loss: 0.5388\n",
            "Epoch 200/300 Loss: 0.8386\n",
            "Epoch 220/300 Loss: 0.4655\n",
            "Epoch 240/300 Loss: 0.9206\n",
            "Epoch 260/300 Loss: 0.1358\n",
            "Epoch 280/300 Loss: 0.0307\n",
            "Epoch 300/300 Loss: 0.4077\n",
            "Fold 2 â†’ P=0.594, R=0.373\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/300 Loss: 10.7431\n",
            "Epoch 40/300 Loss: 2.8700\n",
            "Epoch 60/300 Loss: 1.5789\n",
            "Epoch 80/300 Loss: 1.8216\n",
            "Epoch 100/300 Loss: 0.6963\n",
            "Epoch 120/300 Loss: 0.7894\n",
            "Epoch 140/300 Loss: 1.3177\n",
            "Epoch 160/300 Loss: 0.1186\n",
            "Epoch 180/300 Loss: 0.1586\n",
            "Epoch 200/300 Loss: 0.6227\n",
            "Epoch 220/300 Loss: 0.6430\n",
            "Epoch 240/300 Loss: 0.0473\n",
            "Epoch 260/300 Loss: 0.0314\n",
            "Epoch 280/300 Loss: 0.0215\n",
            "Epoch 300/300 Loss: 0.4724\n",
            "Fold 3 â†’ P=0.559, R=0.647\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 20/300 Loss: 8.5198\n",
            "Epoch 40/300 Loss: 2.7060\n",
            "Epoch 60/300 Loss: 1.4313\n",
            "Epoch 80/300 Loss: 0.5362\n",
            "Epoch 100/300 Loss: 3.9874\n",
            "Epoch 120/300 Loss: 0.1868\n",
            "Epoch 140/300 Loss: 9.0105\n",
            "Epoch 160/300 Loss: 1.6388\n",
            "Epoch 180/300 Loss: 0.8225\n",
            "Epoch 200/300 Loss: 1.6672\n",
            "Epoch 220/300 Loss: 0.8630\n",
            "Epoch 240/300 Loss: 0.2613\n",
            "Epoch 260/300 Loss: 0.3900\n",
            "Epoch 280/300 Loss: 0.0269\n",
            "Epoch 300/300 Loss: 4.8471\n",
            "Fold 4 â†’ P=0.550, R=0.216\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/300 Loss: 9.6932\n",
            "Epoch 40/300 Loss: 2.3222\n",
            "Epoch 60/300 Loss: 0.9230\n",
            "Epoch 80/300 Loss: 1.8468\n",
            "Epoch 100/300 Loss: 1.1726\n",
            "Epoch 120/300 Loss: 0.8473\n",
            "Epoch 140/300 Loss: 0.1963\n",
            "Epoch 160/300 Loss: 0.1876\n",
            "Epoch 180/300 Loss: 0.0895\n",
            "Epoch 200/300 Loss: 0.3495\n",
            "Epoch 220/300 Loss: 0.1130\n",
            "Epoch 240/300 Loss: 0.4631\n",
            "Epoch 260/300 Loss: 0.0654\n",
            "Epoch 280/300 Loss: 0.6915\n",
            "Epoch 300/300 Loss: 0.1241\n",
            "Fold 5 â†’ P=0.548, R=0.333\n",
            "âœ… Best fold = 1 | P=0.571, R=0.640\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.5000\n",
            "Recall:    0.5000\n",
            "F1 score:  0.5000\n",
            "Accuracy:  0.8849\n",
            "AUC:       0.8952\n",
            "TP, TN, FP, FN: 21, 302, 21, 21\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/detailed_predictions_pytorch_780.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 01:56:10.292621: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 01:56:10.294016: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-02 01:56:10.324517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-02 01:56:10.848138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 01:56:12.678279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-02 01:56:12.679890: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 01:56:17.037359: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-12-02 01:56:17.037393: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-12-02 01:56:17.039947: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-12-02 01:56:17.071189: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-12-02 01:56:17.071205: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-12-02 01:56:17.103076: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-12-02 01:56:17.103746: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-12-02 01:56:17.165560: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/tf_model\n",
            "2025-12-02 01:56:17.188010: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 148068 microseconds.\n",
            "2025-12-02 01:56:17.279746: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-02 01:56:17.544049: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 44.764 G  ops, equivalently 22.382 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/single_eye_resnet18_780.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.5000\n",
            "Recall:    0.5000\n",
            "F1 score:  0.5000\n",
            "Accuracy:  0.8849\n",
            "AUC:       0.8952\n",
            "TP, TN, FP, FN: 21, 302, 21, 21\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro/detailed_predictions_tflite_780.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 0.5000, R: 0.5000, AUC: 0.8952\n",
            "TFLite  â†’ P: 0.5000, R: 0.5000, AUC: 0.8952\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 780\n",
        "EPOCHS_CV = 300\n",
        "BATCH_CV = 14\n",
        "LR_CV = 0.00003\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"Right_EYE_1_eye_stratified_repro\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified_780.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch_780.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18_780.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18_780.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite_780.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified_780.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaca0122-413f-4777-9083-439b855c435f",
      "metadata": {
        "id": "eaca0122-413f-4777-9083-439b855c435f",
        "outputId": "206ad694-bd80-4eef-c1f6-54e9566d24b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "TEST: 43 anemic / 365 total\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 254 anemic / 2190 total\n",
            "Random stratified val set: 42 anemic / 365 total\n",
            "Random stratified test set: 42 anemic / 365 total\n",
            "Original test set: 43 anemic / 365 total\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 20/220 Loss: 10.7102\n",
            "Epoch 40/220 Loss: 2.0890\n",
            "Epoch 60/220 Loss: 1.9651\n",
            "Epoch 80/220 Loss: 0.5620\n",
            "Epoch 100/220 Loss: 1.0330\n",
            "Epoch 120/220 Loss: 0.2076\n",
            "Epoch 140/220 Loss: 0.1254\n",
            "Epoch 160/220 Loss: 0.2101\n",
            "Epoch 180/220 Loss: 0.4396\n",
            "Epoch 200/220 Loss: 1.3714\n",
            "Epoch 220/220 Loss: 0.3631\n",
            "Fold 1 â†’ P=0.629, R=0.440\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 20/220 Loss: 9.6848\n",
            "Epoch 40/220 Loss: 2.4242\n",
            "Epoch 60/220 Loss: 1.6010\n",
            "Epoch 80/220 Loss: 0.3642\n",
            "Epoch 100/220 Loss: 0.5100\n",
            "Epoch 120/220 Loss: 0.2886\n",
            "Epoch 140/220 Loss: 0.4235\n",
            "Epoch 160/220 Loss: 5.7125\n",
            "Epoch 180/220 Loss: 0.0698\n",
            "Epoch 200/220 Loss: 12.0000\n",
            "Epoch 220/220 Loss: 0.9754\n",
            "Fold 2 â†’ P=0.634, R=0.510\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 20/220 Loss: 13.3627\n",
            "Epoch 40/220 Loss: 2.1878\n",
            "Epoch 60/220 Loss: 4.8842\n",
            "Epoch 80/220 Loss: 0.6557\n",
            "Epoch 100/220 Loss: 0.3303\n",
            "Epoch 120/220 Loss: 0.1345\n",
            "Epoch 140/220 Loss: 1.8944\n",
            "Epoch 160/220 Loss: 0.0351\n",
            "Epoch 180/220 Loss: 1.1931\n",
            "Epoch 200/220 Loss: 0.7581\n",
            "Epoch 220/220 Loss: 0.0165\n",
            "Fold 3 â†’ P=0.655, R=0.373\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 20/220 Loss: 9.5250\n",
            "Epoch 40/220 Loss: 2.3984\n",
            "Epoch 60/220 Loss: 0.8048\n",
            "Epoch 80/220 Loss: 0.3007\n",
            "Epoch 100/220 Loss: 0.7080\n",
            "Epoch 120/220 Loss: 0.1403\n",
            "Epoch 140/220 Loss: 8.2768\n",
            "Epoch 160/220 Loss: 0.0904\n",
            "Epoch 180/220 Loss: 0.1558\n",
            "Epoch 200/220 Loss: 1.3072\n",
            "Epoch 220/220 Loss: 1.1154\n",
            "Fold 4 â†’ P=0.644, R=0.569\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 20/220 Loss: 11.4303\n",
            "Epoch 40/220 Loss: 1.4968\n",
            "Epoch 60/220 Loss: 1.4945\n",
            "Epoch 80/220 Loss: 4.7718\n",
            "Epoch 100/220 Loss: 0.4657\n",
            "Epoch 120/220 Loss: 0.6752\n",
            "Epoch 140/220 Loss: 0.0607\n",
            "Epoch 160/220 Loss: 0.4299\n",
            "Epoch 180/220 Loss: 0.0750\n",
            "Epoch 200/220 Loss: 0.2986\n",
            "Epoch 220/220 Loss: 0.4431\n",
            "Fold 5 â†’ P=0.659, R=0.569\n",
            "âœ… Best fold = 5 | P=0.659, R=0.569\n",
            "\n",
            "ðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.6286\n",
            "Recall:    0.5238\n",
            "F1 score:  0.5714\n",
            "Accuracy:  0.9096\n",
            "AUC:       0.9198\n",
            "TP, TN, FP, FN: 22, 310, 13, 20\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/detailed_predictions_pytorch.csv\n",
            "\n",
            "âœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-03 00:26:52.736808: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-03 00:26:52.738133: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-03 00:26:52.764866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-03 00:26:53.312058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting PyTorch model to ONNX...\n",
            "   âœ… ONNX model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/model.onnx\n",
            "2. Converting ONNX model to TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-03 00:26:54.906170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-12-03 00:26:54.907932: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_62_x, add_19_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TensorFlow SavedModel saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model\n",
            "3. Converting TensorFlow SavedModel to TFLite...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-03 00:26:59.349701: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-12-03 00:26:59.349733: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-12-03 00:26:59.352266: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model\n",
            "2025-12-03 00:26:59.386382: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-12-03 00:26:59.386402: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model\n",
            "2025-12-03 00:26:59.411928: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-12-03 00:26:59.412641: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-12-03 00:26:59.465648: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/tf_model\n",
            "2025-12-03 00:26:59.516115: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 163854 microseconds.\n",
            "2025-12-03 00:26:59.632115: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-03 00:26:59.926273: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 75.905 G  ops, equivalently 37.952 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite model saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/single_eye_resnet18.tflite\n",
            "   TFLite Model Size: 42.64 MB\n",
            "âœ… TFLite conversion pipeline complete.\n",
            "\n",
            "ðŸ” Loading TFLite model and re-evaluating on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite model input shape: [   1    3 1024 1024]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\n",
            "Precision: 0.6286\n",
            "Recall:    0.5238\n",
            "F1 score:  0.5714\n",
            "Accuracy:  0.9096\n",
            "AUC:       0.9198\n",
            "TP, TN, FP, FN: 22, 310, 13, 20\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024/detailed_predictions_tflite.csv\n",
            "\n",
            "ðŸ” Comparing with original PyTorch test results (Random Stratified):\n",
            "PyTorch â†’ P: 0.6286, R: 0.5238, AUC: 0.9198\n",
            "TFLite  â†’ P: 0.6286, R: 0.5238, AUC: 0.9198\n",
            "âœ… TFLite results match PyTorch within tolerance (1e-3).\n",
            "\n",
            "âœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\n",
            "âœ… Detailed prediction CSVs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/Right_EYE_1_eye_stratified_repro_1024\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Single-Eye ResNet18 Training (5-fold CV -> select best fold -> TEST + TFLite Re-eval)\n",
        "-------------------------------------------------------------------------------\n",
        "- FIXED: No data leakage (CV uses only original TRAIN data)\n",
        "- Strict determinism: fixed seeds, cuDNN deterministic, no TF32, single-thread OpenCV\n",
        "- Single image per patient\n",
        "- Early stop if P & R >= 0.90 on validation\n",
        "- TFLite conversion + re-evaluation on same test set with auto-detected input size\n",
        "- Added random stratified test split for robustness evaluation\n",
        "- Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "- Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0           # safest for reproducibility\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 1024\n",
        "EPOCHS_CV = 220\n",
        "BATCH_CV = 14\n",
        "LR_CV = 0.00003\n",
        "EARLY_STOP_PR = 0.90      # stop training if P & R >= 0.90\n",
        "\n",
        "\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"Right_EYE_1_eye_stratified_repro_1024\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "dirs = {\n",
        "    'anemic_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_train_roi/\"),\n",
        "    'non_train': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_train_roi/\"),\n",
        "    'anemic_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_val_roi/\"),\n",
        "    'non_val': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_val_roi/\"),\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING WITH FILENAMES\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "train_imgs, train_lbls, train_filenames = [], [], []\n",
        "val_imgs, val_lbls, val_filenames = [], [], []\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "\n",
        "for folder, label in [(dirs['anemic_train'],1),(dirs['non_train'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    train_imgs+=i; train_lbls+=l; train_filenames+=f\n",
        "for folder, label in [(dirs['anemic_val'],1),(dirs['non_val'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    val_imgs+=i; val_lbls+=l; val_filenames+=f\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_imgs = train_imgs + val_imgs + test_imgs\n",
        "all_lbls = train_lbls + val_lbls + test_lbls\n",
        "all_filenames = train_filenames + val_filenames + test_filenames\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp, X_test_strat, y_temp, y_test_strat, fname_temp, fname_test_strat = train_test_split(\n",
        "    all_imgs, all_lbls, all_filenames,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_lbls,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat, X_val_strat, y_train_strat, y_val_strat, fname_train_strat, fname_val_strat = train_test_split(\n",
        "    X_temp, y_temp, fname_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class SingleEyeDataset(Dataset):\n",
        "    def __init__(self, imgs, labels, transform):\n",
        "        self.imgs = imgs\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.imgs[idx]), self.labels[idx]\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    np.random.seed(SEED + worker_id)\n",
        "    random.seed(SEED + worker_id)\n",
        "    torch.manual_seed(SEED + worker_id)\n",
        "\n",
        "# =========================\n",
        "# MODEL\n",
        "# =========================\n",
        "class SingleResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Linear(512,1)\n",
        "    def forward(self,x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# =========================\n",
        "# METRICS AND PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    preds, probs, labels_all = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device).float()\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(imgs)\n",
        "        p = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (p > 0.5).astype(int)\n",
        "        preds.extend(pred.tolist())\n",
        "        probs.extend(p.tolist())\n",
        "        labels_all.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), 0, 0, 0, 0, labels_all, probs, all_filenames, preds\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, all_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# TRAINING LOOP\n",
        "# =========================\n",
        "def train_and_eval_single():\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((RESOLUTION,RESOLUTION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # Use random stratified training data for CV\n",
        "    X = X_train_strat  # Random stratified training data\n",
        "    y = y_train_strat\n",
        "    filenames = fname_train_strat\n",
        "\n",
        "    if len(y) < N_SPLITS:\n",
        "        raise RuntimeError(\"Not enough training samples for CV\")\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    results = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(kf.split(X, y), 1):\n",
        "        print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "        train_subset_imgs = [X[i] for i in tr_idx]\n",
        "        train_subset_lbls = [y[i] for i in tr_idx]\n",
        "        train_subset_filenames = [filenames[i] for i in tr_idx]\n",
        "        val_subset_imgs = [X[i] for i in vl_idx]\n",
        "        val_subset_lbls = [y[i] for i in vl_idx]\n",
        "        val_subset_filenames = [filenames[i] for i in vl_idx]\n",
        "\n",
        "        tr_loader = DataLoader(\n",
        "            SingleEyeDataset(train_subset_imgs, train_subset_lbls, train_tf),\n",
        "            batch_size=BATCH_CV, shuffle=True, num_workers=NUM_WORKERS,\n",
        "            worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "            generator=torch.Generator().manual_seed(SEED)\n",
        "        )\n",
        "        vl_loader = DataLoader(\n",
        "            SingleEyeDataset(val_subset_imgs, val_subset_lbls, eval_tf),\n",
        "            batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        model = SingleResNet18().to(device)\n",
        "        opt = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n",
        "\n",
        "        for ep in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in tr_loader:\n",
        "                imgs = imgs.to(device).float()\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=USE_AMP and device.type == \"cuda\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = loss_fn(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (ep + 1) % 20 == 0 or ep == EPOCHS_CV - 1:\n",
        "                print(f\"Epoch {ep+1}/{EPOCHS_CV} Loss: {total_loss:.4f}\")\n",
        "\n",
        "            if EARLY_STOP_PR:\n",
        "                P, R, _, _, _, _, _, _, _, _, _, _, _ = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "                if P >= EARLY_STOP_PR and R >= EARLY_STOP_PR and P <1 and R < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {ep+1}: P={P:.3f}, R={R:.3f}\")\n",
        "                    break\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, vl_loader, val_subset_filenames)\n",
        "        results.append({\n",
        "             'Fold': fold,\n",
        "             'Val_Precision': val_metrics[0],\n",
        "             'Val_Recall': val_metrics[1],\n",
        "             'Val_F1': val_metrics[2],\n",
        "             'Val_Accuracy': val_metrics[3],\n",
        "             'Val_AUC': val_metrics[4],\n",
        "             'Val_TP': val_metrics[5],\n",
        "             'Val_TN': val_metrics[6],\n",
        "             'Val_FP': val_metrics[7],\n",
        "             'Val_FN': val_metrics[8],\n",
        "         })\n",
        "        print(f\"Fold {fold} â†’ P={val_metrics[0]:.3f}, R={val_metrics[1]:.3f}\")\n",
        "\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "             torch.save({\n",
        "                 'model_state': model.state_dict(),\n",
        "                 'fold': fold,\n",
        "                 'val_metrics': {\n",
        "                     'precision': val_metrics[0],\n",
        "                     'recall': val_metrics[1],\n",
        "                     'f1': val_metrics[2],\n",
        "                     'accuracy': val_metrics[3],\n",
        "                     'auc': val_metrics[4],\n",
        "                     'tp': val_metrics[5],\n",
        "                     'tn': val_metrics[6],\n",
        "                     'fp': val_metrics[7],\n",
        "                     'fn': val_metrics[8],\n",
        "                 }\n",
        "             }, os.path.join(OUTPUT_DIR, f\"fold_{fold}.pt\"))\n",
        "\n",
        "    _cv_cols = ['Fold','Val_Precision','Val_Recall','Val_F1','Val_Accuracy','Val_AUC','Val_TP','Val_TN','Val_FP','Val_FN']\n",
        "    pd.DataFrame(results)[_cv_cols].to_csv(os.path.join(OUTPUT_DIR, \"cv_results.csv\"), index=False)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision', 'Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df.Val_Precision >= 0.90) & (df.Val_Recall >= 0.90)]\n",
        "\n",
        "    if len(candidates) > 0:\n",
        "        best = candidates.sort_values(['Val_F1', 'Val_AUC', 'minPR'], ascending=False).iloc[0]\n",
        "    else:\n",
        "        best = df.sort_values(['minPR', 'Val_F1', 'Val_AUC'], ascending=False).iloc[0]\n",
        "\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold} | P={best['Val_Precision']:.3f}, R={best['Val_Recall']:.3f}\")\n",
        "\n",
        "    # Random stratified test evaluation\n",
        "    test_loader_strat = DataLoader(\n",
        "        SingleEyeDataset(X_test_strat, y_test_strat, eval_tf),\n",
        "        batch_size=BATCH_CV, shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    checkpoint = torch.load(\n",
        "        os.path.join(OUTPUT_DIR, f\"fold_{best_fold}.pt\"),\n",
        "        map_location=device,\n",
        "        weights_only=False\n",
        "    )\n",
        "    model = SingleResNet18().to(device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    test_metrics_strat = evaluate_with_predictions(model, test_loader_strat, fname_test_strat)\n",
        "\n",
        "    print(\"\\nðŸ“Š FINAL TEST RESULTS (Random Stratified Test Set):\")\n",
        "    print(f\"Precision: {test_metrics_strat[0]:.4f}\")\n",
        "    print(f\"Recall:    {test_metrics_strat[1]:.4f}\")\n",
        "    print(f\"F1 score:  {test_metrics_strat[2]:.4f}\")\n",
        "    print(f\"Accuracy:  {test_metrics_strat[3]:.4f}\")\n",
        "    print(f\"AUC:       {test_metrics_strat[4]:.4f}\")\n",
        "    print(f\"TP, TN, FP, FN: {int(test_metrics_strat[5])}, {int(test_metrics_strat[6])}, {int(test_metrics_strat[7])}, {int(test_metrics_strat[8])}\")\n",
        "\n",
        "\n",
        "    # Save stratified test results\n",
        "    _strat_row = [{\n",
        "         'Test_Precision': test_metrics_strat[0],\n",
        "         'Test_Recall': test_metrics_strat[1],\n",
        "         'Test_F1': test_metrics_strat[2],\n",
        "         'Test_Accuracy': test_metrics_strat[3],\n",
        "         'Test_AUC': test_metrics_strat[4],\n",
        "         'Test_TP': test_metrics_strat[5],\n",
        "         'Test_TN': test_metrics_strat[6],\n",
        "         'Test_FP': test_metrics_strat[7],\n",
        "         'Test_FN': test_metrics_strat[8],\n",
        "         'Best_Fold': best_fold\n",
        "    }]\n",
        "    _strat_cols = ['Test_Precision','Test_Recall','Test_F1','Test_Accuracy','Test_AUC','Test_TP','Test_TN','Test_FP','Test_FN','Best_Fold']\n",
        "    pd.DataFrame(_strat_row)[_strat_cols].to_csv(os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    # Save detailed predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(OUTPUT_DIR, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(OUTPUT_DIR, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(OUTPUT_DIR, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    return model, test_metrics_strat\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(model, output_dir, resolution):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, 3, resolution, resolution, device=device)\n",
        "    onnx_path = os.path.join(output_dir, \"model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, \"single_eye_resnet18.tflite\")\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # PyTorch â†’ ONNX\n",
        "    print(\"1. Converting PyTorch model to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            dummy_input,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            # No dynamic_axes â†’ fixes input size\n",
        "        )\n",
        "        print(f\"   âœ… ONNX model saved to: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ PyTorch to ONNX failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # ONNX â†’ TensorFlow\n",
        "    print(\"2. Converting ONNX model to TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TensorFlow SavedModel saved to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ONNX to TensorFlow failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # TensorFlow â†’ TFLite\n",
        "    print(\"3. Converting TensorFlow SavedModel to TFLite...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"   âœ… TFLite model saved to: {tflite_path}\")\n",
        "        print(f\"   TFLite Model Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ TensorFlow to TFLite failed: {e}\")\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION (AUTO-DETECT INPUT SIZE)\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    import tensorflow as tf\n",
        "    from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "    import numpy as np\n",
        "    from PIL import Image\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Train and evaluate\n",
        "    model, strat_test_metrics = train_and_eval_single()\n",
        "    print(\"\\nâœ… Single-eye model finished reproducibly with NO DATA LEAKAGE.\")\n",
        "\n",
        "    # Convert to TFLite\n",
        "    convert_to_tflite(model, OUTPUT_DIR, RESOLUTION)\n",
        "    print(\"âœ… TFLite conversion pipeline complete.\")\n",
        "\n",
        "    # Re-evaluate TFLite on random stratified test set\n",
        "    print(\"\\nðŸ” Loading TFLite model and re-evaluating on random stratified test set...\")\n",
        "    tflite_file = os.path.join(OUTPUT_DIR, \"single_eye_resnet18.tflite\")\n",
        "    if not os.path.exists(tflite_file):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {tflite_file}\")\n",
        "\n",
        "    tflite_metrics_strat = evaluate_tflite_on_test_with_predictions(tflite_file, X_test_strat, y_test_strat, fname_test_strat)\n",
        "\n",
        "    if tflite_metrics_strat:\n",
        "        P_strat, R_strat, F1_strat, acc_strat, auc_strat, tp_strat, tn_strat, fp_strat, fn_strat, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics_strat\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (Random Stratified Test Set):\")\n",
        "        print(f\"Precision: {P_strat:.4f}\")\n",
        "        print(f\"Recall:    {R_strat:.4f}\")\n",
        "        print(f\"F1 score:  {F1_strat:.4f}\")\n",
        "        print(f\"Accuracy:  {acc_strat:.4f}\")\n",
        "        print(f\"AUC:       {auc_strat:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp_strat)}, {int(tn_strat)}, {int(fp_strat)}, {int(fn_strat)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        # Plot ROC curve and confusion matrix for TFLite model\n",
        "        plot_roc_curve(tflite_labels, tflite_probs,\n",
        "                       \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"roc_curve_tflite.png\"))\n",
        "        plot_confusion_matrix(tflite_labels,\n",
        "                              tflite_preds,\n",
        "                              \"Confusion Matrix - TFLite Model\",\n",
        "                              os.path.join(OUTPUT_DIR, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "        # Compare with original PyTorch test results\n",
        "        test_results_path = os.path.join(OUTPUT_DIR, \"test_results_stratified.csv\")\n",
        "        if os.path.exists(test_results_path):\n",
        "            strat_pytorch = pd.read_csv(test_results_path).iloc[0]\n",
        "            print(\"\\nðŸ” Comparing with original PyTorch test results (Random Stratified):\")\n",
        "            print(f\"PyTorch â†’ P: {strat_pytorch['Test_Precision']:.4f}, R: {strat_pytorch['Test_Recall']:.4f}, AUC: {strat_pytorch['Test_AUC']:.4f}\")\n",
        "            print(f\"TFLite  â†’ P: {P_strat:.4f}, R: {R_strat:.4f}, AUC: {auc_strat:.4f}\")\n",
        "\n",
        "            tol = 1e-3\n",
        "            p_ok = abs(P_strat - strat_pytorch['Test_Precision']) < tol\n",
        "            r_ok = abs(R_strat - strat_pytorch['Test_Recall']) < tol\n",
        "            auc_ok = abs(auc_strat - strat_pytorch['Test_AUC']) < tol\n",
        "\n",
        "            if p_ok and r_ok and auc_ok:\n",
        "                print(\"âœ… TFLite results match PyTorch within tolerance (1e-3).\")\n",
        "            else:\n",
        "                print(\"âš ï¸ TFLite results differ from PyTorch (check normalization or export).\")\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(strat_pytorch, tflite_metrics_strat,\n",
        "                                   os.path.join(OUTPUT_DIR, \"metrics_comparison.png\"))\n",
        "        else:\n",
        "            print(\"âš ï¸ Original test results not found for comparison.\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed on random stratified test set.\")\n",
        "\n",
        "    print(\"\\nâœ… Analysis complete: Random stratified test set evaluated with comprehensive plots and detailed CSV predictions!\")\n",
        "    print(f\"âœ… Detailed prediction CSVs saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b632057-9adf-4b46-b0de-e29c3e1453ae",
      "metadata": {
        "id": "4b632057-9adf-4b46-b0de-e29c3e1453ae",
        "outputId": "ffde0afe-cfd4-4001-c202-3d260db43ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ðŸ“‚ TEST  anemic (LEFT)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=44\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=42\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "\n",
            "ðŸ“‚ TEST  non-anemic (LEFT)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=314\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=319\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=318\n",
            "âœ… TRAIN: anemic=243, non-anemic=1857, total=2100\n",
            "âœ… VAL: anemic=39, non-anemic=294, total=333\n",
            "âœ… TEST: anemic=35, non-anemic=270, total=305\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 237 anemic / 2052 total\n",
            "Random stratified val set: 40 anemic / 343 total\n",
            "Random stratified test set: 40 anemic / 343 total\n",
            "Original test set: 35 anemic / 305 total\n",
            "\n",
            "===== Processing LEFT resolution: 224 =====\n",
            "\n",
            "--- LEFT Fold 1 ---\n",
            "Epoch [10/120] Loss: 16.998985\n",
            "Epoch [20/120] Loss: 6.071345\n",
            "Epoch [30/120] Loss: 3.970397\n",
            "Epoch [40/120] Loss: 1.434303\n",
            "Epoch [50/120] Loss: 1.165084\n",
            "Epoch [60/120] Loss: 0.239665\n",
            "Epoch [70/120] Loss: 1.501746\n",
            "Epoch [80/120] Loss: 1.223256\n",
            "Epoch [90/120] Loss: 1.009799\n",
            "Epoch [100/120] Loss: 0.134725\n",
            "Epoch [110/120] Loss: 0.435632\n",
            "Epoch [120/120] Loss: 0.359815\n",
            "[{'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9130434782608695, 'Val_Recall': 0.875, 'Val_F1': 0.8936170212765957, 'Val_Accuracy': 0.975669099756691, 'Val_AUC': 0.9942607897153353, 'Val_TP': 42, 'Val_TN': 359, 'Val_FP': 4, 'Val_FN': 6}]\n",
            "\n",
            "--- LEFT Fold 2 ---\n",
            "Epoch [10/120] Loss: 14.913998\n",
            "Epoch [20/120] Loss: 5.938978\n",
            "Epoch [30/120] Loss: 2.690935\n",
            "Epoch [40/120] Loss: 3.187557\n",
            "Epoch [50/120] Loss: 1.029294\n",
            "Epoch [60/120] Loss: 0.336979\n",
            "Epoch [70/120] Loss: 0.837190\n",
            "Epoch [80/120] Loss: 1.162193\n",
            "Epoch [90/120] Loss: 0.107358\n",
            "Epoch [100/120] Loss: 0.638433\n",
            "Epoch [110/120] Loss: 0.082100\n",
            "Epoch [120/120] Loss: 0.062758\n",
            "[{'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9130434782608695, 'Val_Recall': 0.875, 'Val_F1': 0.8936170212765957, 'Val_Accuracy': 0.975669099756691, 'Val_AUC': 0.9942607897153353, 'Val_TP': 42, 'Val_TN': 359, 'Val_FP': 4, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.875, 'Val_F1': 0.9130434782608695, 'Val_Accuracy': 0.9805352798053528, 'Val_AUC': 0.9981060606060606, 'Val_TP': 42, 'Val_TN': 361, 'Val_FP': 2, 'Val_FN': 6}]\n",
            "\n",
            "--- LEFT Fold 3 ---\n",
            "Epoch [10/120] Loss: 16.296415\n",
            "Epoch [20/120] Loss: 9.271016\n",
            "Epoch [30/120] Loss: 3.993763\n",
            "Epoch [40/120] Loss: 1.401848\n",
            "Epoch [50/120] Loss: 1.526306\n",
            "Epoch [60/120] Loss: 1.536956\n",
            "Epoch [70/120] Loss: 1.545300\n",
            "Epoch [80/120] Loss: 0.392623\n",
            "Epoch [90/120] Loss: 0.439868\n",
            "Epoch [100/120] Loss: 1.014997\n",
            "Epoch [110/120] Loss: 0.703980\n",
            "Epoch [120/120] Loss: 0.702002\n",
            "[{'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9130434782608695, 'Val_Recall': 0.875, 'Val_F1': 0.8936170212765957, 'Val_Accuracy': 0.975669099756691, 'Val_AUC': 0.9942607897153353, 'Val_TP': 42, 'Val_TN': 359, 'Val_FP': 4, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.875, 'Val_F1': 0.9130434782608695, 'Val_Accuracy': 0.9805352798053528, 'Val_AUC': 0.9981060606060606, 'Val_TP': 42, 'Val_TN': 361, 'Val_FP': 2, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.8444444444444444, 'Val_Recall': 0.8085106382978723, 'Val_F1': 0.8260869565217391, 'Val_Accuracy': 0.9609756097560975, 'Val_AUC': 0.9887462634077722, 'Val_TP': 38, 'Val_TN': 356, 'Val_FP': 7, 'Val_FN': 9}]\n",
            "\n",
            "--- LEFT Fold 4 ---\n",
            "Epoch [10/120] Loss: 14.929973\n",
            "Epoch [20/120] Loss: 5.578956\n",
            "Epoch [30/120] Loss: 2.707667\n",
            "Epoch [40/120] Loss: 1.246541\n",
            "Epoch [50/120] Loss: 0.938727\n",
            "Epoch [60/120] Loss: 0.875788\n",
            "Epoch [70/120] Loss: 0.817563\n",
            "Epoch [80/120] Loss: 0.552132\n",
            "Epoch [90/120] Loss: 1.164564\n",
            "Epoch [100/120] Loss: 0.390270\n",
            "Epoch [110/120] Loss: 0.152268\n",
            "Epoch [120/120] Loss: 0.288216\n",
            "[{'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9130434782608695, 'Val_Recall': 0.875, 'Val_F1': 0.8936170212765957, 'Val_Accuracy': 0.975669099756691, 'Val_AUC': 0.9942607897153353, 'Val_TP': 42, 'Val_TN': 359, 'Val_FP': 4, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.875, 'Val_F1': 0.9130434782608695, 'Val_Accuracy': 0.9805352798053528, 'Val_AUC': 0.9981060606060606, 'Val_TP': 42, 'Val_TN': 361, 'Val_FP': 2, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.8444444444444444, 'Val_Recall': 0.8085106382978723, 'Val_F1': 0.8260869565217391, 'Val_Accuracy': 0.9609756097560975, 'Val_AUC': 0.9887462634077722, 'Val_TP': 38, 'Val_TN': 356, 'Val_FP': 7, 'Val_FN': 9}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.8070175438596491, 'Val_Recall': 0.9787234042553191, 'Val_F1': 0.8846153846153846, 'Val_Accuracy': 0.9707317073170731, 'Val_AUC': 0.9966004337377645, 'Val_TP': 46, 'Val_TN': 352, 'Val_FP': 11, 'Val_FN': 1}]\n",
            "\n",
            "--- LEFT Fold 5 ---\n",
            "Epoch [10/120] Loss: 16.909315\n",
            "Epoch [20/120] Loss: 7.001933\n",
            "Epoch [30/120] Loss: 3.300245\n",
            "Epoch [40/120] Loss: 1.884799\n",
            "Epoch [50/120] Loss: 1.899182\n",
            "Epoch [60/120] Loss: 1.708817\n",
            "Epoch [70/120] Loss: 1.523132\n",
            "Epoch [80/120] Loss: 0.166794\n",
            "Epoch [90/120] Loss: 0.060761\n",
            "Epoch [100/120] Loss: 0.638803\n",
            "Epoch [110/120] Loss: 0.364645\n",
            "Epoch [120/120] Loss: 0.220627\n",
            "[{'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9130434782608695, 'Val_Recall': 0.875, 'Val_F1': 0.8936170212765957, 'Val_Accuracy': 0.975669099756691, 'Val_AUC': 0.9942607897153353, 'Val_TP': 42, 'Val_TN': 359, 'Val_FP': 4, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.875, 'Val_F1': 0.9130434782608695, 'Val_Accuracy': 0.9805352798053528, 'Val_AUC': 0.9981060606060606, 'Val_TP': 42, 'Val_TN': 361, 'Val_FP': 2, 'Val_FN': 6}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.8444444444444444, 'Val_Recall': 0.8085106382978723, 'Val_F1': 0.8260869565217391, 'Val_Accuracy': 0.9609756097560975, 'Val_AUC': 0.9887462634077722, 'Val_TP': 38, 'Val_TN': 356, 'Val_FP': 7, 'Val_FN': 9}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.8070175438596491, 'Val_Recall': 0.9787234042553191, 'Val_F1': 0.8846153846153846, 'Val_Accuracy': 0.9707317073170731, 'Val_AUC': 0.9966004337377645, 'Val_TP': 46, 'Val_TN': 352, 'Val_FP': 11, 'Val_FN': 1}, {'EyeSet': 'LEFT', 'Resolution': 224, 'Fold': 5, 'Val_Precision': 0.9545454545454546, 'Val_Recall': 0.8936170212765957, 'Val_F1': 0.9230769230769231, 'Val_Accuracy': 0.9829268292682927, 'Val_AUC': 0.9973037922747787, 'Val_TP': 42, 'Val_TN': 361, 'Val_FP': 2, 'Val_FN': 5}]\n",
            "âœ… Best fold = 5\n",
            "\n",
            "ðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type\n",
            "          5           0.875        0.875    0.875       0.970845  0.994554       35      298        5        5 Random_Stratified\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/detailed_predictions_pytorch.csv\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting to ONNX...\n",
            "   âœ… ONNX saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_model.onnx\n",
            "2. ONNX -> TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) input, x, y with unsupported characters which will be renamed to onnx_tf_prefix_identity_49_input, transpose_187_x, onnx_tf_prefix__fusion_fusion_1_add_1_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TF SavedModel saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model\n",
            "3. TF -> TFLite (SELECT_TF_OPS)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 05:40:36.678763: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-18 05:40:36.678806: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-18 05:40:36.683671: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model\n",
            "2025-11-18 05:40:36.724432: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-18 05:40:36.724453: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model\n",
            "2025-11-18 05:40:36.758856: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-18 05:40:36.841169: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_tf_model\n",
            "2025-11-18 05:40:36.882144: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 198478 microseconds.\n",
            "2025-11-18 05:40:37.624506: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
            "Flex ops: FlexErf\n",
            "Details:\n",
            "\ttf.Erf(tensor<1x128xf32>) -> (tensor<1x128xf32>) : {device = \"\"}\n",
            "\ttf.Erf(tensor<1x512xf32>) -> (tensor<1x512xf32>) : {device = \"\"}\n",
            "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
            "2025-11-18 05:40:37.624559: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 10.898 G  ops, equivalently 5.449 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_eye_resnet18_shared_stratified.tflite (45.92 MB)\n",
            "\n",
            "ðŸŽ‰ SUCCESS! Final TFLite model size: 45.92 MB\n",
            "ðŸ“ Path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/tri_left_eye_resnet18_shared_stratified.tflite\n",
            "\n",
            "ðŸ” Re-evaluating TFLite model on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
            "2025-11-18 05:40:38.236075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-18 05:40:38.237343: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 285 nodes with 2 partitions.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0']\n",
            "   âž¤ Detected layout: NCHW, size: 224x224\n",
            "\n",
            "ðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type  Source\n",
            "        5.0           0.875        0.875    0.875       0.970845  0.994554       35      298        5        5 Random_Stratified PyTorch\n",
            "        NaN           0.875        0.875    0.875       0.970845  0.994554       35      298        5        5 Random_Stratified  TFLite\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified/detailed_predictions_tflite.csv\n",
            "âœ… TFLite results MATCH PyTorch within tolerance.\n",
            "\n",
            "âœ… Pipeline completed. Model evaluated on random stratified test set with shared backbone.\n",
            "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye_hb_90_repro_bestfold_only_shared_stratified\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Tri-left-Eye ResNet18 with SHARED BACKBONE & TFLite Verification\n",
        "----------------------------------------------------------------------------------\n",
        "âœ… Shared ResNet18 across 3 inputs â†’ ~45 MB TFLite\n",
        "âœ… TFLite export with SELECT_TF_OPS (GELU via FlexDelegate)\n",
        "âœ… Re-evaluates .tflite file and compares results with PyTorch\n",
        "âœ… Ensures no silent divergence between frameworks\n",
        "âœ… Added random stratified test split for robustness evaluation\n",
        "âœ… Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "âœ… Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 224\n",
        "EPOCHS_CV = 120\n",
        "BATCH_CV = 24\n",
        "LR_CV = 0.00017\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "set_global_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    try:\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"tri_left_eye_hb_90_repro_bestfold_only_shared_stratified\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_left(dirs_map):\n",
        "    suffixes = {'left1': '_left_eye_1.png', 'left2': '_left_eye_2.png', 'left3': '_left_eye_3.png'}\n",
        "    bases_sets = []\n",
        "    for k in ['left1', 'left2', 'left3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    inter = set.intersection(*bases_sets)\n",
        "    return sorted(inter)\n",
        "\n",
        "def load_tri_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': [], 'filenames': []}\n",
        "    key_map = {'r1': ('left1', '_left_eye_1.png'), 'r2': ('left2', '_left_eye_2.png'), 'r3': ('left3', '_left_eye_3.png')}\n",
        "    for b in bases:\n",
        "        imgs, failed = {}, False\n",
        "        for short_k, (long_k, suf) in key_map.items():\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[short_k] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if not failed:\n",
        "            out['r1'].append(imgs['r1'])\n",
        "            out['r2'].append(imgs['r2'])\n",
        "            out['r3'].append(imgs['r3'])\n",
        "            out['filenames'].append(b)  # Use base name as identifier\n",
        "    return out\n",
        "\n",
        "def prepare_dataset_left_with_filenames(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_a = common_bases_left(anemic_dirs)\n",
        "    bases_n = common_bases_left(non_dirs)\n",
        "    imgs_a = load_tri_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_tri_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "\n",
        "    # Combine anemic and non-anemic data\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… {split_name}: anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    try:\n",
        "        df_bases = pd.DataFrame({'class': ['anemic']*len(bases_a) + ['non_anemic']*len(bases_n),\n",
        "                                 'base_id': bases_a + bases_n})\n",
        "        df_bases.to_csv(os.path.join(output_dir, f\"{split_name.lower()}_used_base_ids_left.csv\"), index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return data\n",
        "\n",
        "def count_files(d):\n",
        "    return sum(1 for f in sorted(os.listdir(d)) if f.endswith(\".png\")) if os.path.isdir(d) else 0\n",
        "\n",
        "def print_dir_stats(title, dirs_map):\n",
        "    print(f\"\\nðŸ“‚ {title}\")\n",
        "    for k in ['left1','left2','left3']:\n",
        "        p = dirs_map[k]; c = count_files(p)\n",
        "        print(f\"{k:7s} | {p} | files={c}\")\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "\n",
        "print_dir_stats(\"TEST  anemic (LEFT)\", test_dirs_anemic)\n",
        "print_dir_stats(\"TEST  non-anemic (LEFT)\", test_dirs_non)\n",
        "\n",
        "train_data = prepare_dataset_left_with_filenames(train_dirs_anemic, train_dirs_non, split_name=\"TRAIN\")\n",
        "val_data   = prepare_dataset_left_with_filenames(val_dirs_anemic,   val_dirs_non,   split_name=\"VAL\")\n",
        "test_data  = prepare_dataset_left_with_filenames(test_dirs_anemic,  test_dirs_non,  split_name=\"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No tri-left-eye TRAIN samples found.\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_r1 = train_data['r1'] + val_data['r1'] + test_data['r1']\n",
        "all_r2 = train_data['r2'] + val_data['r2'] + test_data['r2']\n",
        "all_r3 = train_data['r3'] + val_data['r3'] + test_data['r3']\n",
        "all_filenames = train_data['filenames'] + val_data['filenames'] + test_data['filenames']\n",
        "all_labels = train_data['label'] + val_data['label'] + test_data['label']\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp_r1, X_test_strat_r1, X_temp_r2, X_test_strat_r2, X_temp_r3, X_test_strat_r3, fname_temp, fname_test_strat, y_temp, y_test_strat = train_test_split(\n",
        "    all_r1, all_r2, all_r3, all_filenames, all_labels,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_labels,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat_r1, X_val_strat_r1, X_train_strat_r2, X_val_strat_r2, X_train_strat_r3, X_val_strat_r3, fname_train_strat, fname_val_strat, y_train_strat, y_val_strat = train_test_split(\n",
        "    X_temp_r1, X_temp_r2, X_temp_r3, fname_temp, y_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "strat_train_data = {\n",
        "    'r1': X_train_strat_r1,\n",
        "    'r2': X_train_strat_r2,\n",
        "    'r3': X_train_strat_r3,\n",
        "    'filenames': fname_train_strat,\n",
        "    'label': y_train_strat\n",
        "}\n",
        "\n",
        "strat_val_data = {\n",
        "    'r1': X_val_strat_r1,\n",
        "    'r2': X_val_strat_r2,\n",
        "    'r3': X_val_strat_r3,\n",
        "    'filenames': fname_val_strat,\n",
        "    'label': y_val_strat\n",
        "}\n",
        "\n",
        "strat_test_data = {\n",
        "    'r1': X_test_strat_r1,\n",
        "    'r2': X_test_strat_r2,\n",
        "    'r3': X_test_strat_r3,\n",
        "    'filenames': fname_test_strat,\n",
        "    'label': y_test_strat\n",
        "}\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_data['label'])} anemic / {len(test_data['label'])} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class TrileftDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[k][idx] for k in ['r1','r2','r3']]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        return images, label\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type=='cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL: SHARED RESNET18 BACKBONE\n",
        "# =========================\n",
        "class TriResNetleft(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(3 * 512, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        f1 = self.backbone(x1)\n",
        "        f2 = self.backbone(x2)\n",
        "        f3 = self.backbone(x3)\n",
        "        x = torch.cat([f1, f2, f3], dim=1)\n",
        "        return self.fusion(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION (PyTorch) WITH PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        x1, x2, x3 = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(x1, x2, x3)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(all_labels) == 0 or len(set(all_labels)) < 2:\n",
        "        return [float('nan')] * 9 + [all_labels, all_probs, all_filenames, all_preds]\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(best_model: nn.Module, output_dir: str, resolution: int, tflite_filename: str):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    best_model.eval().to('cpu')\n",
        "    dummy_inputs = tuple(torch.randn(1, 3, resolution, resolution) for _ in range(3))\n",
        "    onnx_path = os.path.join(output_dir, \"tri_left_model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tri_left_tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, tflite_filename)\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # Step 1: PyTorch -> ONNX\n",
        "    print(\"1. Converting to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            best_model,\n",
        "            dummy_inputs,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input1', 'input2', 'input3'],\n",
        "            output_names=['output']\n",
        "        )\n",
        "        print(f\"   âœ… ONNX saved: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: ONNX -> TensorFlow\n",
        "    print(\"2. ONNX -> TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        if os.path.exists(tf_path):\n",
        "            import shutil\n",
        "            shutil.rmtree(tf_path)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TF SavedModel saved: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: TF -> TFLite with SELECT_TF_OPS\n",
        "    print(\"3. TF -> TFLite (SELECT_TF_OPS)...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"   âœ… TFLite saved: {tflite_path} ({size_mb:.2f} MB)\")\n",
        "        return tflite_path\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Conversion failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# TFLITE RE-EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data, resolution):\n",
        "    import tensorflow as tf\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” TFLite input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) == 4:\n",
        "        if first_shape[1] == 3:  # [B,C,H,W]\n",
        "            layout = 'NCHW'\n",
        "        else:  # [B,H,W,C]\n",
        "            layout = 'NHWC'\n",
        "\n",
        "    resize_h, resize_w = int(first_shape[1] if layout == 'NHWC' else first_shape[2]), \\\n",
        "                         int(first_shape[2] if layout == 'NHWC' else first_shape[3])\n",
        "\n",
        "    print(f\"   âž¤ Detected layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        img_resized = img_pil.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(img_resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, all_filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    for i in range(len(test_data['label'])):\n",
        "        imgs = [test_data['r1'][i], test_data['r2'][i], test_data['r3'][i]]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            raw_img = imgs[idx]\n",
        "            processed = preprocess_pil_style(raw_img)\n",
        "\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        logit = float(np.array(output).reshape(-1)[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        auc = float('nan')\n",
        "    else:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN TRAINING LOOP\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    resolution = RESOLUTION\n",
        "    results = []\n",
        "    cv_index_records = []\n",
        "\n",
        "    print(f\"\\n===== Processing LEFT resolution: {resolution} =====\")\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(strat_train_data['label'])\n",
        "\n",
        "    fold = 1\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- LEFT Fold {fold} ---\")\n",
        "        cv_index_records.append({\"fold\": fold, \"train_indices\": train_idx.tolist(), \"val_indices\": val_idx.tolist()})\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in strat_train_data.items()}\n",
        "        val_subset   = {k: [v[i] for i in val_idx]   for k, v in strat_train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(TrileftDataset(train_subset, train_transform), BATCH_CV, True)\n",
        "        val_loader   = make_loader(TrileftDataset(val_subset,   test_transform),  BATCH_CV, False)\n",
        "\n",
        "        model = TriResNetleft().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in train_loader:\n",
        "                x1, x2, x3 = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(x1, x2, x3)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] Loss: {total_loss:.6f}\")\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, val_loader, val_subset['filenames'])\n",
        "        result_row = {\n",
        "            'EyeSet': 'LEFT',\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8]\n",
        "        }\n",
        "        results.append(result_row)\n",
        "        print(results)\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"left_cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({'model_state': model.state_dict()}, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save CV results\n",
        "    pd.DataFrame(results).to_csv(os.path.join(output_dir, \"left_val_cross_validation_results.csv\"), index=False)\n",
        "    with open(os.path.join(output_dir, \"left_cv_indices.json\"), \"w\") as f:\n",
        "        json.dump(cv_index_records, f, indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df['Val_Precision'] >= 0.90) & (df['Val_Recall'] >= 0.90)]\n",
        "    best = candidates.sort_values(['Val_F1'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "           df.sort_values(['minPR','Val_F1'], ascending=False).iloc[0]\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # Load best model\n",
        "    ckpt_path = os.path.join(output_dir, f\"left_cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    best_model = TriResNetleft().to(device)\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Test evaluation (PyTorch) - Random Stratified Test Set\n",
        "    test_loader_strat = make_loader(TrileftDataset(strat_test_data, test_transform), BATCH_CV, False)\n",
        "    test_metrics_strat = evaluate_with_predictions(best_model, test_loader_strat, strat_test_data['filenames'])\n",
        "\n",
        "    test_results_df = pd.DataFrame([{\n",
        "        'ChosenFold': best_fold,\n",
        "        'Test_Precision': test_metrics_strat[0],\n",
        "        'Test_Recall': test_metrics_strat[1],\n",
        "        'Test_F1': test_metrics_strat[2],\n",
        "        'Test_Accuracy': test_metrics_strat[3],\n",
        "        'Test_AUC': test_metrics_strat[4],\n",
        "        'Test_TP': test_metrics_strat[5],\n",
        "        'Test_TN': test_metrics_strat[6],\n",
        "        'Test_FP': test_metrics_strat[7],\n",
        "        'Test_FN': test_metrics_strat[8],\n",
        "        'Test_Type': 'Random_Stratified'\n",
        "    }])\n",
        "    test_results_df.to_csv(os.path.join(output_dir, \"left_bestfold_test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    print(\"\\nðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\")\n",
        "    print(test_results_df.to_string(index=False))\n",
        "\n",
        "    # Save detailed PyTorch predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(output_dir, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(output_dir, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(output_dir, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    # Convert to TFLite\n",
        "    tflite_filename = \"tri_left_eye_resnet18_shared_stratified.tflite\"\n",
        "    tflite_path = convert_to_tflite(best_model.cpu(), output_dir, resolution, tflite_filename)\n",
        "\n",
        "    if tflite_path:\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"\\nðŸŽ‰ SUCCESS! Final TFLite model size: {size_mb:.2f} MB\")\n",
        "        print(f\"ðŸ“ Path: {tflite_path}\")\n",
        "\n",
        "        # --- ðŸ” Re-evaluate TFLite model on random stratified test set ---\n",
        "        print(\"\\nðŸ” Re-evaluating TFLite model on random stratified test set...\")\n",
        "        try:\n",
        "            tflite_metrics = evaluate_tflite_model_with_predictions(tflite_path, strat_test_data, resolution)\n",
        "            tflite_results_df = pd.DataFrame([{\n",
        "                'Source': 'TFLite',\n",
        "                'Test_Precision': tflite_metrics[0],\n",
        "                'Test_Recall': tflite_metrics[1],\n",
        "                'Test_F1': tflite_metrics[2],\n",
        "                'Test_Accuracy': tflite_metrics[3],\n",
        "                'Test_AUC': tflite_metrics[4],\n",
        "                'Test_TP': tflite_metrics[5],\n",
        "                'Test_TN': tflite_metrics[6],\n",
        "                'Test_FP': tflite_metrics[7],\n",
        "                'Test_FN': tflite_metrics[8],\n",
        "                'Test_Type': 'Random_Stratified'\n",
        "            }])\n",
        "\n",
        "            combined = pd.concat([\n",
        "                test_results_df.assign(Source='PyTorch'),\n",
        "                tflite_results_df\n",
        "            ], ignore_index=True)\n",
        "\n",
        "            print(\"\\nðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\")\n",
        "            print(combined.to_string(index=False))\n",
        "            combined.to_csv(os.path.join(output_dir, \"pytorch_vs_tflite_comparison_stratified.csv\"), index=False)\n",
        "\n",
        "            # Save detailed TFLite predictions to CSV\n",
        "            save_predictions_to_csv(\n",
        "                tflite_metrics[11],  # filenames\n",
        "                tflite_metrics[9],   # true labels\n",
        "                tflite_metrics[12],  # pred labels\n",
        "                tflite_metrics[10],  # pred probs\n",
        "                os.path.join(output_dir, \"detailed_predictions_tflite.csv\")\n",
        "            )\n",
        "\n",
        "            # Plot ROC curve and confusion matrix for TFLite model\n",
        "            plot_roc_curve(tflite_metrics[9], tflite_metrics[10],\n",
        "                           \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                           os.path.join(output_dir, \"roc_curve_tflite.png\"))\n",
        "            plot_confusion_matrix(tflite_metrics[9],\n",
        "                                  tflite_metrics[12],\n",
        "                                  \"Confusion Matrix - TFLite Model\",\n",
        "                                  os.path.join(output_dir, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(test_results_df.iloc[0].to_dict(), tflite_metrics,\n",
        "                                   os.path.join(output_dir, \"metrics_comparison.png\"))\n",
        "\n",
        "            tol = 1e-3\n",
        "            if (abs(tflite_metrics[2] - test_metrics_strat[2]) < tol and\n",
        "                abs(tflite_metrics[4] - test_metrics_strat[4]) < tol):\n",
        "                print(\"âœ… TFLite results MATCH PyTorch within tolerance.\")\n",
        "            else:\n",
        "                print(\"âš ï¸ WARNING: TFLite results differ significantly from PyTorch!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ TFLite evaluation failed: {e}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite conversion failed.\")\n",
        "\n",
        "    print(\"\\nâœ… Pipeline completed. Model evaluated on random stratified test set with shared backbone.\")\n",
        "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891aa87d-4c87-48a7-963c-02d9bec00f00",
      "metadata": {
        "id": "891aa87d-4c87-48a7-963c-02d9bec00f00",
        "outputId": "1e26b1e6-d272-40d5-dd3a-4ab7f10e7326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ðŸ“‚ TEST  anemic (right)\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "\n",
            "ðŸ“‚ TEST  non-anemic (right)\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=322\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=329\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=328\n",
            "âœ… TRAIN: anemic=248, non-anemic=1907, total=2155\n",
            "âœ… VAL: anemic=37, non-anemic=298, total=335\n",
            "âœ… TEST: anemic=34, non-anemic=284, total=318\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 239 anemic / 2106 total\n",
            "Random stratified val set: 40 anemic / 351 total\n",
            "Random stratified test set: 40 anemic / 351 total\n",
            "Original test set: 34 anemic / 318 total\n",
            "\n",
            "===== Processing right resolution: 224 =====\n",
            "\n",
            "--- right Fold 1 ---\n",
            "Epoch [10/150] Loss: 18.414652\n",
            "Epoch [20/150] Loss: 11.064136\n",
            "Epoch [30/150] Loss: 4.808266\n",
            "Epoch [40/150] Loss: 3.884744\n",
            "Epoch [50/150] Loss: 1.784923\n",
            "Epoch [60/150] Loss: 0.640957\n",
            "Epoch [70/150] Loss: 1.234614\n",
            "Epoch [80/150] Loss: 0.354699\n",
            "Epoch [90/150] Loss: 0.887796\n",
            "Epoch [100/150] Loss: 0.570219\n",
            "Epoch [110/150] Loss: 0.628602\n",
            "Epoch [120/150] Loss: 0.042622\n",
            "Epoch [130/150] Loss: 0.197461\n",
            "Epoch [140/150] Loss: 0.340961\n",
            "Epoch [150/150] Loss: 0.363196\n",
            "[{'EyeSet': 'right', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 1.0, 'Val_Recall': 0.8333333333333334, 'Val_F1': 0.9090909090909091, 'Val_Accuracy': 0.981042654028436, 'Val_AUC': 0.9992201426024956, 'Val_TP': 40, 'Val_TN': 374, 'Val_FP': 0, 'Val_FN': 8}]\n",
            "\n",
            "--- right Fold 2 ---\n",
            "Epoch [10/150] Loss: 16.672193\n",
            "Epoch [20/150] Loss: 10.501110\n",
            "Epoch [30/150] Loss: 3.395845\n",
            "Epoch [40/150] Loss: 4.257673\n",
            "Epoch [50/150] Loss: 0.437571\n",
            "Epoch [60/150] Loss: 1.338536\n",
            "Epoch [70/150] Loss: 0.889269\n",
            "Epoch [80/150] Loss: 0.997270\n",
            "Epoch [90/150] Loss: 0.058970\n",
            "Epoch [100/150] Loss: 2.526225\n",
            "Epoch [110/150] Loss: 0.102595\n",
            "Epoch [120/150] Loss: 0.278480\n",
            "Epoch [130/150] Loss: 0.044875\n",
            "Epoch [140/150] Loss: 0.418600\n",
            "Epoch [150/150] Loss: 0.244873\n",
            "[{'EyeSet': 'right', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 1.0, 'Val_Recall': 0.8333333333333334, 'Val_F1': 0.9090909090909091, 'Val_Accuracy': 0.981042654028436, 'Val_AUC': 0.9992201426024956, 'Val_TP': 40, 'Val_TN': 374, 'Val_FP': 0, 'Val_FN': 8}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9782608695652174, 'Val_Recall': 0.9574468085106383, 'Val_F1': 0.967741935483871, 'Val_Accuracy': 0.9928741092636579, 'Val_AUC': 0.9986346569575606, 'Val_TP': 45, 'Val_TN': 373, 'Val_FP': 1, 'Val_FN': 2}]\n",
            "\n",
            "--- right Fold 3 ---\n",
            "Epoch [10/150] Loss: 17.536136\n",
            "Epoch [20/150] Loss: 10.656889\n",
            "Epoch [30/150] Loss: 2.331328\n",
            "Epoch [40/150] Loss: 0.837087\n",
            "Epoch [50/150] Loss: 1.576985\n",
            "Epoch [60/150] Loss: 0.157027\n",
            "Epoch [70/150] Loss: 0.251380\n",
            "Epoch [80/150] Loss: 0.024903\n",
            "Epoch [90/150] Loss: 0.784159\n",
            "Epoch [100/150] Loss: 0.046316\n",
            "Epoch [110/150] Loss: 0.868532\n",
            "Epoch [120/150] Loss: 0.017866\n",
            "Epoch [130/150] Loss: 0.417235\n",
            "Epoch [140/150] Loss: 0.223364\n",
            "Epoch [150/150] Loss: 0.281329\n",
            "[{'EyeSet': 'right', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 1.0, 'Val_Recall': 0.8333333333333334, 'Val_F1': 0.9090909090909091, 'Val_Accuracy': 0.981042654028436, 'Val_AUC': 0.9992201426024956, 'Val_TP': 40, 'Val_TN': 374, 'Val_FP': 0, 'Val_FN': 8}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9782608695652174, 'Val_Recall': 0.9574468085106383, 'Val_F1': 0.967741935483871, 'Val_Accuracy': 0.9928741092636579, 'Val_AUC': 0.9986346569575606, 'Val_TP': 45, 'Val_TN': 373, 'Val_FP': 1, 'Val_FN': 2}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.94, 'Val_Recall': 0.9791666666666666, 'Val_F1': 0.9591836734693877, 'Val_Accuracy': 0.9904988123515439, 'Val_AUC': 0.9996648793565683, 'Val_TP': 47, 'Val_TN': 370, 'Val_FP': 3, 'Val_FN': 1}]\n",
            "\n",
            "--- right Fold 4 ---\n",
            "Epoch [10/150] Loss: 17.273498\n",
            "Epoch [20/150] Loss: 6.878223\n",
            "Epoch [30/150] Loss: 2.599668\n",
            "Epoch [40/150] Loss: 1.162973\n",
            "Epoch [50/150] Loss: 1.582364\n",
            "Epoch [60/150] Loss: 0.281414\n",
            "Epoch [70/150] Loss: 0.601167\n",
            "Epoch [80/150] Loss: 0.305611\n",
            "Epoch [90/150] Loss: 0.534496\n",
            "Epoch [100/150] Loss: 0.438588\n",
            "Epoch [110/150] Loss: 0.371694\n",
            "Epoch [120/150] Loss: 0.367382\n",
            "Epoch [130/150] Loss: 0.192298\n",
            "Epoch [140/150] Loss: 0.041165\n",
            "Epoch [150/150] Loss: 0.048454\n",
            "[{'EyeSet': 'right', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 1.0, 'Val_Recall': 0.8333333333333334, 'Val_F1': 0.9090909090909091, 'Val_Accuracy': 0.981042654028436, 'Val_AUC': 0.9992201426024956, 'Val_TP': 40, 'Val_TN': 374, 'Val_FP': 0, 'Val_FN': 8}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9782608695652174, 'Val_Recall': 0.9574468085106383, 'Val_F1': 0.967741935483871, 'Val_Accuracy': 0.9928741092636579, 'Val_AUC': 0.9986346569575606, 'Val_TP': 45, 'Val_TN': 373, 'Val_FP': 1, 'Val_FN': 2}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.94, 'Val_Recall': 0.9791666666666666, 'Val_F1': 0.9591836734693877, 'Val_Accuracy': 0.9904988123515439, 'Val_AUC': 0.9996648793565683, 'Val_TP': 47, 'Val_TN': 370, 'Val_FP': 3, 'Val_FN': 1}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.9722222222222222, 'Val_Recall': 0.7291666666666666, 'Val_F1': 0.8333333333333333, 'Val_Accuracy': 0.9667458432304038, 'Val_AUC': 0.995420017873101, 'Val_TP': 35, 'Val_TN': 372, 'Val_FP': 1, 'Val_FN': 13}]\n",
            "\n",
            "--- right Fold 5 ---\n",
            "Epoch [10/150] Loss: 17.117854\n",
            "Epoch [20/150] Loss: 10.274195\n",
            "Epoch [30/150] Loss: 2.981957\n",
            "Epoch [40/150] Loss: 0.838288\n",
            "Epoch [50/150] Loss: 0.563729\n",
            "Epoch [60/150] Loss: 0.381442\n",
            "Epoch [70/150] Loss: 0.289198\n",
            "Epoch [80/150] Loss: 0.694586\n",
            "Epoch [90/150] Loss: 0.047483\n",
            "Epoch [100/150] Loss: 0.039237\n",
            "Epoch [110/150] Loss: 0.884003\n",
            "Epoch [120/150] Loss: 0.032211\n",
            "Epoch [130/150] Loss: 0.014954\n",
            "Epoch [140/150] Loss: 0.468877\n",
            "Epoch [150/150] Loss: 0.175198\n",
            "[{'EyeSet': 'right', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 1.0, 'Val_Recall': 0.8333333333333334, 'Val_F1': 0.9090909090909091, 'Val_Accuracy': 0.981042654028436, 'Val_AUC': 0.9992201426024956, 'Val_TP': 40, 'Val_TN': 374, 'Val_FP': 0, 'Val_FN': 8}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9782608695652174, 'Val_Recall': 0.9574468085106383, 'Val_F1': 0.967741935483871, 'Val_Accuracy': 0.9928741092636579, 'Val_AUC': 0.9986346569575606, 'Val_TP': 45, 'Val_TN': 373, 'Val_FP': 1, 'Val_FN': 2}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.94, 'Val_Recall': 0.9791666666666666, 'Val_F1': 0.9591836734693877, 'Val_Accuracy': 0.9904988123515439, 'Val_AUC': 0.9996648793565683, 'Val_TP': 47, 'Val_TN': 370, 'Val_FP': 3, 'Val_FN': 1}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.9722222222222222, 'Val_Recall': 0.7291666666666666, 'Val_F1': 0.8333333333333333, 'Val_Accuracy': 0.9667458432304038, 'Val_AUC': 0.995420017873101, 'Val_TP': 35, 'Val_TN': 372, 'Val_FP': 1, 'Val_FN': 13}, {'EyeSet': 'right', 'Resolution': 224, 'Fold': 5, 'Val_Precision': 0.9574468085106383, 'Val_Recall': 0.9375, 'Val_F1': 0.9473684210526315, 'Val_Accuracy': 0.9881235154394299, 'Val_AUC': 0.9993856121537087, 'Val_TP': 45, 'Val_TN': 371, 'Val_FP': 2, 'Val_FN': 3}]\n",
            "âœ… Best fold = 2\n",
            "\n",
            "ðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type\n",
            "          2            0.95         0.95     0.95       0.988604  0.999116       38      309        2        2 Random_Stratified\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/detailed_predictions_pytorch.csv\n",
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting to ONNX...\n",
            "   âœ… ONNX saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_model.onnx\n",
            "2. ONNX -> TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Function `__call__` contains input name(s) input, x, y with unsupported characters which will be renamed to onnx_tf_prefix_identity_49_input, transpose_187_x, onnx_tf_prefix__fusion_fusion_1_add_1_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TF SavedModel saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model\n",
            "3. TF -> TFLite (SELECT_TF_OPS)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 07:56:01.385865: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-18 07:56:01.385897: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-18 07:56:01.387503: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model\n",
            "2025-11-18 07:56:01.423259: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-18 07:56:01.423282: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model\n",
            "2025-11-18 07:56:01.438857: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-18 07:56:01.479790: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_tf_model\n",
            "2025-11-18 07:56:01.520477: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 132979 microseconds.\n",
            "2025-11-18 07:56:02.225564: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
            "Flex ops: FlexErf\n",
            "Details:\n",
            "\ttf.Erf(tensor<1x128xf32>) -> (tensor<1x128xf32>) : {device = \"\"}\n",
            "\ttf.Erf(tensor<1x512xf32>) -> (tensor<1x512xf32>) : {device = \"\"}\n",
            "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
            "2025-11-18 07:56:02.225617: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 10.898 G  ops, equivalently 5.449 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_eye_resnet18_shared_stratified.tflite (45.92 MB)\n",
            "\n",
            "ðŸŽ‰ SUCCESS! Final TFLite model size: 45.92 MB\n",
            "ðŸ“ Path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/tri_right_eye_resnet18_shared_stratified.tflite\n",
            "\n",
            "ðŸ” Re-evaluating TFLite model on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 07:56:02.659680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-18 07:56:02.660962: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0']\n",
            "   âž¤ Detected layout: NCHW, size: 224x224\n",
            "\n",
            "ðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type  Source\n",
            "        2.0            0.95         0.95     0.95       0.988604  0.999116       38      309        2        2 Random_Stratified PyTorch\n",
            "        NaN            0.95         0.95     0.95       0.988604  0.999116       38      309        2        2 Random_Stratified  TFLite\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified/detailed_predictions_tflite.csv\n",
            "âœ… TFLite results MATCH PyTorch within tolerance.\n",
            "\n",
            "âœ… Pipeline completed. Model evaluated on random stratified test set with shared backbone.\n",
            "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye_hb_90_repro_bestfold_only_shared_stratified\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Tri-right-Eye ResNet18 with SHARED BACKBONE & TFLite Verification\n",
        "----------------------------------------------------------------------------------\n",
        "âœ… Shared ResNet18 across 3 inputs â†’ ~45 MB TFLite\n",
        "âœ… TFLite export with SELECT_TF_OPS (GELU via FlexDelegate)\n",
        "âœ… Re-evaluates .tflite file and compares results with PyTorch\n",
        "âœ… Ensures no silent divergence between frameworks\n",
        "âœ… Added random stratified test split for robustness evaluation\n",
        "âœ… Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "âœ… Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 224  # Only one resolution used now\n",
        "EPOCHS_CV = 150\n",
        "BATCH_CV = 28\n",
        "LR_CV = 0.00022\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "set_global_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    try:\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"tri_right_eye_hb_90_repro_bestfold_only_shared_stratified\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_right(dirs_map):\n",
        "    suffixes = {'right1': '_right_eye_1.png', 'right2': '_right_eye_2.png', 'right3': '_right_eye_3.png'}\n",
        "    bases_sets = []\n",
        "    for k in ['right1', 'right2', 'right3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    inter = set.intersection(*bases_sets)\n",
        "    return sorted(inter)\n",
        "\n",
        "def load_tri_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': [], 'filenames': []}\n",
        "    key_map = {'r1': ('right1', '_right_eye_1.png'), 'r2': ('right2', '_right_eye_2.png'), 'r3': ('right3', '_right_eye_3.png')}\n",
        "    for b in bases:\n",
        "        imgs, failed = {}, False\n",
        "        for short_k, (long_k, suf) in key_map.items():\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[short_k] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if not failed:\n",
        "            out['r1'].append(imgs['r1'])\n",
        "            out['r2'].append(imgs['r2'])\n",
        "            out['r3'].append(imgs['r3'])\n",
        "            out['filenames'].append(b)  # Use base name as identifier\n",
        "    return out\n",
        "\n",
        "def prepare_dataset_right_with_filenames(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_a = common_bases_right(anemic_dirs)\n",
        "    bases_n = common_bases_right(non_dirs)\n",
        "    imgs_a = load_tri_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_tri_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "\n",
        "    # Combine anemic and non-anemic data\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "\n",
        "    print(f\"âœ… {split_name}: anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    try:\n",
        "        df_bases = pd.DataFrame({'class': ['anemic']*len(bases_a) + ['non_anemic']*len(bases_n),\n",
        "                                 'base_id': bases_a + bases_n})\n",
        "        df_bases.to_csv(os.path.join(output_dir, f\"{split_name.lower()}_used_base_ids_right.csv\"), index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return data\n",
        "\n",
        "def count_files(d):\n",
        "    return sum(1 for f in sorted(os.listdir(d)) if f.endswith(\".png\")) if os.path.isdir(d) else 0\n",
        "\n",
        "def print_dir_stats(title, dirs_map):\n",
        "    print(f\"\\nðŸ“‚ {title}\")\n",
        "    for k in ['right1','right2','right3']:\n",
        "        p = dirs_map[k]; c = count_files(p)\n",
        "        print(f\"{k:7s} | {p} | files={c}\")\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "\n",
        "print_dir_stats(\"TEST  anemic (right)\", test_dirs_anemic)\n",
        "print_dir_stats(\"TEST  non-anemic (right)\", test_dirs_non)\n",
        "\n",
        "train_data = prepare_dataset_right_with_filenames(train_dirs_anemic, train_dirs_non, split_name=\"TRAIN\")\n",
        "val_data   = prepare_dataset_right_with_filenames(val_dirs_anemic,   val_dirs_non,   split_name=\"VAL\")\n",
        "test_data  = prepare_dataset_right_with_filenames(test_dirs_anemic,  test_dirs_non,  split_name=\"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No tri-right-eye TRAIN samples found.\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_r1 = train_data['r1'] + val_data['r1'] + test_data['r1']\n",
        "all_r2 = train_data['r2'] + val_data['r2'] + test_data['r2']\n",
        "all_r3 = train_data['r3'] + val_data['r3'] + test_data['r3']\n",
        "all_filenames = train_data['filenames'] + val_data['filenames'] + test_data['filenames']\n",
        "all_labels = train_data['label'] + val_data['label'] + test_data['label']\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp_r1, X_test_strat_r1, X_temp_r2, X_test_strat_r2, X_temp_r3, X_test_strat_r3, fname_temp, fname_test_strat, y_temp, y_test_strat = train_test_split(\n",
        "    all_r1, all_r2, all_r3, all_filenames, all_labels,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_labels,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat_r1, X_val_strat_r1, X_train_strat_r2, X_val_strat_r2, X_train_strat_r3, X_val_strat_r3, fname_train_strat, fname_val_strat, y_train_strat, y_val_strat = train_test_split(\n",
        "    X_temp_r1, X_temp_r2, X_temp_r3, fname_temp, y_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "strat_train_data = {\n",
        "    'r1': X_train_strat_r1,\n",
        "    'r2': X_train_strat_r2,\n",
        "    'r3': X_train_strat_r3,\n",
        "    'filenames': fname_train_strat,\n",
        "    'label': y_train_strat\n",
        "}\n",
        "\n",
        "strat_val_data = {\n",
        "    'r1': X_val_strat_r1,\n",
        "    'r2': X_val_strat_r2,\n",
        "    'r3': X_val_strat_r3,\n",
        "    'filenames': fname_val_strat,\n",
        "    'label': y_val_strat\n",
        "}\n",
        "\n",
        "strat_test_data = {\n",
        "    'r1': X_test_strat_r1,\n",
        "    'r2': X_test_strat_r2,\n",
        "    'r3': X_test_strat_r3,\n",
        "    'filenames': fname_test_strat,\n",
        "    'label': y_test_strat\n",
        "}\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_data['label'])} anemic / {len(test_data['label'])} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class TrirightDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[k][idx] for k in ['r1','r2','r3']]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        return images, label\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type=='cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL: SHARED RESNET18 BACKBONE\n",
        "# =========================\n",
        "class TriResNetright(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(3 * 512, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        f1 = self.backbone(x1)\n",
        "        f2 = self.backbone(x2)\n",
        "        f3 = self.backbone(x3)\n",
        "        x = torch.cat([f1, f2, f3], dim=1)\n",
        "        return self.fusion(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION (PyTorch) WITH PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        x1, x2, x3 = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(x1, x2, x3)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(all_labels) == 0 or len(set(all_labels)) < 2:\n",
        "        return [float('nan')] * 9 + [all_labels, all_probs, all_filenames, all_preds]\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(best_model: nn.Module, output_dir: str, resolution: int, tflite_filename: str):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    best_model.eval().to('cpu')\n",
        "    dummy_inputs = tuple(torch.randn(1, 3, resolution, resolution) for _ in range(3))\n",
        "    onnx_path = os.path.join(output_dir, \"tri_right_model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"tri_right_tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, tflite_filename)\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # Step 1: PyTorch -> ONNX\n",
        "    print(\"1. Converting to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            best_model,\n",
        "            dummy_inputs,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input1', 'input2', 'input3'],\n",
        "            output_names=['output']\n",
        "        )\n",
        "        print(f\"   âœ… ONNX saved: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: ONNX -> TensorFlow\n",
        "    print(\"2. ONNX -> TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        if os.path.exists(tf_path):\n",
        "            import shutil\n",
        "            shutil.rmtree(tf_path)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TF SavedModel saved: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: TF -> TFLite with SELECT_TF_OPS\n",
        "    print(\"3. TF -> TFLite (SELECT_TF_OPS)...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"   âœ… TFLite saved: {tflite_path} ({size_mb:.2f} MB)\")\n",
        "        return tflite_path\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Conversion failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# TFLITE RE-EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data, resolution):\n",
        "    import tensorflow as tf\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” TFLite input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) == 4:\n",
        "        if first_shape[1] == 3:  # [B,C,H,W]\n",
        "            layout = 'NCHW'\n",
        "        else:  # [B,H,W,C]\n",
        "            layout = 'NHWC'\n",
        "\n",
        "    resize_h, resize_w = int(first_shape[1] if layout == 'NHWC' else first_shape[2]), \\\n",
        "                         int(first_shape[2] if layout == 'NHWC' else first_shape[3])\n",
        "\n",
        "    print(f\"   âž¤ Detected layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        img_resized = img_pil.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(img_resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, all_filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    for i in range(len(test_data['label'])):\n",
        "        imgs = [test_data['r1'][i], test_data['r2'][i], test_data['r3'][i]]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            raw_img = imgs[idx]\n",
        "            processed = preprocess_pil_style(raw_img)\n",
        "\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        logit = float(np.array(output).reshape(-1)[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        auc = float('nan')\n",
        "    else:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN TRAINING LOOP\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    resolution = RESOLUTION\n",
        "    results = []\n",
        "    cv_index_records = []\n",
        "\n",
        "    print(f\"\\n===== Processing right resolution: {resolution} =====\")\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(strat_train_data['label'])\n",
        "\n",
        "    fold = 1\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- right Fold {fold} ---\")\n",
        "        cv_index_records.append({\"fold\": fold, \"train_indices\": train_idx.tolist(), \"val_indices\": val_idx.tolist()})\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in strat_train_data.items()}\n",
        "        val_subset   = {k: [v[i] for i in val_idx]   for k, v in strat_train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(TrirightDataset(train_subset, train_transform), BATCH_CV, True)\n",
        "        val_loader   = make_loader(TrirightDataset(val_subset,   test_transform),  BATCH_CV, False)\n",
        "\n",
        "        model = TriResNetright().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in train_loader:\n",
        "                x1, x2, x3 = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(x1, x2, x3)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] Loss: {total_loss:.6f}\")\n",
        "\n",
        "        val_metrics = evaluate_with_predictions(model, val_loader, val_subset['filenames'])\n",
        "        result_row = {\n",
        "            'EyeSet': 'right',\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8]\n",
        "        }\n",
        "        results.append(result_row)\n",
        "        print(results)\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"right_cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({'model_state': model.state_dict()}, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save CV results\n",
        "    pd.DataFrame(results).to_csv(os.path.join(output_dir, \"right_val_cross_validation_results.csv\"), index=False)\n",
        "    with open(os.path.join(output_dir, \"right_cv_indices.json\"), \"w\") as f:\n",
        "        json.dump(cv_index_records, f, indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df['Val_Precision'] >= 0.90) & (df['Val_Recall'] >= 0.90)]\n",
        "    best = candidates.sort_values(['Val_F1'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "           df.sort_values(['minPR','Val_F1'], ascending=False).iloc[0]\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # Load best model\n",
        "    ckpt_path = os.path.join(output_dir, f\"right_cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    best_model = TriResNetright().to(device)\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Test evaluation (PyTorch) - Random Stratified Test Set\n",
        "    test_loader_strat = make_loader(TrirightDataset(strat_test_data, test_transform), BATCH_CV, False)\n",
        "    test_metrics_strat = evaluate_with_predictions(best_model, test_loader_strat, strat_test_data['filenames'])\n",
        "\n",
        "    test_results_df = pd.DataFrame([{\n",
        "        'ChosenFold': best_fold,\n",
        "        'Test_Precision': test_metrics_strat[0],\n",
        "        'Test_Recall': test_metrics_strat[1],\n",
        "        'Test_F1': test_metrics_strat[2],\n",
        "        'Test_Accuracy': test_metrics_strat[3],\n",
        "        'Test_AUC': test_metrics_strat[4],\n",
        "        'Test_TP': test_metrics_strat[5],\n",
        "        'Test_TN': test_metrics_strat[6],\n",
        "        'Test_FP': test_metrics_strat[7],\n",
        "        'Test_FN': test_metrics_strat[8],\n",
        "        'Test_Type': 'Random_Stratified'\n",
        "    }])\n",
        "    test_results_df.to_csv(os.path.join(output_dir, \"right_bestfold_test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    print(\"\\nðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\")\n",
        "    print(test_results_df.to_string(index=False))\n",
        "\n",
        "    # Save detailed PyTorch predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(output_dir, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(output_dir, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(output_dir, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    # Convert to TFLite\n",
        "    tflite_filename = \"tri_right_eye_resnet18_shared_stratified.tflite\"\n",
        "    tflite_path = convert_to_tflite(best_model.cpu(), output_dir, resolution, tflite_filename)\n",
        "\n",
        "    if tflite_path:\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"\\nðŸŽ‰ SUCCESS! Final TFLite model size: {size_mb:.2f} MB\")\n",
        "        print(f\"ðŸ“ Path: {tflite_path}\")\n",
        "\n",
        "        # --- ðŸ” Re-evaluate TFLite model on random stratified test set ---\n",
        "        print(\"\\nðŸ” Re-evaluating TFLite model on random stratified test set...\")\n",
        "        try:\n",
        "            tflite_metrics = evaluate_tflite_model_with_predictions(tflite_path, strat_test_data, resolution)\n",
        "            tflite_results_df = pd.DataFrame([{\n",
        "                'Source': 'TFLite',\n",
        "                'Test_Precision': tflite_metrics[0],\n",
        "                'Test_Recall': tflite_metrics[1],\n",
        "                'Test_F1': tflite_metrics[2],\n",
        "                'Test_Accuracy': tflite_metrics[3],\n",
        "                'Test_AUC': tflite_metrics[4],\n",
        "                'Test_TP': tflite_metrics[5],\n",
        "                'Test_TN': tflite_metrics[6],\n",
        "                'Test_FP': tflite_metrics[7],\n",
        "                'Test_FN': tflite_metrics[8],\n",
        "                'Test_Type': 'Random_Stratified'\n",
        "            }])\n",
        "\n",
        "            combined = pd.concat([\n",
        "                test_results_df.assign(Source='PyTorch'),\n",
        "                tflite_results_df\n",
        "            ], ignore_index=True)\n",
        "\n",
        "            print(\"\\nðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\")\n",
        "            print(combined.to_string(index=False))\n",
        "            combined.to_csv(os.path.join(output_dir, \"pytorch_vs_tflite_comparison_stratified.csv\"), index=False)\n",
        "\n",
        "            # Save detailed TFLite predictions to CSV\n",
        "            save_predictions_to_csv(\n",
        "                tflite_metrics[11],  # filenames\n",
        "                tflite_metrics[9],   # true labels\n",
        "                tflite_metrics[12],  # pred labels\n",
        "                tflite_metrics[10],  # pred probs\n",
        "                os.path.join(output_dir, \"detailed_predictions_tflite.csv\")\n",
        "            )\n",
        "\n",
        "            # Plot ROC curve and confusion matrix for TFLite model\n",
        "            plot_roc_curve(tflite_metrics[9], tflite_metrics[10],\n",
        "                           \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                           os.path.join(output_dir, \"roc_curve_tflite.png\"))\n",
        "            plot_confusion_matrix(tflite_metrics[9],\n",
        "                                  tflite_metrics[12],\n",
        "                                  \"Confusion Matrix - TFLite Model\",\n",
        "                                  os.path.join(output_dir, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(test_results_df.iloc[0].to_dict(), tflite_metrics,\n",
        "                                   os.path.join(output_dir, \"metrics_comparison.png\"))\n",
        "\n",
        "            tol = 1e-3\n",
        "            if (abs(tflite_metrics[2] - test_metrics_strat[2]) < tol and\n",
        "                abs(tflite_metrics[4] - test_metrics_strat[4]) < tol):\n",
        "                print(\"âœ… TFLite results MATCH PyTorch within tolerance.\")\n",
        "            else:\n",
        "                print(\"âš ï¸ WARNING: TFLite results differ significantly from PyTorch!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ TFLite evaluation failed: {e}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite conversion failed.\")\n",
        "\n",
        "    print(\"\\nâœ… Pipeline completed. Model evaluated on random stratified test set with shared backbone.\")\n",
        "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c665b1-c115-40f8-bc94-61e952260b70",
      "metadata": {
        "id": "73c665b1-c115-40f8-bc94-61e952260b70",
        "outputId": "67c1cc55-968e-4eca-e336-6190af3c4ea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'done'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"done\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ad2b5c-ca20-484f-9ecf-4ebd3db8822c",
      "metadata": {
        "id": "39ad2b5c-ca20-484f-9ecf-4ebd3db8822c",
        "outputId": "a2390760-797d-4b9e-fdd5-09a2e31f1826"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ðŸ“‚ TEST  anemic (HEXA)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=44\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=42\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "\n",
            "ðŸ“‚ TEST  non-anemic (HEXA)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=314\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=319\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=318\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=322\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=329\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=328\n",
            "âœ… TRAIN: anemic=235, non-anemic=1824, total=2059\n",
            "âœ… VAL: anemic=37, non-anemic=291, total=328\n",
            "âœ… TEST: anemic=28, non-anemic=237, total=265\n",
            "\n",
            "--- Creating Random Stratified Split (Training + Validation + Test) ---\n",
            "Random stratified train set: 225 anemic / 1988 total\n",
            "Random stratified val set: 37 anemic / 332 total\n",
            "Random stratified test set: 38 anemic / 332 total\n",
            "Original test set: 28 anemic / 265 total\n",
            "\n",
            "===== Processing HEXA resolution: 224 =====\n",
            "\n",
            "--- HEXA Fold 1 ---\n",
            "Epoch [10/300] Loss: 61.726384\n",
            "Epoch [20/300] Loss: 32.769000\n",
            "Epoch [30/300] Loss: 7.466861\n",
            "âœ… Early stop at epoch 39: P=0.977, R=0.956\n",
            "[{'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9772727272727273, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9662921348314608, 'Val_Accuracy': 0.992462311557789, 'Val_AUC': 0.9988668555240794, 'Val_TP': 43, 'Val_TN': 352, 'Val_FP': 1, 'Val_FN': 2, 'Stopped_Early': True}]\n",
            "\n",
            "--- HEXA Fold 2 ---\n",
            "Epoch [10/300] Loss: 58.256446\n",
            "Epoch [20/300] Loss: 48.173854\n",
            "Epoch [30/300] Loss: 17.629208\n",
            "Epoch [40/300] Loss: 8.038916\n",
            "Epoch [50/300] Loss: 6.707968\n",
            "âœ… Early stop at epoch 58: P=0.933, R=0.933\n",
            "[{'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9772727272727273, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9662921348314608, 'Val_Accuracy': 0.992462311557789, 'Val_AUC': 0.9988668555240794, 'Val_TP': 43, 'Val_TN': 352, 'Val_FP': 1, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9333333333333333, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9333333333333333, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9982373308152345, 'Val_TP': 42, 'Val_TN': 350, 'Val_FP': 3, 'Val_FN': 3, 'Stopped_Early': True}]\n",
            "\n",
            "--- HEXA Fold 3 ---\n",
            "Epoch [10/300] Loss: 62.274310\n",
            "Epoch [20/300] Loss: 54.746252\n",
            "Epoch [30/300] Loss: 33.159649\n",
            "Epoch [40/300] Loss: 7.826910\n",
            "âœ… Early stop at epoch 45: P=0.915, R=0.956\n",
            "[{'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9772727272727273, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9662921348314608, 'Val_Accuracy': 0.992462311557789, 'Val_AUC': 0.9988668555240794, 'Val_TP': 43, 'Val_TN': 352, 'Val_FP': 1, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9333333333333333, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9333333333333333, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9982373308152345, 'Val_TP': 42, 'Val_TN': 350, 'Val_FP': 3, 'Val_FN': 3, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.9148936170212766, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9347826086956522, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9969153289266605, 'Val_TP': 43, 'Val_TN': 349, 'Val_FP': 4, 'Val_FN': 2, 'Stopped_Early': True}]\n",
            "\n",
            "--- HEXA Fold 4 ---\n",
            "Epoch [10/300] Loss: 62.672257\n",
            "Epoch [20/300] Loss: 47.794793\n",
            "Epoch [30/300] Loss: 33.305262\n",
            "Epoch [40/300] Loss: 16.856599\n",
            "Epoch [50/300] Loss: 9.216533\n",
            "Epoch [60/300] Loss: 4.481563\n",
            "Epoch [70/300] Loss: 3.049713\n",
            "Epoch [80/300] Loss: 3.997542\n",
            "Epoch [90/300] Loss: 1.903179\n",
            "Epoch [100/300] Loss: 3.037217\n",
            "Epoch [110/300] Loss: 1.449062\n",
            "Epoch [120/300] Loss: 0.320215\n",
            "âœ… Early stop at epoch 129: P=0.977, R=0.933\n",
            "[{'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9772727272727273, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9662921348314608, 'Val_Accuracy': 0.992462311557789, 'Val_AUC': 0.9988668555240794, 'Val_TP': 43, 'Val_TN': 352, 'Val_FP': 1, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9333333333333333, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9333333333333333, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9982373308152345, 'Val_TP': 42, 'Val_TN': 350, 'Val_FP': 3, 'Val_FN': 3, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.9148936170212766, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9347826086956522, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9969153289266605, 'Val_TP': 43, 'Val_TN': 349, 'Val_FP': 4, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.9767441860465116, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9545454545454545, 'Val_Accuracy': 0.9899244332493703, 'Val_AUC': 0.9994318181818181, 'Val_TP': 42, 'Val_TN': 351, 'Val_FP': 1, 'Val_FN': 3, 'Stopped_Early': True}]\n",
            "\n",
            "--- HEXA Fold 5 ---\n",
            "Epoch [10/300] Loss: 61.617158\n",
            "Epoch [20/300] Loss: 51.232952\n",
            "Epoch [30/300] Loss: 17.051870\n",
            "Epoch [40/300] Loss: 3.874095\n",
            "Epoch [50/300] Loss: 0.680279\n",
            "âœ… Early stop at epoch 52: P=0.976, R=0.911\n",
            "[{'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 1, 'Val_Precision': 0.9772727272727273, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9662921348314608, 'Val_Accuracy': 0.992462311557789, 'Val_AUC': 0.9988668555240794, 'Val_TP': 43, 'Val_TN': 352, 'Val_FP': 1, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 2, 'Val_Precision': 0.9333333333333333, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9333333333333333, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9982373308152345, 'Val_TP': 42, 'Val_TN': 350, 'Val_FP': 3, 'Val_FN': 3, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 3, 'Val_Precision': 0.9148936170212766, 'Val_Recall': 0.9555555555555556, 'Val_F1': 0.9347826086956522, 'Val_Accuracy': 0.9849246231155779, 'Val_AUC': 0.9969153289266605, 'Val_TP': 43, 'Val_TN': 349, 'Val_FP': 4, 'Val_FN': 2, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 4, 'Val_Precision': 0.9767441860465116, 'Val_Recall': 0.9333333333333333, 'Val_F1': 0.9545454545454545, 'Val_Accuracy': 0.9899244332493703, 'Val_AUC': 0.9994318181818181, 'Val_TP': 42, 'Val_TN': 351, 'Val_FP': 1, 'Val_FN': 3, 'Stopped_Early': True}, {'EyeSet': 'HEXA', 'Resolution': 224, 'Fold': 5, 'Val_Precision': 0.9761904761904762, 'Val_Recall': 0.9111111111111111, 'Val_F1': 0.9425287356321839, 'Val_Accuracy': 0.9874055415617129, 'Val_AUC': 0.9982323232323231, 'Val_TP': 41, 'Val_TN': 351, 'Val_FP': 1, 'Val_FN': 4, 'Stopped_Early': True}]\n",
            "âœ… Best fold = 1\n",
            "\n",
            "ðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type\n",
            "          1        0.971429     0.894737 0.931507        0.98494  0.997225       34      293        1        4 Random_Stratified\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/detailed_predictions_pytorch.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 17:35:29.792568: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-18 17:35:29.829953: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-11-18 17:35:30.075684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-18 17:35:30.781805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting TFLite Conversion Pipeline ---\n",
            "1. Converting to ONNX...\n",
            "   âœ… ONNX saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_model.onnx\n",
            "2. ONNX -> TensorFlow SavedModel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 17:35:34.321429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-18 17:35:34.323238: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO:absl:Function `__call__` contains input name(s) input, x, y with unsupported characters which will be renamed to onnx_tf_prefix_identity_49_input, transpose_373_x, onnx_tf_prefix__fusion_fusion_1_add_1_y in the SavedModel.\n",
            "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model/assets\n",
            "INFO:absl:Writing fingerprint to /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model/fingerprint.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TF SavedModel saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model\n",
            "3. TF -> TFLite (SELECT_TF_OPS)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-18 17:35:44.923160: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-11-18 17:35:44.923199: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-11-18 17:35:44.925469: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model\n",
            "2025-11-18 17:35:44.967500: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-11-18 17:35:44.967531: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model\n",
            "2025-11-18 17:35:45.017977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-11-18 17:35:45.021437: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-11-18 17:35:45.152273: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_tf_model\n",
            "2025-11-18 17:35:45.221762: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 296295 microseconds.\n",
            "2025-11-18 17:35:45.418429: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-11-18 17:35:46.415906: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
            "Flex ops: FlexErf\n",
            "Details:\n",
            "\ttf.Erf(tensor<1x128xf32>) -> (tensor<1x128xf32>) : {device = \"\"}\n",
            "\ttf.Erf(tensor<1x512xf32>) -> (tensor<1x512xf32>) : {device = \"\"}\n",
            "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
            "2025-11-18 17:35:46.416204: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2138] Estimated count of arithmetic ops: 21.796 G  ops, equivalently 10.898 G  MACs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… TFLite saved: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_eye_resnet18_shared_stratified.tflite (48.96 MB)\n",
            "\n",
            "ðŸŽ‰ SUCCESS! Final TFLite model size: 48.96 MB\n",
            "ðŸ“ Path: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/hexa_eye_resnet18_shared_stratified.tflite\n",
            "\n",
            "ðŸ” Re-evaluating TFLite model on random stratified test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
            "2025-11-18 17:35:47.140218: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-18 17:35:47.141551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 540 nodes with 2 partitions.\n",
            "\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” TFLite input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0', 'serving_default_input4:0', 'serving_default_input5:0', 'serving_default_input6:0']\n",
            "   âž¤ Detected layout: NCHW, size: 224x224\n",
            "\n",
            "ðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\n",
            " ChosenFold  Test_Precision  Test_Recall  Test_F1  Test_Accuracy  Test_AUC  Test_TP  Test_TN  Test_FP  Test_FN         Test_Type  Source\n",
            "        1.0        0.971429     0.894737 0.931507        0.98494  0.997225       34      293        1        4 Random_Stratified PyTorch\n",
            "        NaN        0.971429     0.894737 0.931507        0.98494  0.997225       34      293        1        4 Random_Stratified  TFLite\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified/detailed_predictions_tflite.csv\n",
            "âœ… TFLite results MATCH PyTorch within tolerance.\n",
            "\n",
            "âœ… Hexa-Eye pipeline completed. Model evaluated on random stratified test set with shared backbone.\n",
            "âœ… Detailed prediction CSVs and plots saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Reproducible Hexa-Eye ResNet18 with SHARED BACKBONE + EARLY STOPPING & TFLite Verification\n",
        "----------------------------------------------------------------------------------\n",
        "âœ… Single ResNet18 used across 6 inputs â†’ ~47 MB TFLite\n",
        "âœ… Stops fold early if Val Precision & Recall >= 0.90\n",
        "âœ… Re-evaluates .tflite model and compares predictions with PyTorch\n",
        "âœ… Ensures faithful deployment (no numerical drift)\n",
        "âœ… Deterministic training + FlexDelegate support for GELU\n",
        "âœ… Added random stratified test split for robustness evaluation\n",
        "âœ… Added detailed prediction CSV with file IDs, predictions, probabilities, and confusion matrix indicators\n",
        "âœ… Added comprehensive plotting: ROC curves, confusion matrices, metrics comparison\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "N_SPLITS = 5\n",
        "RESOLUTION = 224\n",
        "EPOCHS_CV = 300\n",
        "BATCH_CV = 8  # Reduced due to 6 inputs per sample\n",
        "LR_CV = 0.0002\n",
        "\n",
        "\n",
        "# ðŸ”¥ NEW: Early stop if both P and R >= this threshold\n",
        "EARLY_STOP_PR = 0.90\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "set_global_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    try:\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "output_dir = os.path.join(base_path, \"hexa_eye_hb_90_repro_bestfold_only_sharedf_stratified\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "# All six input directories\n",
        "train_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_train_roi/'\n",
        "})\n",
        "train_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_train_roi/'\n",
        "})\n",
        "val_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_val_roi/'\n",
        "})\n",
        "val_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_val_roi/'\n",
        "})\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_hexa(dirs_map):\n",
        "    suffixes = {\n",
        "        'left1': '_left_eye_1.png', 'left2': '_left_eye_2.png', 'left3': '_left_eye_3.png',\n",
        "        'right1': '_right_eye_1.png', 'right2': '_right_eye_2.png', 'right3': '_right_eye_3.png'\n",
        "    }\n",
        "    bases_sets = []\n",
        "    for k in dirs_map.keys():\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    inter = set.intersection(*bases_sets)\n",
        "    return sorted(inter)\n",
        "\n",
        "def load_hexa_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {f'r{i}': [] for i in range(1,7)}\n",
        "    out['filenames'] = []\n",
        "    key_map = [\n",
        "        ('left1', '_left_eye_1.png'),\n",
        "        ('left2', '_left_eye_2.png'),\n",
        "        ('left3', '_left_eye_3.png'),\n",
        "        ('right1', '_right_eye_1.png'),\n",
        "        ('right2', '_right_eye_2.png'),\n",
        "        ('right3', '_right_eye_3.png')\n",
        "    ]\n",
        "    for b in bases:\n",
        "        imgs, failed = [], False\n",
        "        for long_k, suf in key_map:\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        if not failed:\n",
        "            for i, img in enumerate(imgs):\n",
        "                out[f'r{i+1}'].append(img)\n",
        "            out['filenames'].append(b)  # Use base name as identifier\n",
        "    return out\n",
        "\n",
        "def prepare_dataset_hexa_with_filenames(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_a = common_bases_hexa(anemic_dirs)\n",
        "    bases_n = common_bases_hexa(non_dirs)\n",
        "    imgs_a = load_hexa_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_hexa_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'r4': imgs_a['r4'] + imgs_n['r4'],\n",
        "        'r5': imgs_a['r5'] + imgs_n['r5'],\n",
        "        'r6': imgs_a['r6'] + imgs_n['r6'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "    print(f\"âœ… {split_name}: anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    try:\n",
        "        df_bases = pd.DataFrame({'class': ['anemic']*len(bases_a) + ['non_anemic']*len(bases_n),\n",
        "                                 'base_id': bases_a + bases_n})\n",
        "        df_bases.to_csv(os.path.join(output_dir, f\"{split_name.lower()}_used_base_ids_hexa.csv\"), index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return data\n",
        "\n",
        "def count_files(d):\n",
        "    return sum(1 for f in sorted(os.listdir(d)) if f.endswith(\".png\")) if os.path.isdir(d) else 0\n",
        "\n",
        "def print_dir_stats(title, dirs_map):\n",
        "    print(f\"\\nðŸ“‚ {title}\")\n",
        "    for k in dirs_map.keys():\n",
        "        p = dirs_map[k]; c = count_files(p)\n",
        "        print(f\"{k:7s} | {p} | files={c}\")\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "\n",
        "print_dir_stats(\"TEST  anemic (HEXA)\", test_dirs_anemic)\n",
        "print_dir_stats(\"TEST  non-anemic (HEXA)\", test_dirs_non)\n",
        "\n",
        "train_data = prepare_dataset_hexa_with_filenames(train_dirs_anemic, train_dirs_non, split_name=\"TRAIN\")\n",
        "val_data   = prepare_dataset_hexa_with_filenames(val_dirs_anemic,   val_dirs_non,   split_name=\"VAL\")\n",
        "test_data  = prepare_dataset_hexa_with_filenames(test_dirs_anemic,  test_dirs_non,  split_name=\"TEST\")\n",
        "\n",
        "if len(train_data['label']) == 0:\n",
        "    raise RuntimeError(\"No hexa-eye TRAIN samples found.\")\n",
        "\n",
        "# =========================\n",
        "# CREATE RANDOM STRATIFIED SPLIT (Training + Validation + Test)\n",
        "# =========================\n",
        "print(\"\\n--- Creating Random Stratified Split (Training + Validation + Test) ---\")\n",
        "# Combine all data for stratified split\n",
        "all_r1 = train_data['r1'] + val_data['r1'] + test_data['r1']\n",
        "all_r2 = train_data['r2'] + val_data['r2'] + test_data['r2']\n",
        "all_r3 = train_data['r3'] + val_data['r3'] + test_data['r3']\n",
        "all_r4 = train_data['r4'] + val_data['r4'] + test_data['r4']\n",
        "all_r5 = train_data['r5'] + val_data['r5'] + test_data['r5']\n",
        "all_r6 = train_data['r6'] + val_data['r6'] + test_data['r6']\n",
        "all_filenames = train_data['filenames'] + val_data['filenames'] + test_data['filenames']\n",
        "all_labels = train_data['label'] + val_data['label'] + test_data['label']\n",
        "\n",
        "# Create stratified random splits - 75% train, 12.5% val, 12.5% test\n",
        "X_temp_r1, X_test_strat_r1, X_temp_r2, X_test_strat_r2, X_temp_r3, X_test_strat_r3, X_temp_r4, X_test_strat_r4, X_temp_r5, X_test_strat_r5, X_temp_r6, X_test_strat_r6, fname_temp, fname_test_strat, y_temp, y_test_strat = train_test_split(\n",
        "    all_r1, all_r2, all_r3, all_r4, all_r5, all_r6, all_filenames, all_labels,\n",
        "    test_size=0.125,  # 12.5% for test\n",
        "    stratify=all_labels,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train_strat_r1, X_val_strat_r1, X_train_strat_r2, X_val_strat_r2, X_train_strat_r3, X_val_strat_r3, X_train_strat_r4, X_val_strat_r4, X_train_strat_r5, X_val_strat_r5, X_train_strat_r6, X_val_strat_r6, fname_train_strat, fname_val_strat, y_train_strat, y_val_strat = train_test_split(\n",
        "    X_temp_r1, X_temp_r2, X_temp_r3, X_temp_r4, X_temp_r5, X_temp_r6, fname_temp, y_temp,\n",
        "    test_size=0.142857,  # 12.5% of total (14.2857% of remaining 87.5%) for validation\n",
        "    stratify=y_temp,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "strat_train_data = {\n",
        "    'r1': X_train_strat_r1,\n",
        "    'r2': X_train_strat_r2,\n",
        "    'r3': X_train_strat_r3,\n",
        "    'r4': X_train_strat_r4,\n",
        "    'r5': X_train_strat_r5,\n",
        "    'r6': X_train_strat_r6,\n",
        "    'filenames': fname_train_strat,\n",
        "    'label': y_train_strat\n",
        "}\n",
        "\n",
        "strat_val_data = {\n",
        "    'r1': X_val_strat_r1,\n",
        "    'r2': X_val_strat_r2,\n",
        "    'r3': X_val_strat_r3,\n",
        "    'r4': X_val_strat_r4,\n",
        "    'r5': X_val_strat_r5,\n",
        "    'r6': X_val_strat_r6,\n",
        "    'filenames': fname_val_strat,\n",
        "    'label': y_val_strat\n",
        "}\n",
        "\n",
        "strat_test_data = {\n",
        "    'r1': X_test_strat_r1,\n",
        "    'r2': X_test_strat_r2,\n",
        "    'r3': X_test_strat_r3,\n",
        "    'r4': X_test_strat_r4,\n",
        "    'r5': X_test_strat_r5,\n",
        "    'r6': X_test_strat_r6,\n",
        "    'filenames': fname_test_strat,\n",
        "    'label': y_test_strat\n",
        "}\n",
        "\n",
        "print(f\"Random stratified train set: {sum(y_train_strat)} anemic / {len(y_train_strat)} total\")\n",
        "print(f\"Random stratified val set: {sum(y_val_strat)} anemic / {len(y_val_strat)} total\")\n",
        "print(f\"Random stratified test set: {sum(y_test_strat)} anemic / {len(y_test_strat)} total\")\n",
        "print(f\"Original test set: {sum(test_data['label'])} anemic / {len(test_data['label'])} total\")\n",
        "\n",
        "# =========================\n",
        "# DATASET\n",
        "# =========================\n",
        "class HexaDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data['label'])\n",
        "    def __getitem__(self, idx):\n",
        "        images = [self.data[f'r{i}'][idx] for i in range(1,7)]\n",
        "        images = [self.transform(img) for img in images]\n",
        "        label = self.data['label'][idx]\n",
        "        return images, label\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    torch.manual_seed(worker_seed)\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(SEED)\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY and (device.type=='cuda'),\n",
        "        worker_init_fn=seed_worker if NUM_WORKERS > 0 else None,\n",
        "        generator=g,\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# MODEL: SHARED RESNET18 BACKBONE (6 inputs)\n",
        "# =========================\n",
        "class HexaResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Single shared backbone\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # Fusion head: 6*512 â†’ 1\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(6 * 512, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, x5, x6):\n",
        "        f1 = self.backbone(x1)\n",
        "        f2 = self.backbone(x2)\n",
        "        f3 = self.backbone(x3)\n",
        "        f4 = self.backbone(x4)\n",
        "        f5 = self.backbone(x5)\n",
        "        f6 = self.backbone(x6)\n",
        "        x = torch.cat([f1, f2, f3, f4, f5, f6], dim=1)\n",
        "        return self.fusion(x)\n",
        "\n",
        "# =========================\n",
        "# EVALUATION (PyTorch) WITH PREDICTIONS\n",
        "# =========================\n",
        "@torch.no_grad()\n",
        "def evaluate_with_predictions(model, loader, filenames):\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    all_filenames = []\n",
        "\n",
        "    # Get all filenames in loader order\n",
        "    batch_size = loader.batch_size\n",
        "    for i in range(0, len(filenames), batch_size):\n",
        "        batch_end = min(i + batch_size, len(filenames))\n",
        "        all_filenames.extend(filenames[i:batch_end])\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        x_list = [img.to(device).float() for img in imgs]\n",
        "        labels = labels.to(device).float().unsqueeze(1)\n",
        "        out = model(*x_list)\n",
        "        prob = torch.sigmoid(out).cpu().numpy().flatten()\n",
        "        pred = (prob > 0.5).astype(int)\n",
        "        all_preds.extend(pred.tolist())\n",
        "        all_probs.extend(prob.tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten().tolist())\n",
        "\n",
        "    if len(all_labels) == 0 or len(set(all_labels)) < 2:\n",
        "        return [float('nan')] * 9 + [all_labels, all_probs, all_filenames, all_preds]\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# TFLITE CONVERSION\n",
        "# =========================\n",
        "def convert_to_tflite(best_model: nn.Module, output_dir: str, resolution: int, tflite_filename: str):\n",
        "    import torch.onnx\n",
        "    import onnx\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    best_model.eval().to('cpu')\n",
        "    dummy_inputs = tuple(torch.randn(1, 3, resolution, resolution) for _ in range(6))\n",
        "    onnx_path = os.path.join(output_dir, \"hexa_model.onnx\")\n",
        "    tf_path = os.path.join(output_dir, \"hexa_tf_model\")\n",
        "    tflite_path = os.path.join(output_dir, tflite_filename)\n",
        "\n",
        "    print(\"\\n--- Starting TFLite Conversion Pipeline ---\")\n",
        "\n",
        "    # Step 1: PyTorch -> ONNX\n",
        "    print(\"1. Converting to ONNX...\")\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            best_model,\n",
        "            dummy_inputs,\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=13,\n",
        "            do_constant_folding=True,\n",
        "            input_names=[f'input{i}' for i in range(1,7)],\n",
        "            output_names=['output']\n",
        "        )\n",
        "        print(f\"   âœ… ONNX saved: {onnx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: ONNX -> TensorFlow\n",
        "    print(\"2. ONNX -> TensorFlow SavedModel...\")\n",
        "    try:\n",
        "        onnx_model = onnx.load(onnx_path)\n",
        "        tf_rep = prepare(onnx_model)\n",
        "        if os.path.exists(tf_path):\n",
        "            import shutil\n",
        "            shutil.rmtree(tf_path)\n",
        "        tf_rep.export_graph(tf_path)\n",
        "        print(f\"   âœ… TF SavedModel saved: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: TF -> TFLite with SELECT_TF_OPS\n",
        "    print(\"3. TF -> TFLite (SELECT_TF_OPS)...\")\n",
        "    try:\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "        tflite_model = converter.convert()\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"   âœ… TFLite saved: {tflite_path} ({size_mb:.2f} MB)\")\n",
        "        return tflite_path\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Conversion failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# TFLITE RE-EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data, resolution):\n",
        "    import tensorflow as tf\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Sort by name to ensure correct order\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” TFLite input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) == 4:\n",
        "        if first_shape[1] == 3:  # [B,C,H,W]\n",
        "            layout = 'NCHW'\n",
        "        else:  # [B,H,W,C]\n",
        "            layout = 'NHWC'\n",
        "\n",
        "    resize_h, resize_w = int(first_shape[1] if layout == 'NHWC' else first_shape[2]), \\\n",
        "                         int(first_shape[2] if layout == 'NHWC' else first_shape[3])\n",
        "\n",
        "    print(f\"   âž¤ Detected layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        img_resized = img_pil.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(img_resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, all_filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    for i in range(len(test_data['label'])):\n",
        "        imgs = [test_data[f'r{j}'][i] for j in range(1,7)]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            raw_img = imgs[idx]\n",
        "            processed = preprocess_pil_style(raw_img)\n",
        "\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        logit = float(np.array(output).reshape(-1)[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        auc = float('nan')\n",
        "    else:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_comparison(pytorch_metrics, tflite_metrics, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy', 'AUC']\n",
        "    pytorch_vals = [pytorch_metrics['Test_Precision'], pytorch_metrics['Test_Recall'],\n",
        "                    pytorch_metrics['Test_F1'], pytorch_metrics['Test_Accuracy'],\n",
        "                    pytorch_metrics['Test_AUC']]\n",
        "    tflite_vals = [tflite_metrics[0], tflite_metrics[1],\n",
        "                   tflite_metrics[2], tflite_metrics[3],\n",
        "                   tflite_metrics[4]]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(x - width/2, pytorch_vals, width, label='PyTorch', color='steelblue')\n",
        "    plt.bar(x + width/2, tflite_vals, width, label='TFLite', color='darkorange')\n",
        "\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('PyTorch vs TFLite Performance Comparison')\n",
        "    plt.xticks(x, metrics)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN TRAINING LOOP (with EARLY STOPPING)\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    resolution = RESOLUTION\n",
        "    results = []\n",
        "    cv_index_records = []\n",
        "\n",
        "    print(f\"\\n===== Processing HEXA resolution: {resolution} =====\")\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((resolution, resolution)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    labels_np = np.array(strat_train_data['label'])\n",
        "\n",
        "    fold = 1\n",
        "    for train_idx, val_idx in kf.split(np.zeros_like(labels_np), labels_np):\n",
        "        print(f\"\\n--- HEXA Fold {fold} ---\")\n",
        "        cv_index_records.append({\"fold\": fold, \"train_indices\": train_idx.tolist(), \"val_indices\": val_idx.tolist()})\n",
        "\n",
        "        train_subset = {k: [v[i] for i in train_idx] for k, v in strat_train_data.items()}\n",
        "        val_subset   = {k: [v[i] for i in val_idx]   for k, v in strat_train_data.items()}\n",
        "\n",
        "        train_loader = make_loader(HexaDataset(train_subset, train_transform), BATCH_CV, True)\n",
        "        val_loader   = make_loader(HexaDataset(val_subset,   test_transform),  BATCH_CV, False)\n",
        "\n",
        "        model = HexaResNet().to(device)\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LR_CV)\n",
        "        scaler = GradScaler(enabled=(USE_AMP and device.type == \"cuda\"))\n",
        "\n",
        "        stopped_early = False\n",
        "        for epoch in range(EPOCHS_CV):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in train_loader:\n",
        "                x_list = [img.to(device).float() for img in imgs]\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with autocast(enabled=(USE_AMP and device.type == \"cuda\")):\n",
        "                    out = model(*x_list)\n",
        "                    loss = criterion(out, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{EPOCHS_CV}] Loss: {total_loss:.6f}\")\n",
        "\n",
        "            # ðŸ”¥ EARLY STOPPING CHECK\n",
        "            if EARLY_STOP_PR is not None:\n",
        "                val_metrics = evaluate_with_predictions(model, val_loader, val_subset['filenames'])\n",
        "                p, r = val_metrics[0], val_metrics[1]\n",
        "                if not (np.isnan(p) or np.isnan(r)) and p >= EARLY_STOP_PR and r >= EARLY_STOP_PR and p < 1 and r < 1:\n",
        "                    print(f\"âœ… Early stop at epoch {epoch+1}: P={p:.3f}, R={r:.3f}\")\n",
        "                    stopped_early = True\n",
        "                    break  # exit inner loop\n",
        "\n",
        "        # Final evaluation after training (or early stop)\n",
        "        val_metrics = evaluate_with_predictions(model, val_loader, val_subset['filenames'])\n",
        "        result_row = {\n",
        "            'EyeSet': 'HEXA',\n",
        "            'Resolution': resolution,\n",
        "            'Fold': fold,\n",
        "            'Val_Precision': val_metrics[0],\n",
        "            'Val_Recall': val_metrics[1],\n",
        "            'Val_F1': val_metrics[2],\n",
        "            'Val_Accuracy': val_metrics[3],\n",
        "            'Val_AUC': val_metrics[4],\n",
        "            'Val_TP': val_metrics[5],\n",
        "            'Val_TN': val_metrics[6],\n",
        "            'Val_FP': val_metrics[7],\n",
        "            'Val_FN': val_metrics[8],\n",
        "            'Stopped_Early': stopped_early\n",
        "        }\n",
        "        results.append(result_row)\n",
        "        print(results)\n",
        "        if SAVE_EVERY_FOLD_MODEL:\n",
        "            fold_path = os.path.join(output_dir, f\"hexa_cv_fold_{fold}_res{resolution}.pt\")\n",
        "            torch.save({'model_state': model.state_dict()}, fold_path)\n",
        "\n",
        "        fold += 1\n",
        "\n",
        "    # Save CV results\n",
        "    pd.DataFrame(results).to_csv(os.path.join(output_dir, \"hexa_val_cross_validation_results.csv\"), index=False)\n",
        "    with open(os.path.join(output_dir, \"hexa_cv_indices.json\"), \"w\") as f:\n",
        "        json.dump(cv_index_records, f, indent=2)\n",
        "\n",
        "    # Select best fold\n",
        "    df = pd.DataFrame(results)\n",
        "    df['minPR'] = df[['Val_Precision','Val_Recall']].min(axis=1)\n",
        "    candidates = df[(df['Val_Precision'] >= 0.90) & (df['Val_Recall'] >= 0.90) & (df['Val_Precision'] < 1) & (df['Val_Recall'] < 1)]\n",
        "    best = candidates.sort_values(['Val_F1'], ascending=False).iloc[0] if len(candidates) > 0 else \\\n",
        "           df.sort_values(['minPR','Val_F1'], ascending=False).iloc[0]\n",
        "    best_fold = int(best['Fold'])\n",
        "    print(f\"âœ… Best fold = {best_fold}\")\n",
        "\n",
        "    # Load best model\n",
        "    ckpt_path = os.path.join(output_dir, f\"hexa_cv_fold_{best_fold}_res{resolution}.pt\")\n",
        "    best_model = HexaResNet().to(device)\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    best_model.load_state_dict(state['model_state'])\n",
        "\n",
        "    # Test evaluation (Random Stratified Test Set)\n",
        "    test_loader_strat = make_loader(HexaDataset(strat_test_data, test_transform), BATCH_CV, False)\n",
        "    test_metrics_strat = evaluate_with_predictions(best_model, test_loader_strat, strat_test_data['filenames'])\n",
        "\n",
        "    test_results_df = pd.DataFrame([{\n",
        "        'ChosenFold': best_fold,\n",
        "        'Test_Precision': test_metrics_strat[0],\n",
        "        'Test_Recall': test_metrics_strat[1],\n",
        "        'Test_F1': test_metrics_strat[2],\n",
        "        'Test_Accuracy': test_metrics_strat[3],\n",
        "        'Test_AUC': test_metrics_strat[4],\n",
        "        'Test_TP': test_metrics_strat[5],\n",
        "        'Test_TN': test_metrics_strat[6],\n",
        "        'Test_FP': test_metrics_strat[7],\n",
        "        'Test_FN': test_metrics_strat[8],\n",
        "        'Test_Type': 'Random_Stratified'\n",
        "    }])\n",
        "    test_results_df.to_csv(os.path.join(output_dir, \"hexa_bestfold_test_results_stratified.csv\"), index=False)\n",
        "\n",
        "    print(\"\\nðŸ“Š TEST Results (Random Stratified Test Set - Shared Backbone):\")\n",
        "    print(test_results_df.to_string(index=False))\n",
        "\n",
        "    # Save detailed PyTorch predictions to CSV\n",
        "    save_predictions_to_csv(\n",
        "        test_metrics_strat[11],  # filenames\n",
        "        test_metrics_strat[9],   # true labels\n",
        "        test_metrics_strat[12],  # pred labels\n",
        "        test_metrics_strat[10],  # pred probs\n",
        "        os.path.join(output_dir, \"detailed_predictions_pytorch.csv\")\n",
        "    )\n",
        "\n",
        "    # Plot ROC curve and confusion matrix for PyTorch model\n",
        "    plot_roc_curve(test_metrics_strat[9], test_metrics_strat[10],\n",
        "                   \"ROC Curve - PyTorch Model (Random Stratified Test Set)\",\n",
        "                   os.path.join(output_dir, \"roc_curve_pytorch.png\"))\n",
        "    plot_confusion_matrix(test_metrics_strat[9],\n",
        "                          test_metrics_strat[12],\n",
        "                          \"Confusion Matrix - PyTorch Model\",\n",
        "                          os.path.join(output_dir, \"confusion_matrix_pytorch.png\"))\n",
        "\n",
        "    # Convert to TFLite\n",
        "    tflite_filename = \"hexa_eye_resnet18_shared_stratified.tflite\"\n",
        "    tflite_path = convert_to_tflite(best_model.cpu(), output_dir, resolution, tflite_filename)\n",
        "\n",
        "    if tflite_path:\n",
        "        size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"\\nðŸŽ‰ SUCCESS! Final TFLite model size: {size_mb:.2f} MB\")\n",
        "        print(f\"ðŸ“ Path: {tflite_path}\")\n",
        "\n",
        "        # --- ðŸ” Re-evaluate TFLite model on random stratified test set ---\n",
        "        print(\"\\nðŸ” Re-evaluating TFLite model on random stratified test set...\")\n",
        "        try:\n",
        "            tflite_metrics = evaluate_tflite_model_with_predictions(tflite_path, strat_test_data, resolution)\n",
        "            tflite_results_df = pd.DataFrame([{\n",
        "                'Source': 'TFLite',\n",
        "                'Test_Precision': tflite_metrics[0],\n",
        "                'Test_Recall': tflite_metrics[1],\n",
        "                'Test_F1': tflite_metrics[2],\n",
        "                'Test_Accuracy': tflite_metrics[3],\n",
        "                'Test_AUC': tflite_metrics[4],\n",
        "                'Test_TP': tflite_metrics[5],\n",
        "                'Test_TN': tflite_metrics[6],\n",
        "                'Test_FP': tflite_metrics[7],\n",
        "                'Test_FN': tflite_metrics[8],\n",
        "                'Test_Type': 'Random_Stratified'\n",
        "            }])\n",
        "\n",
        "            combined = pd.concat([\n",
        "                test_results_df.assign(Source='PyTorch'),\n",
        "                tflite_results_df\n",
        "            ], ignore_index=True)\n",
        "\n",
        "            print(\"\\nðŸ“Š COMPARISON: PyTorch vs TFLite (Random Stratified Test Set)\")\n",
        "            print(combined.to_string(index=False))\n",
        "            combined.to_csv(os.path.join(output_dir, \"pytorch_vs_tflite_comparison_stratified.csv\"), index=False)\n",
        "\n",
        "            # Save detailed TFLite predictions to CSV\n",
        "            save_predictions_to_csv(\n",
        "                tflite_metrics[11],  # filenames\n",
        "                tflite_metrics[9],   # true labels\n",
        "                tflite_metrics[12],  # pred labels\n",
        "                tflite_metrics[10],  # pred probs\n",
        "                os.path.join(output_dir, \"detailed_predictions_tflite.csv\")\n",
        "            )\n",
        "\n",
        "            # Plot ROC curve and confusion matrix for TFLite model\n",
        "            plot_roc_curve(tflite_metrics[9], tflite_metrics[10],\n",
        "                           \"ROC Curve - TFLite Model (Random Stratified Test Set)\",\n",
        "                           os.path.join(output_dir, \"roc_curve_tflite.png\"))\n",
        "            plot_confusion_matrix(tflite_metrics[9],\n",
        "                                  tflite_metrics[12],\n",
        "                                  \"Confusion Matrix - TFLite Model\",\n",
        "                                  os.path.join(output_dir, \"confusion_matrix_tflite.png\"))\n",
        "\n",
        "            # Create metrics comparison plot\n",
        "            plot_metrics_comparison(test_results_df.iloc[0].to_dict(), tflite_metrics,\n",
        "                                   os.path.join(output_dir, \"metrics_comparison.png\"))\n",
        "\n",
        "            tol = 1e-3\n",
        "            if (abs(tflite_metrics[2] - test_metrics_strat[2]) < tol and\n",
        "                abs(tflite_metrics[4] - test_metrics_strat[4]) < tol):\n",
        "                print(\"âœ… TFLite results MATCH PyTorch within tolerance.\")\n",
        "            else:\n",
        "                print(\"âš ï¸ WARNING: TFLite results differ significantly from PyTorch!\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ TFLite evaluation failed: {e}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite conversion failed.\")\n",
        "\n",
        "    print(\"\\nâœ… Hexa-Eye pipeline completed. Model evaluated on random stratified test set with shared backbone.\")\n",
        "    print(f\"âœ… Detailed prediction CSVs and plots saved to: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90b7950-47e6-4bb1-a4f6-0134dd091101",
      "metadata": {
        "id": "e90b7950-47e6-4bb1-a4f6-0134dd091101"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd4c6ef-5814-4723-a1ba-d703b6d009d2",
      "metadata": {
        "id": "5fd4c6ef-5814-4723-a1ba-d703b6d009d2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7058f5fd-046f-4a23-90b3-77df6f1a2dc3",
      "metadata": {
        "id": "7058f5fd-046f-4a23-90b3-77df6f1a2dc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd39d0a0-3d7c-4c17-b98b-7f682ee0db31",
      "metadata": {
        "id": "dd39d0a0-3d7c-4c17-b98b-7f682ee0db31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3018e6-f0c1-48da-9508-7983f08ef68e",
      "metadata": {
        "id": "ff3018e6-f0c1-48da-9508-7983f08ef68e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f265c791-9422-4ec0-ad4e-c1882976a2fa",
      "metadata": {
        "id": "f265c791-9422-4ec0-ad4e-c1882976a2fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba0dd90-55e1-4263-bbdc-e2e55fe9fabc",
      "metadata": {
        "id": "3ba0dd90-55e1-4263-bbdc-e2e55fe9fabc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ba65a7-e16e-42a3-a034-5c649c18f3d8",
      "metadata": {
        "id": "d7ba65a7-e16e-42a3-a034-5c649c18f3d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff611319-7a43-4d79-a34f-6ccfc35b7c4d",
      "metadata": {
        "id": "ff611319-7a43-4d79-a34f-6ccfc35b7c4d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}