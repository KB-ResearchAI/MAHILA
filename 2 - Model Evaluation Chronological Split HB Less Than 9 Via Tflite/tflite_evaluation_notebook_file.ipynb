{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d66d169-ba85-40c5-a06a-5880cfd25c76",
      "metadata": {
        "id": "5d66d169-ba85-40c5-a06a-5880cfd25c76",
        "outputId": "d5ee79aa-9f09-4a89-9b7c-bdbd797a8830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 44 anemic / 358 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 1.0000\n",
            "Recall:    0.9773\n",
            "F1 score:  0.9885\n",
            "Accuracy:  0.9972\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 43, 314, 0, 1\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/left_eye_1_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"left_eye_1_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"left_eye_1_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1e8d1e-73f5-4ba4-a7bc-55cc7f327c9d",
      "metadata": {
        "id": "3d1e8d1e-73f5-4ba4-a7bc-55cc7f327c9d",
        "outputId": "eb82065c-6ae1-42a1-a735-55483a385217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "\n",
            "ðŸ“‚ TEST  anemic (HEXA)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=44\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=42\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=43\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/ | files=40\n",
            "\n",
            "ðŸ“‚ TEST  non-anemic (HEXA)\n",
            "left1   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=314\n",
            "left2   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=319\n",
            "left3   | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=318\n",
            "right1  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=322\n",
            "right2  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=329\n",
            "right3  | /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/ | files=328\n",
            "âœ… TEST: anemic=28, non-anemic=237, total=265\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on HEXA test set...\n",
            "ðŸ” TFLite input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0', 'serving_default_input4:0', 'serving_default_input5:0', 'serving_default_input6:0']\n",
            "   âž¤ Detected layout: NCHW, size: 224x224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-28 22:24:19.959391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-28 22:24:19.960626: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS (HEXA-EYE):\n",
            "Precision: 1.0000\n",
            "Recall:    0.9643\n",
            "F1 score:  0.9818\n",
            "Accuracy:  0.9962\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 27, 237, 0, 1\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/hexa_eye_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. All outputs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "SEED = 42\n",
        "NUM_WORKERS = 0\n",
        "PIN_MEMORY = False\n",
        "USE_AMP = True\n",
        "SAVE_EVERY_FOLD_MODEL = True\n",
        "RESOLUTION = 224  # Add this â€” needed for TFLite preprocessing\n",
        "\n",
        "# =========================\n",
        "# DETERMINISM\n",
        "# =========================\n",
        "def set_global_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = False\n",
        "        torch.backends.cudnn.allow_tf32 = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "set_global_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    try:\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# =========================\n",
        "# PATHS\n",
        "# =========================\n",
        "base_path = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"hexa_eye_resnet18_shared.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "output_dir = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def make_full_path(subdirs):\n",
        "    return {k: os.path.join(base_path, v) for k, v in subdirs.items()}\n",
        "\n",
        "test_dirs_anemic = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'\n",
        "})\n",
        "test_dirs_non = make_full_path({\n",
        "    'left1': 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left2': 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'left3': 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right1': 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right2': 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/',\n",
        "    'right3': 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'\n",
        "})\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_hexa(dirs_map):\n",
        "    suffixes = {\n",
        "        'left1': '_left_eye_1.png', 'left2': '_left_eye_2.png', 'left3': '_left_eye_3.png',\n",
        "        'right1': '_right_eye_1.png', 'right2': '_right_eye_2.png', 'right3': '_right_eye_3.png'\n",
        "    }\n",
        "    bases_sets = []\n",
        "    for k in dirs_map.keys():\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    inter = set.intersection(*bases_sets)\n",
        "    return sorted(inter)\n",
        "\n",
        "def load_hexa_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {f'r{i}': [] for i in range(1,7)}\n",
        "    out['filenames'] = []\n",
        "    key_map = [\n",
        "        ('left1', '_left_eye_1.png'),\n",
        "        ('left2', '_left_eye_2.png'),\n",
        "        ('left3', '_left_eye_3.png'),\n",
        "        ('right1', '_right_eye_1.png'),\n",
        "        ('right2', '_right_eye_2.png'),\n",
        "        ('right3', '_right_eye_3.png')\n",
        "    ]\n",
        "    for b in bases:\n",
        "        imgs, failed = [], False\n",
        "        for long_k, suf in key_map:\n",
        "            path = os.path.join(dirs_map[long_k], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        if not failed:\n",
        "            for i, img in enumerate(imgs):\n",
        "                out[f'r{i+1}'].append(img)\n",
        "            out['filenames'].append(b)\n",
        "    return out\n",
        "\n",
        "def prepare_dataset_hexa_with_filenames(anemic_dirs, non_dirs, split_name=\"(split)\"):\n",
        "    bases_a = common_bases_hexa(anemic_dirs)\n",
        "    bases_n = common_bases_hexa(non_dirs)\n",
        "    imgs_a = load_hexa_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_hexa_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'r4': imgs_a['r4'] + imgs_n['r4'],\n",
        "        'r5': imgs_a['r5'] + imgs_n['r5'],\n",
        "        'r6': imgs_a['r6'] + imgs_n['r6'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "    print(f\"âœ… {split_name}: anemic={len(imgs_a['r1'])}, non-anemic={len(imgs_n['r1'])}, total={len(data['label'])}\")\n",
        "    try:\n",
        "        df_bases = pd.DataFrame({'class': ['anemic']*len(bases_a) + ['non_anemic']*len(bases_n),\n",
        "                                 'base_id': bases_a + bases_n})\n",
        "        df_bases.to_csv(os.path.join(output_dir, f\"{split_name.lower()}_used_base_ids_hexa.csv\"), index=False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return data\n",
        "\n",
        "def count_files(d):\n",
        "    return sum(1 for f in sorted(os.listdir(d)) if f.endswith(\".png\")) if os.path.isdir(d) else 0\n",
        "\n",
        "def print_dir_stats(title, dirs_map):\n",
        "    print(f\"\\nðŸ“‚ {title}\")\n",
        "    for k in dirs_map.keys():\n",
        "        p = dirs_map[k]; c = count_files(p)\n",
        "        print(f\"{k:7s} | {p} | files={c}\")\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "print_dir_stats(\"TEST  anemic (HEXA)\", test_dirs_anemic)\n",
        "print_dir_stats(\"TEST  non-anemic (HEXA)\", test_dirs_non)\n",
        "\n",
        "test_data = prepare_dataset_hexa_with_filenames(test_dirs_anemic, test_dirs_non, split_name=\"TEST\")\n",
        "\n",
        "# =========================\n",
        "# TFLITE RE-EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data, resolution):\n",
        "    import tensorflow as tf\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Sort inputs by name to ensure consistent order (r1, r2, ..., r6)\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” TFLite input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    # Assume all inputs have same shape\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) == 4:\n",
        "        if first_shape[-1] == 3:  # NHWC\n",
        "            layout = 'NHWC'\n",
        "            resize_h, resize_w = int(first_shape[1]), int(first_shape[2])\n",
        "        elif first_shape[1] == 3:  # NCHW\n",
        "            layout = 'NCHW'\n",
        "            resize_h, resize_w = int(first_shape[2]), int(first_shape[3])\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer layout from shape: {first_shape}\")\n",
        "    else:\n",
        "        raise ValueError(f\"Expected 4D input, got {first_shape}\")\n",
        "\n",
        "    print(f\"   âž¤ Detected layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        img_pil = Image.fromarray(img_rgb)\n",
        "        img_resized = img_pil.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(img_resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, all_filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    total = len(test_data['label'])\n",
        "    for i in range(total):\n",
        "        imgs = [test_data[f'r{j}'][i] for j in range(1,7)]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        # Set each input tensor\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            raw_img = imgs[idx]\n",
        "            processed = preprocess_pil_style(raw_img)\n",
        "\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:  # NHWC\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        logit = float(np.array(output).reshape(-1)[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    if len(set(all_labels)) < 2:\n",
        "        auc = float('nan')\n",
        "    else:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0,1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, all_filenames, all_preds\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# PLOTTING FUNCTIONS\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on HEXA test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    # âœ… Fix: Pass test_data (not undefined variables)\n",
        "    tflite_metrics = evaluate_tflite_model_with_predictions(TFLITE_PATH, test_data, RESOLUTION)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS (HEXA-EYE):\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = os.path.join(OUTPUT_DIR, \"hexa_eye_detailed_predictions_tflite.csv\")\n",
        "        save_predictions_to_csv(tflite_filenames, tflite_labels, tflite_preds, tflite_probs, csv_path)\n",
        "\n",
        "        # Plot results\n",
        "        plot_roc_curve(\n",
        "            tflite_labels, tflite_probs,\n",
        "            \"ROC Curve - TFLite Hexa-Eye Model\",\n",
        "            os.path.join(OUTPUT_DIR, \"hexa_eye_roc_curve_tflite.png\")\n",
        "        )\n",
        "        plot_confusion_matrix(\n",
        "            tflite_labels, tflite_preds,\n",
        "            \"Confusion Matrix - TFLite Hexa-Eye Model\",\n",
        "            os.path.join(OUTPUT_DIR, \"hexa_eye_confusion_matrix_tflite.png\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. All outputs saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f2abf8-4ce4-4d45-9e5d-f5f4708131c8",
      "metadata": {
        "id": "11f2abf8-4ce4-4d45-9e5d-f5f4708131c8",
        "outputId": "fb04bad3-eba7-4fa1-ae6f-c3cc8943553e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Loading test data...\n",
            "âœ… Loaded 305 test samples (35 anemic, 270 non-anemic)\n",
            "ðŸ” Evaluating TFLite model...\n",
            "ðŸ” Input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0']\n",
            "   âž¤ Layout: NCHW, size: 224x224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-28 22:25:41.705141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-28 22:25:41.706385: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š TFLite Results (Tri-Left-Eye):\n",
            "Precision: 1.0000\n",
            "Recall:    0.9429\n",
            "F1 Score:  0.9706\n",
            "Accuracy:  0.9934\n",
            "AUC:       0.9996\n",
            "TP/TN/FP/FN: 33/270/0/2\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/tri_left_tflite_predictions.csv\n",
            "\n",
            "âœ… Evaluation complete. Outputs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Re-evaluation for Tri-Left-Eye Model\n",
        "- Loads test data from tri_left_eye/.../anemic_test_roi & anemic_not_test_roi\n",
        "- Evaluates exported .tflite model\n",
        "- Saves CSV + optional plots\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "from sklearn.metrics import (precision_recall_fscore_support, accuracy_score,\n",
        "                             roc_auc_score, confusion_matrix, roc_curve)\n",
        "import tensorflow as tf\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"tri_left_eye_resnet18_shared.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Test directories\n",
        "test_dirs_anemic = {\n",
        "    'left1': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "    'left2': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "    'left3': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "}\n",
        "test_dirs_non = {\n",
        "    'left1': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "    'left2': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "    'left3': os.path.join(BASE_PATH, 'tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_left(dirs_map):\n",
        "    suffixes = {'left1': '_left_eye_1.png', 'left2': '_left_eye_2.png', 'left3': '_left_eye_3.png'}\n",
        "    bases_sets = []\n",
        "    for k in ['left1', 'left2', 'left3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    return sorted(set.intersection(*bases_sets))\n",
        "\n",
        "def load_tri_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': [], 'filenames': []}\n",
        "    key_map = [('r1', 'left1', '_left_eye_1.png'),\n",
        "               ('r2', 'left2', '_left_eye_2.png'),\n",
        "               ('r3', 'left3', '_left_eye_3.png')]\n",
        "    for b in bases:\n",
        "        imgs, failed = {}, False\n",
        "        for out_key, dir_key, suf in key_map:\n",
        "            path = os.path.join(dirs_map[dir_key], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[out_key] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if not failed:\n",
        "            out['r1'].append(imgs['r1'])\n",
        "            out['r2'].append(imgs['r2'])\n",
        "            out['r3'].append(imgs['r3'])\n",
        "            out['filenames'].append(b)\n",
        "    return out\n",
        "\n",
        "def prepare_test_data(anemic_dirs, non_dirs):\n",
        "    bases_a = common_bases_left(anemic_dirs)\n",
        "    bases_n = common_bases_left(non_dirs)\n",
        "    imgs_a = load_tri_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_tri_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "    print(f\"âœ… Loaded {len(data['label'])} test samples \"\n",
        "          f\"({len(imgs_a['r1'])} anemic, {len(imgs_n['r1'])} non-anemic)\")\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Sort by name to ensure r1â†’input1, r2â†’input2, r3â†’input3\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” Input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {first_shape}\")\n",
        "\n",
        "    # Auto-detect layout\n",
        "    if first_shape[1] == 3 and first_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        resize_h, resize_w = int(first_shape[2]), int(first_shape[3])\n",
        "    elif first_shape[3] == 3 and first_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        resize_h, resize_w = int(first_shape[1]), int(first_shape[2])\n",
        "    else:\n",
        "        if first_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            resize_h, resize_w = int(first_shape[1]), int(first_shape[2])\n",
        "        elif first_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            resize_h, resize_w = int(first_shape[2]), int(first_shape[3])\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer layout from {first_shape}\")\n",
        "\n",
        "    print(f\"   âž¤ Layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        resized = pil_img.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    for i in range(len(test_data['label'])):\n",
        "        imgs = [test_data['r1'][i], test_data['r2'][i], test_data['r3'][i]]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            processed = preprocess_pil_style(imgs[idx])\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        logit = float(interpreter.get_tensor(output_details[0]['index']).flatten()[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    # Metrics\n",
        "    if len(set(all_labels)) < 2:\n",
        "        p = r = f1 = acc = auc = float('nan')\n",
        "        tn = fp = fn = tp = 0\n",
        "    else:\n",
        "        p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    true_str = ['Anemic' if y == 1 else 'Non-Anemic' for y in true_labels]\n",
        "    pred_str = ['Anemic' if y == 1 else 'Non-Anemic' for y in pred_labels]\n",
        "    tp = [1 if t == 1 and p == 1 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if t == 0 and p == 0 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if t == 0 and p == 1 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if t == 1 and p == 0 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_str,\n",
        "        'predicted_value': pred_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn\n",
        "    })\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# PLOTTING (Optional)\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = roc_auc_score(y_true, y_scores)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(title); plt.legend(loc=\"lower right\"); plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title); plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
        "\n",
        "# =========================\n",
        "# MAIN\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸ” Loading test data...\")\n",
        "    test_data = prepare_test_data(test_dirs_anemic, test_dirs_non)\n",
        "\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found: {TFLITE_PATH}\")\n",
        "\n",
        "    print(\"ðŸ” Evaluating TFLite model...\")\n",
        "    metrics = evaluate_tflite_model_with_predictions(TFLITE_PATH, test_data)\n",
        "\n",
        "    if metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, labels, probs, filenames, preds = metrics\n",
        "\n",
        "        print(\"\\nðŸ“Š TFLite Results (Tri-Left-Eye):\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 Score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP/TN/FP/FN: {tp}/{tn}/{fp}/{fn}\")\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = os.path.join(OUTPUT_DIR, \"tri_left_tflite_predictions.csv\")\n",
        "        save_predictions_to_csv(filenames, labels, preds, probs, csv_path)\n",
        "\n",
        "        # Optional: save plots\n",
        "        plot_roc_curve(labels, probs,\n",
        "                       \"ROC Curve - TFLite (Tri-Left-Eye)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"tri_left_roc_tflite.png\"))\n",
        "        plot_confusion_matrix(labels, preds,\n",
        "                              \"Confusion Matrix - TFLite (Tri-Left-Eye)\",\n",
        "                              os.path.join(OUTPUT_DIR, \"tri_left_cm_tflite.png\"))\n",
        "\n",
        "        print(f\"\\nâœ… Evaluation complete. Outputs saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ Evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbb8c9d-cbf6-4f34-bb42-263ee7648216",
      "metadata": {
        "id": "dfbb8c9d-cbf6-4f34-bb42-263ee7648216",
        "outputId": "1d7c3dda-c54e-4d63-e594-ee8e41bc92aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Loading test data...\n",
            "âœ… Loaded 318 test samples (34 anemic, 284 non-anemic)\n",
            "ðŸ” Evaluating TFLite model...\n",
            "ðŸ” Input names: ['serving_default_input1:0', 'serving_default_input2:0', 'serving_default_input3:0']\n",
            "   âž¤ Layout: NCHW, size: 224x224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-28 22:26:29.810386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-11-28 22:26:29.811609: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š TFLite Results (Tri-right-Eye):\n",
            "Precision: 1.0000\n",
            "Recall:    0.9118\n",
            "F1 Score:  0.9538\n",
            "Accuracy:  0.9906\n",
            "AUC:       1.0000\n",
            "TP/TN/FP/FN: 31/284/0/3\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/tri_right_tflite_predictions.csv\n",
            "\n",
            "âœ… Evaluation complete. Outputs saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Re-evaluation for Tri-right-Eye Model\n",
        "- Loads test data from tri_right_eye/.../anemic_test_roi & anemic_not_test_roi\n",
        "- Evaluates exported .tflite model\n",
        "- Saves CSV + optional plots\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "from sklearn.metrics import (precision_recall_fscore_support, accuracy_score,\n",
        "                             roc_auc_score, confusion_matrix, roc_curve)\n",
        "import tensorflow as tf\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"tri_right_eye_resnet18_shared.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Test directories\n",
        "test_dirs_anemic = {\n",
        "    'right1': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "    'right2': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "    'right3': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_test_roi/'),\n",
        "}\n",
        "test_dirs_non = {\n",
        "    'right1': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "    'right2': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "    'right3': os.path.join(BASE_PATH, 'tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/anemic_not_test_roi/'),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "def base_from(fname, suffix):\n",
        "    return fname[:-len(suffix)] if fname.endswith(suffix) else None\n",
        "\n",
        "def common_bases_right(dirs_map):\n",
        "    suffixes = {'right1': '_right_eye_1.png', 'right2': '_right_eye_2.png', 'right3': '_right_eye_3.png'}\n",
        "    bases_sets = []\n",
        "    for k in ['right1', 'right2', 'right3']:\n",
        "        folder = dirs_map[k]\n",
        "        if not os.path.isdir(folder):\n",
        "            return []\n",
        "        names = [f for f in os.listdir(folder) if f.endswith(suffixes[k])]\n",
        "        bases = {base_from(f, suffixes[k]) for f in names if base_from(f, suffixes[k]) is not None}\n",
        "        bases_sets.append(bases)\n",
        "    if not bases_sets:\n",
        "        return []\n",
        "    return sorted(set.intersection(*bases_sets))\n",
        "\n",
        "def load_tri_images_by_bases_with_filenames(dirs_map, bases):\n",
        "    out = {'r1': [], 'r2': [], 'r3': [], 'filenames': []}\n",
        "    key_map = [('r1', 'right1', '_right_eye_1.png'),\n",
        "               ('r2', 'right2', '_right_eye_2.png'),\n",
        "               ('r3', 'right3', '_right_eye_3.png')]\n",
        "    for b in bases:\n",
        "        imgs, failed = {}, False\n",
        "        for out_key, dir_key, suf in key_map:\n",
        "            path = os.path.join(dirs_map[dir_key], b + suf)\n",
        "            if not os.path.isfile(path):\n",
        "                failed = True\n",
        "                break\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                failed = True\n",
        "                break\n",
        "            imgs[out_key] = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if not failed:\n",
        "            out['r1'].append(imgs['r1'])\n",
        "            out['r2'].append(imgs['r2'])\n",
        "            out['r3'].append(imgs['r3'])\n",
        "            out['filenames'].append(b)\n",
        "    return out\n",
        "\n",
        "def prepare_test_data(anemic_dirs, non_dirs):\n",
        "    bases_a = common_bases_right(anemic_dirs)\n",
        "    bases_n = common_bases_right(non_dirs)\n",
        "    imgs_a = load_tri_images_by_bases_with_filenames(anemic_dirs, bases_a)\n",
        "    imgs_n = load_tri_images_by_bases_with_filenames(non_dirs, bases_n)\n",
        "    data = {\n",
        "        'r1': imgs_a['r1'] + imgs_n['r1'],\n",
        "        'r2': imgs_a['r2'] + imgs_n['r2'],\n",
        "        'r3': imgs_a['r3'] + imgs_n['r3'],\n",
        "        'filenames': imgs_a['filenames'] + imgs_n['filenames'],\n",
        "        'label': [1]*len(imgs_a['r1']) + [0]*len(imgs_n['r1'])\n",
        "    }\n",
        "    print(f\"âœ… Loaded {len(data['label'])} test samples \"\n",
        "          f\"({len(imgs_a['r1'])} anemic, {len(imgs_n['r1'])} non-anemic)\")\n",
        "    return data\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION\n",
        "# =========================\n",
        "def evaluate_tflite_model_with_predictions(tflite_path, test_data):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Sort by name to ensure r1â†’input1, r2â†’input2, r3â†’input3\n",
        "    sorted_inputs = sorted(input_details, key=lambda x: x['name'])\n",
        "    print(f\"ðŸ” Input names: {[d['name'] for d in sorted_inputs]}\")\n",
        "\n",
        "    first_shape = sorted_inputs[0]['shape']\n",
        "    if len(first_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {first_shape}\")\n",
        "\n",
        "    # Auto-detect layout\n",
        "    if first_shape[1] == 3 and first_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        resize_h, resize_w = int(first_shape[2]), int(first_shape[3])\n",
        "    elif first_shape[3] == 3 and first_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        resize_h, resize_w = int(first_shape[1]), int(first_shape[2])\n",
        "    else:\n",
        "        if first_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            resize_h, resize_w = int(first_shape[1]), int(first_shape[2])\n",
        "        elif first_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            resize_h, resize_w = int(first_shape[2]), int(first_shape[3])\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot infer layout from {first_shape}\")\n",
        "\n",
        "    print(f\"   âž¤ Layout: {layout}, size: {resize_h}x{resize_w}\")\n",
        "\n",
        "    def preprocess_pil_style(img_rgb):\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        resized = pil_img.resize((resize_w, resize_h), Image.BILINEAR)\n",
        "        tensor = to_tensor(resized)\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()\n",
        "\n",
        "    all_preds, all_probs, all_labels, filenames = [], [], [], test_data['filenames']\n",
        "\n",
        "    for i in range(len(test_data['label'])):\n",
        "        imgs = [test_data['r1'][i], test_data['r2'][i], test_data['r3'][i]]\n",
        "        label = test_data['label'][i]\n",
        "\n",
        "        for idx, detail in enumerate(sorted_inputs):\n",
        "            processed = preprocess_pil_style(imgs[idx])\n",
        "            if layout == 'NCHW':\n",
        "                model_input = np.expand_dims(processed, axis=0).astype(detail['dtype'])\n",
        "            else:\n",
        "                nhwc = np.transpose(processed, (1, 2, 0))\n",
        "                model_input = np.expand_dims(nhwc, axis=0).astype(detail['dtype'])\n",
        "            interpreter.set_tensor(detail['index'], model_input)\n",
        "\n",
        "        interpreter.invoke()\n",
        "        logit = float(interpreter.get_tensor(output_details[0]['index']).flatten()[0])\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_probs.append(prob)\n",
        "        all_labels.append(label)\n",
        "\n",
        "    # Metrics\n",
        "    if len(set(all_labels)) < 2:\n",
        "        p = r = f1 = acc = auc = float('nan')\n",
        "        tn = fp = fn = tp = 0\n",
        "    else:\n",
        "        p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return p, r, f1, acc, auc, tp, tn, fp, fn, all_labels, all_probs, filenames, all_preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    true_str = ['Anemic' if y == 1 else 'Non-Anemic' for y in true_labels]\n",
        "    pred_str = ['Anemic' if y == 1 else 'Non-Anemic' for y in pred_labels]\n",
        "    tp = [1 if t == 1 and p == 1 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if t == 0 and p == 0 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if t == 0 and p == 1 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if t == 1 and p == 0 else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_str,\n",
        "        'predicted_value': pred_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn\n",
        "    })\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# PLOTTING (Optional)\n",
        "# =========================\n",
        "def plot_roc_curve(y_true, y_scores, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = roc_auc_score(y_true, y_scores)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(title); plt.legend(loc=\"lower right\"); plt.grid(True)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Anemic', 'Anemic'],\n",
        "                yticklabels=['Non-Anemic', 'Anemic'])\n",
        "    plt.title(title); plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight'); plt.close()\n",
        "\n",
        "# =========================\n",
        "# MAIN\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸ” Loading test data...\")\n",
        "    test_data = prepare_test_data(test_dirs_anemic, test_dirs_non)\n",
        "\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found: {TFLITE_PATH}\")\n",
        "\n",
        "    print(\"ðŸ” Evaluating TFLite model...\")\n",
        "    metrics = evaluate_tflite_model_with_predictions(TFLITE_PATH, test_data)\n",
        "\n",
        "    if metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, labels, probs, filenames, preds = metrics\n",
        "\n",
        "        print(\"\\nðŸ“Š TFLite Results (Tri-right-Eye):\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 Score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP/TN/FP/FN: {tp}/{tn}/{fp}/{fn}\")\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = os.path.join(OUTPUT_DIR, \"tri_right_tflite_predictions.csv\")\n",
        "        save_predictions_to_csv(filenames, labels, preds, probs, csv_path)\n",
        "\n",
        "        # Optional: save plots\n",
        "        plot_roc_curve(labels, probs,\n",
        "                       \"ROC Curve - TFLite (Tri-right-Eye)\",\n",
        "                       os.path.join(OUTPUT_DIR, \"tri_right_roc_tflite.png\"))\n",
        "        plot_confusion_matrix(labels, preds,\n",
        "                              \"Confusion Matrix - TFLite (Tri-right-Eye)\",\n",
        "                              os.path.join(OUTPUT_DIR, \"tri_right_cm_tflite.png\"))\n",
        "\n",
        "        print(f\"\\nâœ… Evaluation complete. Outputs saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ Evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269d5e64-63df-421b-8509-1af431a44c59",
      "metadata": {
        "id": "269d5e64-63df-421b-8509-1af431a44c59",
        "outputId": "19fabb02-841c-42b2-efd5-a8140c284913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 42 anemic / 361 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 1.0000\n",
            "Recall:    0.9762\n",
            "F1 score:  0.9880\n",
            "Accuracy:  0.9972\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 41, 319, 0, 1\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/left_eye_2_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"left_eye_2_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"left_eye_2_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb959774-544d-489f-93ef-661f04f8e4b5",
      "metadata": {
        "id": "fb959774-544d-489f-93ef-661f04f8e4b5",
        "outputId": "aa789958-4c95-4736-b024-c7702a9a79d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 43 anemic / 361 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 1.0000\n",
            "Recall:    0.9767\n",
            "F1 score:  0.9882\n",
            "Accuracy:  0.9972\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 42, 318, 0, 1\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/left_eye_3_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_left_eye/left_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"left_eye_3_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"left_eye_3_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6ed3f8-04d2-4032-bdb0-6564d599b1d9",
      "metadata": {
        "id": "fc6ed3f8-04d2-4032-bdb0-6564d599b1d9",
        "outputId": "5bd2cfb8-b264-4dbc-d3ea-ddd0d3d6b66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 43 anemic / 365 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [   1    3 1024 1024]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 0.6500\n",
            "Recall:    0.3023\n",
            "F1 score:  0.4127\n",
            "Accuracy:  0.8986\n",
            "AUC:       0.8706\n",
            "TP, TN, FP, FN: 13, 315, 7, 30\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/right_eye_1_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_1_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"right_eye_1_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"right_eye_1_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79692812-d994-4ba1-854b-d582a4a0f48e",
      "metadata": {
        "id": "79692812-d994-4ba1-854b-d582a4a0f48e",
        "outputId": "8be43054-7300-4af4-ebd8-935f0501941f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 40 anemic / 369 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 1.0000\n",
            "Recall:    0.9750\n",
            "F1 score:  0.9873\n",
            "Accuracy:  0.9973\n",
            "AUC:       1.0000\n",
            "TP, TN, FP, FN: 39, 329, 0, 1\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/right_eye_2_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_2_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"right_eye_2_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"right_eye_2_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2dcb40-7228-4165-b14a-c6d63181822e",
      "metadata": {
        "id": "bd2dcb40-7228-4165-b14a-c6d63181822e",
        "outputId": "b0f13e66-c81e-446d-b2df-beb8622d2821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST: 40 anemic / 368 total\n",
            "ðŸ”€ Randomizing test dataset order...\n",
            "\n",
            "ðŸ” Loading TFLite model and evaluating on test set...\n",
            "ðŸ” TFLite model input shape: [  1   3 780 780]\n",
            "   âž¤ Detected layout: NCHW\n",
            "\n",
            "ðŸ“Š TFLITE TEST RESULTS:\n",
            "Precision: 1.0000\n",
            "Recall:    0.8750\n",
            "F1 score:  0.9333\n",
            "Accuracy:  0.9864\n",
            "AUC:       0.9987\n",
            "TP, TN, FP, FN: 35, 328, 0, 5\n",
            "âœ… Predictions saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files/right_eye_3_detailed_predictions_tflite.csv\n",
            "âœ… Evaluation complete. Results saved to: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite files\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "TFLite Evaluation on Test Set\n",
        "-----------------------------\n",
        "Load and evaluate a single TFLite model on the test set\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "DATA_DIR = \"tri_right_eye/right_eye_3_hb_less_than_9_0/conjunctiva_extracted/\"\n",
        "TFLITE_PATH = os.path.join(BASE_PATH, \"TFlite files\", \"right_eye_3_single_eye_resnet18.tflite\")\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOAD TEST DATA\n",
        "# =========================\n",
        "def load_images_with_filenames(folder, label):\n",
        "    imgs, lbls, filenames = [], [], []\n",
        "    if os.path.exists(folder):\n",
        "        for f in sorted(os.listdir(folder)):\n",
        "            if f.endswith(\".png\"):\n",
        "                im = cv2.imread(os.path.join(folder, f))\n",
        "                if im is not None:\n",
        "                    imgs.append(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
        "                    lbls.append(label)\n",
        "                    filenames.append(f)\n",
        "    return imgs, lbls, filenames\n",
        "\n",
        "dirs = {\n",
        "    'anemic_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_test_roi/\"),\n",
        "    'non_test': os.path.join(BASE_PATH, DATA_DIR, \"anemic_not_test_roi/\")\n",
        "}\n",
        "\n",
        "test_imgs, test_lbls, test_filenames = [], [], []\n",
        "for folder, label in [(dirs['anemic_test'],1),(dirs['non_test'],0)]:\n",
        "    i,l,f = load_images_with_filenames(folder,label)\n",
        "    test_imgs+=i; test_lbls+=l; test_filenames+=f\n",
        "\n",
        "print(f\"TEST: {sum(test_lbls)} anemic / {len(test_lbls)} total\")\n",
        "\n",
        "# ðŸ”€ Randomize the test set (reproducibly)\n",
        "print(\"ðŸ”€ Randomizing test dataset order...\")\n",
        "seed = 42\n",
        "rng = np.random.default_rng(seed)\n",
        "indices = rng.permutation(len(test_imgs))\n",
        "test_imgs = [test_imgs[i] for i in indices]\n",
        "test_lbls = [test_lbls[i] for i in indices]\n",
        "test_filenames = [test_filenames[i] for i in indices]\n",
        "\n",
        "# =========================\n",
        "# TFLITE EVALUATION WITH PREDICTIONS\n",
        "# =========================\n",
        "def evaluate_tflite_on_test_with_predictions(tflite_path, test_imgs, test_lbls, test_filenames):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    expected_shape = input_details[0]['shape']\n",
        "    print(f\"ðŸ” TFLite model input shape: {expected_shape}\")\n",
        "\n",
        "    if len(expected_shape) != 4:\n",
        "        raise ValueError(f\"Expected 4D input, got {expected_shape}\")\n",
        "\n",
        "    batch = expected_shape[0]\n",
        "    assert batch == 1, \"Batch size must be 1\"\n",
        "\n",
        "    # Detect layout: NCHW if shape[1] == 3, NHWC if shape[3] == 3\n",
        "    if expected_shape[1] == 3 and expected_shape[3] != 3:\n",
        "        layout = 'NCHW'\n",
        "        _, _, h, w = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NCHW\")\n",
        "    elif expected_shape[3] == 3 and expected_shape[1] != 3:\n",
        "        layout = 'NHWC'\n",
        "        _, h, w, _ = expected_shape\n",
        "        resize_h, resize_w = int(h), int(w)\n",
        "        print(f\"   âž¤ Detected layout: NHWC\")\n",
        "    else:\n",
        "        # Fallback: assume NHWC if last dim is 3\n",
        "        if expected_shape[-1] == 3:\n",
        "            layout = 'NHWC'\n",
        "            _, h, w, _ = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        elif expected_shape[1] == 3:\n",
        "            layout = 'NCHW'\n",
        "            _, _, h, w = expected_shape\n",
        "            resize_h, resize_w = int(h), int(w)\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot determine layout from shape {expected_shape}\")\n",
        "\n",
        "    preds, probs, labels_all = [], [], []\n",
        "\n",
        "    # Use PIL + torchvision to EXACTLY match PyTorch preprocessing\n",
        "    def preprocess_pil_style(img_rgb, target_size):\n",
        "        \"\"\"\n",
        "        Reproduce:\n",
        "          transforms.ToPILImage() â†’ Resize â†’ ToTensor â†’ Normalize\n",
        "        \"\"\"\n",
        "        # img_rgb: numpy array (H, W, C), uint8, RGB\n",
        "        pil_img = Image.fromarray(img_rgb)\n",
        "        # Resize with PIL BILINEAR (same as torchvision)\n",
        "        resized_pil = pil_img.resize((target_size[1], target_size[0]), Image.BILINEAR)  # (W, H)\n",
        "        # ToTensor: (H, W, C) uint8 â†’ (C, H, W) float32 [0,1]\n",
        "        tensor = to_tensor(resized_pil)  # shape: (C, H, W)\n",
        "        # Normalize with ImageNet stats\n",
        "        normalized = normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        return normalized.numpy()  # (C, H, W), float32\n",
        "\n",
        "    for img, label in zip(test_imgs, test_lbls):\n",
        "        # img is RGB numpy array (H, W, C), uint8 â€” same as loaded by cv2.cvtColor(..., cv2.COLOR_BGR2RGB)\n",
        "        img_norm_nchw = preprocess_pil_style(img, (resize_h, resize_w))  # (C, H, W)\n",
        "\n",
        "        if layout == 'NCHW':\n",
        "            input_data = np.expand_dims(img_norm_nchw, axis=0)  # (1, C, H, W)\n",
        "        else:  # NHWC\n",
        "            img_norm_nhwc = np.transpose(img_norm_nchw, (1, 2, 0))  # (H, W, C)\n",
        "            input_data = np.expand_dims(img_norm_nhwc, axis=0)  # (1, H, W, C)\n",
        "\n",
        "        input_data = input_data.astype(input_details[0]['dtype'])\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])  # [1, 1]\n",
        "        logit = output[0][0]\n",
        "        prob = 1.0 / (1.0 + np.exp(-logit))\n",
        "        pred = int(prob > 0.5)\n",
        "\n",
        "        preds.append(pred)\n",
        "        probs.append(prob)\n",
        "        labels_all.append(label)\n",
        "\n",
        "    if len(set(labels_all)) < 2:\n",
        "        print(\"âš ï¸ Only one class in test set!\")\n",
        "        return None\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, preds, average='binary')\n",
        "    acc = accuracy_score(labels_all, preds)\n",
        "    auc = roc_auc_score(labels_all, probs)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels_all, preds, labels=[0, 1]).ravel()\n",
        "\n",
        "    return P, R, F1, acc, auc, tp, tn, fp, fn, labels_all, probs, test_filenames, preds\n",
        "\n",
        "# =========================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================\n",
        "def save_predictions_to_csv(filenames, true_labels, pred_labels, pred_probs, output_path):\n",
        "    # Convert labels to readable format\n",
        "    true_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in true_labels]\n",
        "    pred_labels_str = ['Anemic' if label == 1 else 'Non-Anemic' for label in pred_labels]\n",
        "\n",
        "    # Calculate confusion matrix indicators\n",
        "    tp = [1 if (t == 1 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    tn = [1 if (t == 0 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fp = [1 if (t == 0 and p == 1) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "    fn = [1 if (t == 1 and p == 0) else 0 for t, p in zip(true_labels, pred_labels)]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'file_id': filenames,\n",
        "        'actual_value': true_labels_str,\n",
        "        'predicted_value': pred_labels_str,\n",
        "        'predicted_probability': pred_probs,\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"âœ… Predictions saved to: {output_path}\")\n",
        "\n",
        "# =========================\n",
        "# MAIN EXECUTION\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nðŸ” Loading TFLite model and evaluating on test set...\")\n",
        "    if not os.path.exists(TFLITE_PATH):\n",
        "        raise FileNotFoundError(f\"TFLite model not found at {TFLITE_PATH}\")\n",
        "\n",
        "    tflite_metrics = evaluate_tflite_on_test_with_predictions(TFLITE_PATH, test_imgs, test_lbls, test_filenames)\n",
        "\n",
        "    if tflite_metrics:\n",
        "        P, R, F1, acc, auc, tp, tn, fp, fn, tflite_labels, tflite_probs, tflite_filenames, tflite_preds = tflite_metrics\n",
        "        print(\"\\nðŸ“Š TFLITE TEST RESULTS:\")\n",
        "        print(f\"Precision: {P:.4f}\")\n",
        "        print(f\"Recall:    {R:.4f}\")\n",
        "        print(f\"F1 score:  {F1:.4f}\")\n",
        "        print(f\"Accuracy:  {acc:.4f}\")\n",
        "        print(f\"AUC:       {auc:.4f}\")\n",
        "        print(f\"TP, TN, FP, FN: {int(tp)}, {int(tn)}, {int(fp)}, {int(fn)}\")\n",
        "\n",
        "        # Save detailed TFLite predictions to CSV\n",
        "        save_predictions_to_csv(\n",
        "            tflite_filenames,\n",
        "            tflite_labels,\n",
        "            tflite_preds,\n",
        "            tflite_probs,\n",
        "            os.path.join(OUTPUT_DIR, \"right_eye_3_detailed_predictions_tflite.csv\")\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Evaluation complete. Results saved to: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ TFLite evaluation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda488f3-845c-419d-b1dc-a7a54c08fee0",
      "metadata": {
        "id": "eda488f3-845c-419d-b1dc-a7a54c08fee0",
        "outputId": "6352578b-2ba5-4622-fa3b-68788b0f9b99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' done '"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' done '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5640a3-c4ac-40bc-ac99-f7d05df01fd6",
      "metadata": {
        "id": "9f5640a3-c4ac-40bc-ac99-f7d05df01fd6",
        "outputId": "dbe79f73-f3b5-44ab-c118-48ad3b703c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zip created at: /home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/TFlite_files.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "BASE_PATH = BASE_PATH = \"/home/ubuntu/anemia-storage/hb_mobilenet/mat_conjunctiva_all_consistent_deletion/\"\n",
        "OUTPUT_DIR = os.path.join(BASE_PATH, \"TFlite files\")   # folder to zip\n",
        "\n",
        "ZIP_PATH = os.path.join(BASE_PATH, \"TFlite_files.zip\")  # name of zip file\n",
        "\n",
        "# Create ZIP\n",
        "shutil.make_archive(\n",
        "    base_name=ZIP_PATH.replace(\".zip\", \"\"),  # remove .zip for function\n",
        "    format='zip',\n",
        "    root_dir=OUTPUT_DIR\n",
        ")\n",
        "\n",
        "print(\"Zip created at:\", ZIP_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1033fd-e092-416a-97c7-9bd7cd12a240",
      "metadata": {
        "id": "9c1033fd-e092-416a-97c7-9bd7cd12a240"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}